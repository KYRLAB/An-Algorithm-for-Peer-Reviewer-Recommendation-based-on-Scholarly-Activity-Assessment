date,submitter_orcid,submitter_name,submitter_institution,submitter_email,submitter_title_doi,submitter_title,submitter_intro,submitter_author1_name,submitter_author1_institution,submitter_author1_email,submitter_author2_name,submitter_author2_institution,submitter_author2_email,submitter_author3_name,submitter_author3_institution,submitter_author3_email,submitter_author4_name,submitter_author4_institution,submitter_author4_email,submitter_author5_name,submitter_author5_institution,submitter_author5_email,submitter_author6_name,submitter_author6_institution,submitter_author6_email,submitter_author7_name,submitter_author7_institution,submitter_author7_email,submitter_author8_name,submitter_author8_institution,submitter_author8_email,submitter_author9_name,submitter_author9_institution,submitter_author9_email,submitter_author10_name,submitter_author10_institution,submitter_author10_email
20200101,326,Lu Qin,"The Chinese University of Hong Kong, Hong Kong, China",lqin@se.cuhk.edu.hk,,Diversifying Top-K Results,"ABSTRACT This paper proposes a general framework for matching similar subsequences in both time series and string databases. The matching results are pairs of query subsequences and database subsequences. The framework finds all possible pairs of similar subsequences if the distance measure satis- fies the ""consistency"" property, which is a property intro- duced in this paper. We show that most popular distance functions, such as the Euclidean distance, DTW, ERP, the Freche?t distance for time series, and the Hamming distance and Levenshtein distance for strings, are all ""consistent"". We also propose a generic index structure for metric spaces named ""reference net"". The reference net occupies O(n) space, where n is the size of the dataset and is optimized to work well with our framework. The experiments demon- strate the ability of our method to improve retrieval perfor- mance when combined with diverse distance measures. The experiments also illustrate that the reference net scales well in terms of space overhead and query time. 1. INTRODUCTION Sequence databases are used in many real-world applica- tions to store diverse types of information, such as DNA and protein data, wireless sensor observations, music and video streams, and financial data. Similarity-based search in such databases is an important functionality, that allows identi- fying, within large amounts of data, the few sequences that contain useful information for a specific task at hand. For example, identifying the most similar database matches for a query sequence can be useful for classification, forecasting, or retrieval of similar past events. The most straightforward way to compare the similarity between two sequences is to use a global similarity mea- sure, that computes an alignment matching the entire first sequence to the entire second sequence. However, in many scenarios it is desirable to perform subsequence matching, where, given two sequences Q and X, we want to identify pairs of subsequences SQ of Q and SX of X, such that the similarity between SQ and SX is high. When a large database of sequences is available, it is important to be able to identify, given a query Q, an optimally matching pair SQ and SX, where SX can be a subsequence of any database sequence. A well-known example of the need for subsequence match- ing is in comparisons of biological sequences. It is quite possible that two DNA sequences Q and X have a large Levenshtein distance [22] (also known as edit distance) be- tween them (e.g., a distance equal to 90% of the length of the sequences), while nonetheless containing subsequences SQ and SX that match at a very high level of statistical significance. Identifying these optimally matching subse- quences [34] helps biologists reason about the evolutionary relationship between Q and X, and possible similarities of functionality between those two pieces of genetic code. Similarly, subsequence matching can be useful in searching music databases, video databases, or databases of events and activities represented as time series. In all the above cases, while the entire query sequence may not have a good match in the database, there can be highly informative and statistically significant matches between subsequences of the query and subsequences of database sequences. Several methods have been proposed for efficient subse- quence matching in large sequence databases. However, all the proposed techniques are targeted to specific distance or similarity functions, and it is not clear how and when these techniques can be generalized and applied to other dis- tances. Especially, subsequence retrieval methods for string databases are difficult to be used for time-series databases. Furthermore, when a new distance function is proposed, we need to develop new techniques for efficient subsequence matching. In this paper we present a general framework, which can be applied to any arbitrary distance metric, as long as the metric satisfies a specific property that we call ""consistency"". Furthermore, we show that many well-known existing distance functions satisfy consistency. Thus, our framework can deal with both sequence types, i.e., strings and time series, including cases where each element of the sequence is a complex object. The framework in this paper consists of a number of steps: dataset segmentation, query segmentation, range query, can- didate generation, and subsequence retrieval. Brute-force search would require evaluating a total of O (|Q|2 |X|2) pairs of subsequences of Q and X. However our filtering method produces a shortlist of candidates after considering O (|Q| |X|) pairs of segments only. For the case where the distance is a metric, we also present a hierarchical reference 1579 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Articles from this volume were invited to present their results at The 38th International Conference on Very Large Data Bases, August 27th - 31st 2012, Istanbul, Turkey. Proceedings of the VLDB Endowment, Vol. 5, No. 11 Copyright 2012 VLDB Endowment 2150-8097/12/07... $ 10.00. net, a novel generic index structure that can be used within our framework to provide efficient query processing. Overall, this paper makes the following contributions: ? We propose a framework that, compared to alterna- tive methods, makes minimal assumptions about the underlying distance, and thus can be applied to a large variety of distance functions. ? We introduce the notion of âconsistencyâ as an im- portant property for distance measures applied to se- quences. ? We propose an efficient filtering method, which pro- duces a shortlist of candidates by matching only O(|Q| |X|) pairs of subsequences, whereas brute force would match O (|Q|2 |X|2) pairs of subsequences. ? We make this filtering method even faster, by using a generic indexing structure with linear space based on reference nets, that efficiently supports range similar- ity queries. ? Experiments demonstrate the ability of our method to provide good performance when combined with diverse metrics such as the Levenshtein distance for strings, and ERP [8] and the discrete Freche?t distance [11]) for time series. 2. RELATEDWORK Typically, the term ""sequences"" can refer to two different data types: strings and time-series. There has been a lot of work in subsequence retrieval for both time series and string databases. However, in almost all cases, existing methods concentrate on a specific distance function or specific type of queries. Here we review some of the recent works on subse- quence matching. Notice that this review is not exhaustive since the topic has received a lot of attention and a complete survey is beyond the scope of this paper. Time-series databases and efficient similarity retrieval have received a lot of attention in the last two decades. The first method for subsequence similarity retrieval under the Eu- clidean (L2?norm) distance appeared in the seminal paper of Faloutsos et al. [12]. The main idea is to use a sliding win- dow to create smaller sequences of fixed length and then use a dimensionality reduction technique to map each window to a small number of features that are indexed using a spa- tial index (e.g., R?-tree). Improvements of this technique have appeared in [28, 27] that improve both the window- based index construction and the query time using sliding windows on the query and not on the database. However, all these techniques are ap",Lu Qin,"The Chinese University of Hong Kong, Hong Kong, China",lqin@se.cuhk.edu.hk,Jeffrey Xu Yu,"The Chinese University of Hong Kong, Hong Kong, China",yu@se.cuhk.edu.hk,Lijun Chang,"The Chinese University of Hong Kong, Hong Kong, China",ljchang@se.cuhk.edu.hk,,,,,,,,,,,,,,,,,,,,,
20200102,897,Haohan Zhu,Department of Computer Science Boston University,zhu@cs.bu.edu,,A Generic Framework for Efficient and Effective Subsequence Retrieval,"ABSTRACT Top-k query processing finds a list of k results that have largest scores w.r.t the user given query, with the assumption that all the k results are independent to each other. In practice, some of the top-k results returned can be very similar to each other. As a re- sult some of the top-k results returned are redundant. In the lit- erature, diversified top-k search has been studied to return k re- sults that take both score and diversity into consideration. Most existing solutions on diversified top-k search assume that scores of all the search results are given, and some works solve the diver- sity problem on a specific problem and can hardly be extended to general cases. In this paper, we study the diversified top-k search problem. We define a general diversified top-k search problem that only considers the similarity of the search results themselves. We propose a framework, such that most existing solutions for top- k query processing can be extended easily to handle diversified top-k search, by simply applying three new functions, a sufficient stop condition sufficient(), a necessary stop condition necessary(), and an algorithm for diversified top-k search on the current set of generated results, div-search-current(). We propose three new algorithms, namely, div-astar, div-dp, and div-cut to solve the div-search-current() problem. div-astar is an A? based algorithm, div-dp is an algorithm that decomposes the results into components which are searched using div-astar independently and combined using dynamic programming. div-cut further decomposes the cur- rent set of generated results using cut points and combines the re- sults using sophisticated operations. We conducted extensive per- formance studies using two real datasets, enwiki and reuters. Our div-cut algorithm finds the optimal solution for diversified top-k search problem in seconds even for k as large as 2, 000. 1. INTRODUCTION Top-k queries are one of the most fundamental queries used in the IR and database areas. Given a user query, the top-k results of the query are a list of k results that have largest scores/relevances with respect to the user query, under the assumption that all of the k results are independent to each other. In some situations, for a cer- tain top-k query, some of the results returned can be very similar to each other. For example, if we search  íì§¸apple íì§¹ in Google image1, 7 out of the top-10 results returned are the logo of the Apple com- pany. In order to remove the redundancy in the results, and at the same time keep the quality of the top-k results, diversity should be considered in the top-k search problems. For top-k search algorithms. In the literature, most of them aim at finding an early stop condition, such that they can find the top- k results without exploring all the possible search results. Based on this, two frameworks are generally used, namely, the incremen- tal top-k framework and the bounding top-k framework. The in- cremental top-k framework outputs the results one by one in non- increasing order of their scores, and stops as soon as k results are generated. It aims to find a polynomial delay algorithm such that given the existing generated results, the next result with largest score can be generated in polynomial time w.r.t. the size of the input only [16, 15, 20, 14]. In the bounding top-k framework, re- sults are not necessarily generated in non-increasing order of their scores. It maintains a score upper bound for the unseen results ev- ery time when a new result is generated. The algorithm stops when the current k-th largest score is no smaller than the upper bound for the unseen results. The threshold algorithm based approaches [7, 9] fall in this framework and other approaches include [12, 17]. Diversity aware search has been studied in recent years. Most of the existing solutions that support diversity on top-k search results assume the ranking of all the search results are given in advance. Based on which, a diversity search algorithm is given to output k results based on a scoring function that takes both query relevance and diversity into consideration [6, 1, 11, 5, 2]. Other works give algorithms that solve the diversity problem for a special area, i.e., graph search [18], document search [22], etc. and can hardly be extended to support general top-k diversity search. In this paper, we propose a general framework to handle the di- versified top-k search problem. We keep the advantages for the existing top-k search algorithms, that can stop early without ex- ploring all search results, and at the same time, we take diversity into consideration. We show that any top-k search algorithm that can be used in the incremental top-k framework or the bounding top-k framework can be easily extended to handle diversified top- k search, by adding three new functions studied in this paper: a sufficient stop condition sufficient(), a necessary stop condition necessary(), and a diversity search function div-search-current(). All of them are application independent. The only assumption in our framework is that, given any two search results vi and vj , whether vi and vj are similar to each other can be decided, e.g., us- ing a similarity function sim(vi, vj) > íì§íì¨ for a user given threshold íì§íì¨ . We output a list of k results with maximum total scores such that 1 http://www.google.com/imghp 1124 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Articles from this volume were invited to present their results at The 38th International Conference on Very Large Data Bases, August 27th - 31st 2012, Istanbul, Turkey. Proceedings of the VLDB Endowment, Vol. 5, No. 11 Copyright 2012 VLDB Endowment 2150-8097/12/07... $ 10.00. no two of them are similar to each other. We make the following contributions in this paper. (1) We formalize the diversified top-k search problem. Based on our definition, the optimal solution only depend on the similarity of search results themselves, and no other information is needed. (2) We study two categories of algorithms generally used in finding top-k results with early stop in the literature, namely, the incre- mental top-k framework and the bounding top-k framework. We show both frameworks can be extended to diversified top-k search by simply adding three application independent functions studied in this paper, namely, a sufficient stop condition sufficient(), a nec- essary stop condition necessary(), and a diversity search function div-search-current(). The sufficient stop condition helps to early stop and the necessary stop condition helps to reduce the number of div-search-current() processes, since div-search-current() is usu- ally a costly operation. (3) We show that div-search-current() is an NP-Hard problem and is hard to be approximated. We propose three new algorithms, namely, div-astar, div-dp, and div-cut, to find the optimal solution for div-search-current(). div-astar is an A? based algorithm and is slow to handle a large number of results. div-dp decomposes the results into disconnected components in order to reduce the graph size to be searched using div-astar. Results in div-dp are com- bined using dynamic programming. div-cut further decomposes each component into several subgraphs to form a cptree, based on the cut points of each component. A tree based search is applied on cptree to find the optimal solution. (4) We conducted extensive performance studies using two real datasets, to test the performance of the three algorithms. Our div-cut approach can find the diversified top-k results within seconds when k is as large as 2, 000. The rest of this paper is organized as follows. Section 2 formally defines the diversified top-k search problem. Section 3 shows the two existing frameworks on general top-k search problems. Sec- tion 4 shows how to extend the two categories of top-k search ap- proaches to solve diversified top-k search, by defining a sufficient stop condition sufficient(), a necessary stop condition necessary(), and a diversified top-k search algorithm div-search-current() to search on the current result set. Section 5, 6, and 7 give three al- gorithms to solve the div-search-current() problem. We show our experimental results in Section 8, and introduce the related work in Section 9. Finally, we conclude our paper in Section 10. 2. PROBLEM DEFINITION We consider a list of results S = {v1, v2,  íì§  íì§  íì§ }. For each vi  íì¨ S, the score of vi is denoted as score(vi). For any two results vi  íì¨ S and vj  íì¨ S, there is a user defined similarity function sim(vi, vj) denoting the similarity between the two results vi and vj . Without loss of generality, we assume 0  íí sim(vi, vj)  íí 1 for any two results vi  íì¨ S and vj  íì¨ S, and sim(v, v) = 1 for any v  íì¨ S. Given an integer k where 1  íí k  íí |S|, the top-k results of S is a list of k results Sk that satisfy the following two conditions. 1) Sk  íì¨ S and |Sk| = k. 2) For any vi  íì¨ Sk and vj  íì¨ S ? Sk, score(vi)  íí score(vj). Here, S ? Sk is the set of results that are in S but not in Sk, i.e., S ? Sk = {v|v  íì¨ S, v / íì¨ Sk}. Given two results vi  íì¨ S and vj  íì¨ S, vi is similar to vj iff sim(vi, vj) > íì§íì¨ where íì§íì¨ is a user defined threshold, and 0 < íì§íì¨  íí 1. We use vi ? vj to define that vi is similar to vj . Definition 1 (Diversified Top-k Results) Given a list of search results S = {v1, v2,  íì§  íì§  íì§ }, and an integer k where 1  íí k  íí |S|, the v1 v3 v5 v2 v4 v6 10 6 8 7 7 1 v1 v3 v5 v2 v4 v6 10 6 8 7 7 1 K=3K=2 Figure 1: A sample diversity graph diversified top-k results of S, denoted as D(S), is a list of results that satisfy the following three conditions. 1) D(S)  íì¨ R and |D(S)|  íí k. 2) For any two results vi  íì¨ R and vj  íì¨ R and vi 6= vj , if vi ? vj , then {vi, vj} * D(S). 3) íì§2 v íì¨D(S) score(v) is maximized. Intuitively, D(S) is the set of at most k results, such that no two results are similar with each other, and the total score of the results is maximized. We use score(D(S)) to denote the total score of results in D(S), i.e., score(D(S)) = íì§2 v íì¨D(S) score(v). In this paper, we are to find the diversified top-k results. Our aim is to find a general approach, such that for any existing algo- rithm that returns the top-k results of a certain problem, it can be easily changed to return the diversified top-k results by applying our framework, in which the result set S is not necessarily to be computed in advanced but grows incrementally with an early stop condition. We first give the definition of the diversity graph. Definition 2 (Diversity Graph) Given a list of results S = {v1, v2,  íì§  íì§  íì§ }, the diversity graph of S, denoted as G(S) = (V,E), is an undirected graph such that for any result v  íì¨ R, there is a corresponding node v  íì¨ V , and for any two results vi  íì¨ S and vj  íì¨ R, there is an edge (vi, vj)  íì¨ E iff vi ? vj . We use V (G(S)) and E(G(S)) to denote the set of nodes and the set of edges in the diversity graph G(S) respectively, and use v.adj(G(S)) to denote the set of nodes that are adjacent to v in G(S). If the context is obvious, we use vi to denote both the result vi in S and the node vi in G(S), we use G to denote G(S), and we use D to denote D(S). Without loss of generality, we assume nodes in G(S) are arranged in non-increasing order of their scores, i.e., for any 1  íí i < j  íí |V (G(S))|, score(vi)  íí score(vj). The diversified top-k results D(S) can be equivalently defined as a subset of nodes in G(S), that satisfy the three conditions. 1) |D(S)|  íí k. 2) D(S) is an independent set of G(S). 3) score(D(S)) is maximized. Here, an independent set of a graph is a set of nodes in a graph, where no two nodes are adjacent. Example 1 Fig. 1 shows the diversity graph for 6 results S = {v1, v2,  íì§  íì§  íì§ , v6}. Suppose k = 2, the optimal solution D(S) includes two points v1 and v2 with score 18, as shown on the left part of Fig. 1. Suppose k = 3, the optimal solution D(S) includes three points v3, v4 and v5 with score 20, as shown on the right part of Fig. 1. In the following, we first show the two existing frameworks to solve top-k search problems, namely, the incremental top-k frame- work and the bounding top-k framework, which are most generally used in top-k search algorithms. Then we show the framework of 1125 Algorithm 1 incremental(k) 1: S  íì§  ?; 2: for i=1 to k do 3: v  íì§  incremental-next(); 4: if v = ? then 5: break; 6: S  íì§  S ? {v}; 7: return S; Algorithm 2 bounding(k) 1: S  íì§  ?; 2: unseen íì§  + íí; 3: while the k-th largest score of S < unseen do 4: v  íì§  bounding-next(); 5: if v = ? then 6: break; 7: S  íì§  S ? {v}; 8: update unseen; 9: return top-k results in S; our approach to extend the two frameworks to handle diversified top-k search. 3. TOP-K SEARCH FRAMEWORKS In the literature, the framework of most algorithms that find top- k results falls into two categories, namely, the incremental top-k framework and the bounding top-k framework. Incremental Top-k: In the incremental top-k framework, results are generated one by one by calling a procedure incremental-next(), with non-increasing order of their scores. The algorithm stops after k results are generated, and the k results are the final top-k results for the problem. The framework named incremental is shown in Algorithm 1. A lot of existing work fall into this category, e.g., finding top-k shortest paths in graphs, finding top-k steiner trees, communities and r-cliques in graphs, etc [16, 15, 20, 14]. A lot of works have been done to assume that the time complexity of each incremental-next() procedure to generate the next result with largest score is polynomial w.r.t. the size of the input only. Bounding Top-k: In the bounding top-k framework, results are generated one by one by calling a procedure bounding-next(), but not necessarily with non-increasing order of their scores. A bound unseen is defined to be the upper bound of the scores for the un- seen results. After each result is generated by bounding-next(), unseen is also updated to be a possibly smaller value. The algo- rithm stops when the k-th largest score of all generated results is no smaller than the upper bound for the unseen results unseen. The framework named bounding is shown in Algorithm 2. The thresh- old algorithm that is generally used to return top-k results falls into this category [7, 9]. Other works that fall into this category include [12, 17]. 4. DIVERSIFIED TOP-K SEARCH In this section, we show how to extend the incremental top-k framework incremental and bounding top-k framework bounding to handle diversified top-k search. We mainly focus on two tasks. First, a new early stop conditions is needed. Second, an algorithm that finds the diversified top-k results for the current generated re- sult set is needed. For the early stop condition, in the original al- gorithm, the stop condition for incremental is simply |S| = k and the stop condition for bounding is the current k-th largest score  íí unseen. Obviously, both of them cannot be applied to handle Algorithm 3 div-search(k) 1: S  íì§  ?; D(S) íì§  ?; 2: while sufficient() do 3: the code to update S (and unseen); 4: if necessary() then 5: D(S) íì§  div-search-current(G(S), k); 6: return D(S); diversified top-k search. Consider an extreme case, when the al- gorithm stops using the original stop condition, it is possible that all the results generated are similar to each other. Thus the current diversified top-k results only contain 1 result with the largest score. It is not the optimal solution because it is possible that an unseen result is not similar to the current one. Here, D(S) computed for the current generated result set S can be used to check the new stop condition, and if the new stop condition is satisfied, D(S) is the optimal solution for the diversified top-k search. We extend both incremental and bounding using the same frame- work, which is shown in Algorithm 3, by adding three new func- tions, a new sufficient stop condition sufficient(), a new necessary stop condition necessary() and an algorithm div-search-current() to search the diversified top-k results on the current generated re- sult set. The algorithm executes the code of the original top-k al- gorithm to update S and stops when sufficient() is satisfied. For incremental, the code is line 3-6 in algorithm 1, and for bounding, the code is line 4-8 in algorithm 2. After updating S, we construct the diversity graph G(S) on S based on the similarity function sim() for any given two results. If the necessary stop condition is satisfied, we find the diversified top-k results for the current result set S using div-search-current(). The necessary stop condition is used to reduce the number of calling div-search-current(), because div-search-current() is a costly work. In the following, we will in- troduce the sufficient stop condition, the necessary stop condition, and the search algorithm for current set. Sufficient Stop Condition: Given the current result set S, we need to calculate an upper bound best(S) for the possible optimal solu- tions considering both the current result set S and the unseen re- sults. Let Di(S) be the best diversified results of S with exactly i elements for 1  íí i  íí k, i.e., Di(S) is a subset of nodes in V (G(S)), that satisfies the following three conditions. 1) |Di(S)| = k. 2) Di(S) is an independent set of G(S). 3) score(Di(S)) is maximized. Lemma 1 Given Di(S) for 1  íí i  íí k and the score upper bound of all the unseen results u. The upper bound best(S) can be calcu- lated as follows. best(S) = max 1 ííi íík {score(Di(S)) + (k ? i) íì© u} (1) where u is the score of the last generated result v, score(v), for incremental and is the upper bound of the unseen results, unseen, for bounding. Proof Sketch: Suppose the final optimal solution is O, then we can divide O into two parts, O = O1 ? O2, where O1 is the set of generated results, and O2 is the set of unseen results. Suppose O1 has n1 elements and O2 has n2 elements. We have n1 + n2  íí k. Since O1 is the set of generated results, we have (1) score(O1)  íí score(Dn1(S)), since Dn1(S) is the optimal solution with n1 el- ements. We also have (2) score(O2)  íí n2  íì© u  íí (k ? n1)  íì© u, 1126 since (u) is the score upper bound for all unseen results. Com- bine (1) and (2), we have score(O) = score(O1) + score(O2)  íí score(Dn1(S)) + (k ? n1)  íì© u  íí max1 ííi íík{score(Di(S)) + (k? i) íì©u} = best(S). best(S) is an upper bound for the optimal solution. ? Having the score upper bound best(S) for the optimal solution, the sufficient stop condition for div-search can be defined as fol- lows. score(D(S))  íí best(S) (2) The following lemma shows that, after every iteration, div-search moves towards the sufficient stop condition. Lemma 2 For any S íí  íì¨ S, best(S íí)  íí best(S) and best(S íí)  íí best(S). Proof Sketch: Since S íí  íì¨ S, the best solution on S íí is a feasible solution on S, thus best(S íí)  íí best(S). Comparing to best(S íí), best(S) is calculated by changing some upper bounds u íí when cal- culating best(S íí) into the real scores no larger than u íí and chang- ing the other unseen upper bounds from u íí to u, where u  íí u íí is assumed by the original algorithm. Thus best(S íí)  íí best(S). ? Necessary Stop Condition: We discuss the necessary stop con- dition for div-search. The necessary stop condition is used as fol- lows. In each iteration, before invoking div-search-current(), if the necessary stop condition is not satisfied, then div-search-current() is not necessarily to be invoked in this iteration. Lemma 3 For div-search, if it can stop in a certain iteration, one of the following conditions should be satisfied before invoking the procedure div-search-current(): 1) The last generated result v = ?. 2) |S|  íí |S íí|+ k ?max{i|1  íí i  íí k,Di(S  íí) 6= ?} and the k-th largest score in S  íí u. Here S íí is the set of results when the last div-search-current() is invoked or ? if div-search-current() is never invoked. Proof Sketch: The first condition is trivial. Now suppose v 6= ?. For the second condition, when the k-th largest score in S < u, it is possible that a new result can be added that updates the k-th largest score, and thus improves the current best solution. Now we discuss |S|  íí |S íí| + k ? max{i|1  íí i  íí k,Di(S  íí) 6= ?}. max{i|1  íí i  íí k,Di(S  íí) 6= ?} is the size of the maximum independent set for G(S íí) if it is smaller than k, and k?max{i|1  íí i  íí k,Di(S  íí) 6= ?} is the minimum number of nodes needed to be added in order to generate a result of size k. If such a result does not exist, we cannot stop because we can always add some unseen nodes to any existing solution with a size smaller than k to make the score larger. As a result, we should add at least k ?max{i|1  íí i  íí k,Di(S  íí) 6= ?} nodes into S íí. ? Searching Current Set: The most important operation in our frame- work is the the algorithm div-search-current() to search the diver- sified top-k results for the current result set S. We first show the difficulties of the problems in this section and give three algorithms, namely div-astar, div-dp, and div-cut on div-search-current() in the next three sections respectively. The following lemma shows that finding the diversified top-k results is an NP-Hard problem. Lemma 4 Finding D(S) on G(S) is an NP-Hard problem. Proof Sketch: We consider a special case of the problem, where score(v) = 1 for all v  íì¨ V (G(S)), and k = |V (G(S))|. In such a case, finding Dk(R) on G(S) is equivalent to finding the v1 v2 v3 v0  íì§  íì§  íì§ u1 u2 u3  íì§  íì§  íì§ u100 v100 99 99 99 1 1 100 99 0.5 1 (a) The Greedy Solution v1 v2 v3 v0  íì§  íì§  íì§ u1 u2 u3  íì§  íì§  íì§ u100 v100 99 99 99 1 1 100 99 0.5 1 (b) The Optimal Solution Figure 2: The greedy algorithm div?astar div?dp div?cut NP NP NP NP NP NP NP NP NP NP NP NP NP NP NP NP NP NP NP NP NP NP NP NPNP Figure 3: Overview of three algorithms maximum independent set on graph G(S), which is an NP-Hard problem. Thus, the original problem is an NP-Hard problem. Greedy is Not Good: Given G(S) and k, a simple greedy algo- rithm to find D(S) works as follows. It processes in iterations. In each iteration, the node v with the maximum score is selected and put into D(S). After that, all the nodes that are adjacent to v in G(S) is removed from G(S). The process stops when G(S) is empty or D(S) contains k results. The quality of the greedy algorithm can be arbitrarily bad. The approximation ratio for the greedy algorithm is not bounded by a constant factor. Even for its special case, the maximum indepen- dent set problem is known to be hard to approximate in the litera- ture. We give an example. Fig. 2 shows a diversity graph with 201 nodes and 200 edges. Suppose k = 100. Using the greedy algo- rithm, the solution is shown in Fig. 2(a), where the selected results are marked gray. The score of the greedy solution is 199. The op- timal solution for the problem is shown in Fig. 2(b). The score of the optimal solution is 9, 900, which is nearly 50 times of the score of the greedy solution. In the following, we propose to find the optimal solution of D(S). We propose three algorithms, namely, div-astar, div-dp, and div-cut. div-astar searches the whole space S using the A? based heuris- tics by designing an upper bound function astar-bound(). Based on the NP-Hardness of the problem, div-astar can hardly handle problems with large diversity graph G. In our second div-dp al- gorithm, we decompose G into connected components. The size of each component can be much smaller than the original graph G, and is searched independently using div-astar. We combine the components using an efficient operation ? based on dynamic pro- gramming. In our third div-cut algorithm, we further decompose each connected component into subgraphs, where subgraphs are connected through a set of cut points. Each subgraph is searched independently for at most 4 times under different conditions. We combine the components using two efficient operations ? and ?. The general ideas of the three algorithms are illustrated in Fig. 3. 5. AN A? BASED APPROACH As discussed in Section 4, div-search-current(G(S), k) should return the optimal solution Di(S) for 1  íí i  íí k in order to find the early stop condition. For simplicity, we use D to denote the set of solutions, and we use D.solutioni to denote the optimal solution 1127 Algorithm 4 div-astar(G, k) Input: The diversity graph G, the top-k value. Output: Search result D. 1: H  íì§  ?; D  íì§  ?; 2: H.push((?, 0, 0, 0)); 3: for k íí = k down to 1 do 4: astar-search(G,H, D, k íí); 5: for all e  íì¨ H do 6: e.bound íì§  astar-bound(G, e, k íí); 7: update e inH; 8: return D; 9: procedure astar-search(G,H, D, k íí) 10: whileH 6= ? andH.top.bound > maxi íík íí{D.scorei} do 11: e íì§  H.pop(); 12: for i = e.pos+ 1 to |V (G)| do 13: if vi.adj(G) ? e.solution = ? then 14: e íí  íì§  (e.solution ? {vi}, i, e.score+ score(vi), 0); 15: e íí.bound íì§  astar-bound(G, e íí, k íí); 16: H.push(e íí); 17: update D using e íí.solution; 18: procedure astar-bound(G, e, k íí) 19: p íì§  |e.solution|; i íì§  e.pos+ 1; 20: bound íì§  e.score; 21: while p < k íí and i < |V (G)| do 22: if vi.adj(G) ? e.solution = ? then 23: bound íì§  bound+ score(vi); 24: p íì§  p+ 1; 25: i íì§  i+ 1; 26: return bound; with i results Di(S), and use D.scorei to denote the score for the optimal solution score(Di(S)). Our first algorithm is an A? based algorithm. The algorithm is shown in Algorithm 4. We define a max heap H to store the entries in the A? search. Each entry e  íì¨ H is with the form e = (solution, pos, score, bound). Each entry e is ranked in H according to e.bound, which is the estimated upper bound of the solution if we further expand it in the A? search. e.solution is the partial solution searched and e.pos is the position of the last searched node in e.solution. e.score is the score of the partial solu- tion, i.e., e.score = score(e.solution). The algorithm should return D.solutioni for all 1  íí i  íí k. Suppose we have an A ? algorithm that finds the optimal solution for a certain D.solutioni, the algo- rithm should be invoked k times to find the k solutions, which is costly. We show that after searching D.solutioni for a certain i, the partial solutions in H can be reused when searching D.solutionj for j < i. In the following, we first discuss the estimated upper bound for partial solutions. Then we discuss the A? algorithm to find the optimal solution D.solutioni for a certain i. At last, we discuss how the partial solutions in H can be reused to find the optimal solutions D.solutioni for all 1  íí i  íí k. Upper Bound Estimation: Given a partial solution e, for a cer- tain k íí, we show how to estimate the score upper bound if we ex- pand the partial solution to be a solution of at most k íí elements. The algorithm astar-bound is shown in Algorithm 4, line 18-26. The newly added nodes should at least satisfy the following two conditions: 1) they can not be one of e.solution, and 2) they are not adjacent to any node in e.solution. Under such conditions, we can just add the set of nodes with largest scores, and after adding the nodes, the total number of nodes is no larger than k íí. In or- der to satisfy condition 1), we visit nodes in G from the posi- tion e.pos + 1 (line 19). Since nodes in G are sorted in the non- increasing order of their scores, we add nodes one by one until the size p reaches k íí. For each node added, condition 2) can be checked using vi.adj(G) ? e.solution = ? (line 22). Lemma 5 astar-bound(G, e, k íí) finds the score upper bound for the partial solution e.solution to be expanded to a solution of at most k íí elements. Proof Sketch: Suppose we have removed all the nodes from G that are adjacent to at least one node in e.solution, then the func- tion astar-bound(G, e, k íí) calculates the upper bound by expand- ing e.solution using the set of nodes after position e.pos in G with largest scores. The optimal solution that e.solution can be ex- panded also selects the expanded nodes from the set of nodes after position e.pos but it may not select all with the largest scores since some of them may be adjacent to each other. Thus the optimal so- lution can not be larger than astar-bound(G, e, k íí). As a result, astar-bound(G, e, k íí) is a score upper bound for all expansions of e.solution. ? A? Search for a Certain k: To find the optimal solution for a certain k = k íí, the A? search algorithm astar-search is shown in Algorithm 4, line 9-17. It runs in iterations. In each iteration, the partial solution e with the largest estimated upper bound is popped out from H (line 11). e can then be expanded to new partial solu- tions by adding a new node into e.solution. The nodes are added from position e.pos + 1 in G since all nodes before the position has been processed (line 12). The newly added node vi should not be adjacent to one of e.solution(line 13), and after adding the new node, the upper bound of the new partial solution should be updated using astar-bound(), and the new partial solution should be pushed into H for further expansion (line 14-16). In line 17, suppose the",Haohan Zhu,Department of Computer Science Boston University,zhu@cs.bu.edu,George Kollios,Department of Computer Science Boston University,gkollios@cs.bu.edu,Vassilis Athitsos,Computer Science and Engineering Department University of Texas at Arlington,athitsos@uta.edu,,,,,,,,,,,,,,,,,,,,,
20200103,1387,Stefan Aulbach,"Technische Universit?t M?nchen, Germany",stefan.aulbach@in.tum.de,,A Comparison of Flexible Schemas for Software as a Service,"ABSTRACT A multi-tenant database system for Software as a Service (SaaS) should offer schemas that are flexible in that they can be extended for different versions of the application and dynamically modified while the system is on-line. This pa- per presents an experimental comparison of five techniques for implementing flexible schemas for SaaS. In three of these techniques, the databaseì°½íµownsì°½í¶the schema in that its struc- ture is explicitly defined in DDL. Included here is the com- monly-used mapping where each tenant is given their own private tables, which we take as the baseline, and a map- ping that employs Sparse Columns in Microsoft SQL Server. These techniques perform well, however they offer only lim- ited support for schema evolution in the presence of existing data. Moreover they do not scale beyond a certain level. In the other two techniques, the application ì°½íµownsì°½í¶ the schema in that it is mapped into generic structures in the database. Included here are XML in DB2 and Pivot Tables in HBase. These techniques give the application complete control over schema evolution, however they can produce a significant decrease in performance. We conclude that the ideal data- base for SaaS has not yet been developed and offer some suggestions as to how it should be designed. Categories and Subject Descriptors H.4 [Information Systems Applications]: Miscellaneous; H.2.1 [Information Systems]: Database Managementì°½í¬ Logical Design General Terms Design, Performance Keywords Multi-Tenancy, Software as a Service, Flexible Schemas, Ex- tensibility, Evolution Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGMODì°½í²09, June 29?July 2, 2009, Providence, Rhode Island, USA. Copyright 2009 ACM 978-1-60558-551-2/09/06 ...$5.00. 1. INTRODUCTION In the Software as a Service (SaaS) model, a service pro- vider owns and operates an application that is accessed by many businesses over the Internet. A key benefit of this model is that, by careful engineering, it is possible to lever- age economy of scale to reduce total cost of ownership rel- ative to on-premises solutions. Common practice in this regard is to consolidate multiple businesses into the same database to reduce operational expenditures, since there are fewer processes to manage, as well as capital expenditures, since resource utilization is increased. A multi-tenant database system for SaaS should offer sche- mas that are flexible in two respects. First, it should be possible to extend the base schema to support multiple spe- cialized versions of the application, e.g., for particular ver- tical industries or geographic regions. An extension may be private to an individual tenant or shared by multiple ten- ants. Second, it should be possible to dynamically evolve the base schema and its extensions while the database is on-line. Evolution of a tenant-owned extension should be totally ì°½íµself-serviceì°½í¶: the service provider should not be in- volved; otherwise operational costs will be too high. This paper presents an experimental comparison of five techniques for implementing flexible schemas for SaaS. In three of these techniques, the database ì°½íµownsì°½í¶ the schema in that its structure is explicitly defined in DDL: Private Tables: Each tenant is given their own private in- stance of the base tables that are extended as required. In contrast, in all of the other mappings, tenants share tables. We take Private Tables as the experimental baseline. Extension Tables: The extensions are vertically partitio- ned into separate tables that are joined to the base tables along a row ID column. Sparse Columns: Every extension field of every tenant is added to its associated base table as a Sparse Column. Our experiments here use Microsoft SQL Server 2008 [1]. To implement Sparse Columns efficiently, SQL Server uses a variant of the Interpreted Storage Format [4, 7], where a value is stored in the row together with an identifier for its column. Our experimental results show that these techniques per- form well, however they offer only limited support for schema evolution. DDL commands over existing data, if they are supported at all, consume considerable resources and neg- atively impact performance. In the on-line setting, the ap- 881 plication must be given control over when and how bulk data transformations occur. An additional issue is that these techniques do not scale beyond a certain level. In the other two techniques, the application ì°½íµownsì°½í¶ the schema in that it is mapped into generic structures in the database: XML: Each base table is augmented by a column that stores all extension fields for a tenant in a flat XML document. Since these documents necessarily vary by tenant, they are untyped. Our experiments here use pureXML in IBM DB2 [20]. Pivot Tables: Each value is stored along with an identifier for its column in a tall narrow table [2]. Our exper- iments here use HBase [11], which is an open source version of Google BigTable [6]. BigTable and HBase were originally designed to support the exploration of massive web data sets, but they are increasingly be- ing used to support enterprise applications [14]. The Pivot Table mapping into HBase that we employ is consistent with best practices. These two techniques give the application complete con- trol over schema evolution, however our experimental results show that they can produce a significant decrease in perfor- mance from the baseline. For XML, the decrease is greatest for reads, which require parsing the untyped documents and reassembling typed rows. The decrease is proportional to the number of extension fields. For Pivot Tables, the de- crease is more than an order of magnitude in some cases. Note that these results should not be taken as a negative statement about the quality of these systems, since they have not been optimized for our use case. Moreover, HBase is an early-stage open source project, not a mature com- mercial product. Our results are intended to give a general indication of the trade-offs in implementing flexible schemas. Several major SaaS vendors have developed mapping tech- niques in which the application owns the schema. This ap- proach has been elevated to a design principle whereby the application derives essential capabilities by managing the metadata itself [19, 23]. To achieve acceptable performance, these applications re-implement significant portions of the database, including indexing and query optimization, from the outside. We believe that databases should be enhanced to directly support the required capabilities. Our experiments are based on a multi-tenant database testbed that simulates a simple but realistic Customer Re- lationship Management (CRM) service. The workload con- tains single- and multi-row create, read, and update oper- ations as well as basic reporting tasks. The schema can be extended for individual tenants and it can evolve over time. Our previous work with a more limited version of this testbed (no extensions) showed that the performance of Pri- vate Tables degrades if there are too many tables [3]. This effect is due to the large amount of memory needed to hold the metadata as well as an inability to keep index pages in the buffer pool. In this paper, we create only a moderate number of tables, take Private Tables as the baseline, and use it to compare the other mappings. This paper is organized as follows. Section 2 describes our multi-tenant database testbed and the CRM application that it simulates. Section 3 describes the schema mapping techniques. Section 4 presents the results of our experi- ments. Section 5 concludes that the ideal database for SaaS LineItem Product Case Contract Lead Opportunity Asset Contact Campaign Account Figure 1: CRM Application Schema has not yet been developed and offers some suggestions as to how it should be designed. 2. MULTI-TENANT DATABASE TESTBED The experiments in this paper are based on a multi-tenant database testbed we have developed that can be adapted for different database configurations. Each configuration re- quires a plug-in to the testbed that transforms abstract ac- tions into operations that are specific to and optimized for the target database. The testbed simulates a simple but realistic CRM ser- vice. Figure 1 shows the entities and relationships in the base schema. The base entities are extended with additional fields of various types for each tenant. Tenants have different sizes and tenants with more data have more extension fields, ranging from 0 to 100. The characteristics of the dataset are modeled on salesforce.comì°½í²s published statistics [13]. The testbed has nine request classes. The distribution of these requests is controlled using a mechanism similar to TPCì°½í²s card decks. Select 1: Select all attributes of a single entity as if it was being displayed in a detail page in the browser. Select 50: Select all attributes of 50 entities as if they were being displayed in a list in the browser. Select 1000: Select all attributes of the first 1000 entities as if they were being exported through a Web Services interface. Reporting: Run one of five reporting queries that perform aggregation and/or parent-child-roll-ups. Insert 1: Insert one new entity instance as if it was being manually entered into the browser. Insert 50: Insert 50 new entity instances as if data were being synchronized through a Web Services interface. Insert 1750: Insert 1750 new entity instances as if data were being imported through a Web Services interface. Update 1: Update a single entity as if it was being modi- fied in an edit page in the browser. Update 100: Update 100 entity instances as if data were being synchronized through a Web Services interface. The testbed mimics a typical application serverì°½í²s behav- ior by creating a configurable number of connections to the database backend. To avoid blockings, the connections are distributed among a set of worker hosts, each of them han- dling a few connections only. Distributing these connec- tions among multiple hosts allows for modeling various sized, multi-threaded application servers. 882 3. SCHEMA MAPPING TECHNIQUES Within a SaaS application, each tenant has a logical sche- ma consisting of the base schema and a set of extensions. To implement multi-tenancy, the logical schemas from mul- tiple tenants are mapped into one physical schema in the database. The mapping layer transforms queries against the logical schemas into queries against the physical schema so multi-tenancy is transparent to application programmers. The physical schemas for the five mapping techniques stud- ied in this paper are illustrated in Figure 2. The example data set used in this Figure is most clearly shown in the Pri- vate Tables mapping (Figure 2(a)). There are three tenants ? 17, 35, and 42 ? each of which has an Account table with Account ID (Aid) and Name fields. Tenant 17 has extended the Account table with two fields for the health care indus- try: Hospital and Beds. Tenant 42 has extended the Account table with one field for the automotive industry: Dealers. In the Extension Tables mapping (Figure 2(b)), the industry extensions are split off into separate tables that are joined to the base Account table using a new Row number column (Row). Tenants share the tables using a tenant ID column (Tenant). This section describes the other three mappings in more detail. 3.1 Sparse Columns in Microsoft SQL Server Sparse Columns were originally developed to manage data such as parts catalogs where each item has only a few out of thousands of possible attributes. Storing such data in con- ventional tables with NULL values can decrease performance even with advanced optimizations for NULL handling. To implement Sparse Columns, SQL Server 2008 uses a variant of the Interpreted Storage Format [4, 7], where a value is stored in the row together with an identifier for its column. In our mapping for SaaS, the base tables are shared by all tenants and every extension field of every tenant is added to the corresponding base table as a Sparse Column, as il- lustrated in Figure 2(c). Sparse columns must be explicitly defined by a CREATE/ALTER TABLE statement in the DDL and, in this sense, are owned by the database. Nev- ertheless, the application must maintain its own description of the extensions, since the column names cannot be stati- cally embedded in the code. For writes, the application must ensure that each tenant uses only those columns that they have declared, since the namespace is global to all tenants. For reads, the application must do an explicit projection on the columns of interest, rather than doing a SELECT ?, to ensure that NULL values are treated correctly. Sparse Columns requires only a small, fixed number of tables, which gives it a performance advantage over Pri- vate Tables; [3] shows that having many tables negatively impacts performance. On the other hand, there is some overhead for managing Sparse Columns. As an example, the SQL Server documentation recommends using a Sparse Column for an INT field only if at least 64% of the values are NULL [15]. Both of these factors are reflected in the performance results presented in Section 4. 3.2 XML in IBM DB2 IBM pureXML was designed to allow processing of semi- structured data alongside of structured relational data [20]. The mapping for SaaS that we use follows the recommenda- tions in the pureXML documentation for supporting multi- tenancy [21]. The base tables are shared by all tenants and Account17 Aid Name Hospital Beds 1 Acme St. Mary 135 2 Gump State 1042 Account35 Aid Name 1 Ball Account42 Aid Name Dealers 1 Big 65 (a) Private Tables AccountExt Tenant Row Aid Name 17 0 1 Acme 17 1 2 Gump 35 0 1 Ball 42 0 1 Big HealthcareAccount Tenant Row Hospital Beds 17 0 St. Mary 135 17 1 State 1042 AutomotiveAccount Tenant Row Dealers 42 0 65 (b) Extension Tables Account Tenant Aid Name SPARSE 17 1 Acme Hospital St. Mary Bed 135 17 2 Gump Hospital State Bed 1042 35 1 Ball 42 1 Big Dealer 65 (c) Sparse Columns Account Tenant Aid Name Ext XML 17 1 Acme <ext><hospital>St. Mary</hospital> <beds>135</beds></ext> 17 2 Gump <ext><hospital>State</hospital> <beds>1042</beds></ext> 35 1 Ball 42 1 Big <ext><dealers>65</dealers></ext> (d) XML RowKey Account Contact 17Act1 [name:Acme, hospital:St. Mary, beds:135 ] 17Act2 [name:Gump, hospital:State, beds:1042 ] 17Ctc1 [íì¨ íì¨ íì¨ ] 17Ctc2 [íì¨ íì¨ íì¨ ] 35Act1 [name:Ball] 35Ctc1 [íì¨ íì¨ íì¨ ] 42Act1 [name:Big, dealers:65 ] (e) Pivot Tables Figure 2: Schema Mapping Techniques each base table is augmented by a column (Ext XML) that stores all extension fields for a tenant in a flat XML docu- ment, as illustrated in Figure 2(d). Since these documents necessarily vary by tenant, they are untyped. This repre- sentation keeps the documents as small as possible, which is an important consideration for performance [16]. pureXML offers a hybrid query language that provides native access to both the structured and semi-structured representations. Our testbed manipulates data in the struc- tured format, thus accessing extension data requires a corre- lated subquery to manage the XML. This subquery extracts the relevant extension fields using the XMLTABLE function which converts an XML document into a tabular format us- ing XPath. The query with the XMLTABLE function has 883 SELECT b.Tenant, b.Aid, b.Name, e.Dealers FROM Accounts b, XMLTABLE(ì°½í²i/extì°½í² PASSING b.Ext_XML AS ""i"" COLUMNS Dealers INTEGER PATH ì°½í²dealersì°½í² ) AS e WHERE Tenant = 42 AND Aid = 1; (a) Physical SELECT Query accounts tid,aid IXSCAN XSCANFETCH NLJOIN accounts RETURN (b) Query Execution Plan Figure 3: Correlated Subquery for XML in DB2 to be generated client- and query-specific to access clientsì°½í² extension fields relevant in the particular query. Figure 3(a) shows an example query against the physical schema that selects three base fields and one extension field; Figure 3(b) shows the associated query plan. In our testbed, rows are always accessed through base fields, hence there is no need to use the special XML indexes offered by pureXML [20]. To insert a new tuple with extension data, the application has to generate the appropriate XML document; our per- formance results generally include the time to perform this operation. Updates to extension fields are implemented us- ing XQuery 2.0 features to modify documents in place. 3.3 Pivot Tables in HBase HBase [11], which is an open source version of Google BigTable [6], was originally designed to support the explo- ration of massive web data sets. These systems are increas- ingly being used to support enterprise applications in a SaaS setting [14]. In an HBase table, columns are grouped into column fam- ilies. Column families must be explicitly defined in advance in the HBase ì°½íµDDLì°½í¶, for this reason they are owned by the database. There should not be more than tens of column families in a table and they should rarely be changed while the system is in operation. Columns within a column family may be created on-the-fly, hence they are owned by the ap- plication. Different rows in a table may use the same column family in different ways. All values in a column are stored as Strings. There may be an unbounded number of columns within a column family. Data in a column family is stored together on disk and in memory. Thus, a column family is essentially a Pivot Table; each value is stored along with an identifier for its column in a tall narrow table [2]. HBase was designed to scale out across a large farm of servers. Rows are range-partitioned across the servers by key. Applications define the key structure, therefore implic- itly control the distribution of data. Rows with the same key SELECT p.Name, COUNT(c.Case_id) AS cases FROM Products p, Assets a, Cases c WHERE c.Asset = a.Asset_id AND a.Product = p.Product_id GROUP BY p.Name ORDER BY cases DESC Figure 4: Logical Reporting Query prefix will be adjacent but, in general, may end up on differ- ent servers. The rows on each server are physically broken up into their column families. The mapping for SaaS that we use is illustrated in Fig- ure 2(e). In keeping with best practices for HBase, this map- ping ensures that data that is likely to be accessed within one query is clustered together. A single HBase table is used to store all tables for all tenants. The physical row key in HBase consists of the concatenation of the tenant ID, the name of the logical table, and the key of the row in the log- ical table. Each logical table is packed into its own column family, thus each row has values in only one column family. Within a column family, each column in the logical table is mapped into its own physical HBase column. Thus, since columns are dynamic, tenants may individually extend the base tables. The reporting queries in our testbed require join, sort and group operations, which are not currently provided by HBase. We therefore implemented these operators outside the database in an adaptation layer that runs in the client. The adaptation layer utilizes operations in the HBase client API such as update single-row, get single-row and multi-row scan with row-filter. As an example, consider the reporting query shown in Figure 4, which produces a list of all Prod- ucts with Cases by joining through Assets. To implement this query, our adaptation layer scans through all Cases for the given tenant and, for each one, retrieves the associated Asset and Product. It then groups and sorts the data for all Cases to produce the final result. In our experiments, HBase was configured to run on a sin- gle node and the Hadoop distributed map-reduce framework was not employed. In our experience, hundreds of tenants for an application like CRM can be managed by a database on a single commodity processor. In this setting, spreading the data for a tenant across multiple nodes and doing dis- tributed query processing would not be advantageous; the overhead for managing the distribution would nullify any benefits of parallelization. Of course, in addition to scal- ing up to handle many small tenants, the ideal SaaS data- base should also scale out to handle large tenants. But even in this case, map-reduce is problematic for queries such as the one in Figure 4, since it requires that data be clustered around Products. Other queries, such as pipeline reports on Opportunities, might require that the data be clustered in other ways. We conclude this section with several comments about the usage of HBase in our experiments. First, HBase offers only row-at-a-time transactions and we did not add a layer to extend the scope to the levels provided by the commer- cial databases. Second, compression of column families was turned off. Third, neither major nor minor compactions oc- curred during any of the experiments. Fourth, replication of data in the Hadoop file system was turned off. Fifth, column families were not pinned in memory. Sixth, the system was configured so that old attribute values were not maintained. 884  1  10  100  1000  10000  100000 Sel 1 Sel 50 Sel 1000 R eport Ins 1 Ins 50 Ins 1750 U pd 1 U pd 100 R e s p o n s e  T im e  [ m s e c ] Query Classes Private Tables Extension Tables Sparse Column (a) Overall  1  10  100  1000  10000  100000 Sel 1 Sel 50 Sel 1000 R eport Ins 1 Ins 50 Ins 1750 U pd 1 U pd 100 R e s p o n s e  T im e  [ m s e c ] Query Classes Priv. Table (Small Tenant) Priv. Table (Medium Tenant) Priv. Table (Large Tenant) Sparse (Small Tenant) Sparse (Medium Tenant) Sparse (Large Tenant) (b) By Tenant Size Figure 5: SQL Server Performance 4. EXPERIMENTAL RESULTS This section presents the results of our experiments on schema extensibility and evolution. To study schema evolu- tion, we issued a series of schema alteration statements dur- ing a run of the testbed and measured the drop in through- put. The experiments were run on Microsoft SQL Server 2008, IBM DB2 V.9.5 on Windows 2008, and HBase 0.19 on Linux 2.6.18 (CentOS 5.2). The database host was a VM on VMWare ESXi with 4 3.16 GHz vCPUs and 8 GB of RAM. 4.1 Microsoft SQL Server Figure 5(a) shows the results of running our testbed on Microsoft SQL Server using three different mappings: Pri- vate Tables, Extension Tables, and Sparse Columns. The horizontal axis shows the different request classes, as de- scribed in Section 2, and the vertical axis shows the response time in milliseconds on a log scale. In comparison to Private Tables, Extension Tables clearly exhibits the effects of vertical partitioning: wide reads (Sel 1, Sel 50, Sel 1000) are slower because an additional join is re- quired, while narrow reads (Report) are faster because some unnecessary loading of data is avoided. Updates (Upd 1, Upd 100) perform similarly to wide reads because our tests modify both base and extension fields. Extension Tables is faster for inserts because tables are shared among tenants so there is a greater likelihood of finding a page in the buffer pool with free space. Sparse Columns performs as well or better than Private Tables in most cases. The additional overhead for managing the Interpreted Storage Format appears to be offset by the fact that there are fewer tables. Sparse Columns performs worse for large inserts (Ins 1750), presumably because the implementation of the Interpreted Storage Format is tuned to favor reads over writes. Figure 5(b) shows a break down of the Private Table and Sparse Column results by tenant size. Recall from Section 2 that larger tenants have more extension fields, ranging from 0 to 100. The results show that the performance of both mappings decreases to some degree as the number of exten- sion fields goes up. SQL Server permits up to 30,000 Sparse Columns per ta- ble. Our standard configuration of the testbed has 195 ten- ants, which requires about 12,000 columns per table. We also tried a configuration with 390 tenants and about 24,000 columns per table and there was little performance degra- dation. The number of extension fields per tenant in our testbed is drawn from actual usage, so SQL Server is unlikely to be able to scale much beyond 400 tenants. As a point of comparison, salesforce.com maintains about 17,000 tenants in one (very large) database [13]. Figures 6(a) and 6(b) show the impact of schema evolu- tion on throughput in SQL Server. In these graphs, the horizontal axis is time in minutes and the vertical axis is transactions per minute. The overall trend of the lines is downward because data is inserted but not deleted during a run. Part way through each run, ALTER TABLE state- ments on 5 base tables were submitted. The first two lines in each graph show schema-only DDL statements: add a new column and increase the size of a VARCHAR column. The third line in each graph shows a DDL statement that affects existing data: decrease the size of a VARCHAR column. To implement this statement, SQL Server scans through the table and ensures that all values fit in the reduced size. A more realistic alteration would perform more work than this, so the results indicate a lower bound on the impact of evo- lution. The gray bar on each graph indicates the period during which this third operation took place. In the Private Tables case (Figure 6(a)), 975 ALTER TA- BLE statements were submitted, 5 for each of the 195 ten- ants. Individual schema-only alterations completed very rapidly, but nevertheless had an impact on throughput be- cause there were so many of them. Adding a new column took about 1 minute to complete while increasing the size of a VARCHAR column took about 3 minutes. Decreasing the size of a VARCHAR column took about 9 minutes and produced a significant decrease in throughput. The overall loss of throughput in each case is indicated by the amount of time it took to complete the run. In the Sparse Columns case (Figure 6(b)), the tables are shared and 5 ALTER TABLE statements were submitted. The schema-only changes completed almost immediately and had no impact on throughput. Decreasing the size of a VAR- CHAR column took about 2 minutes, during which through- 885  0  2000  4000  6000  8000  10000  12000  14000  16000  0 5 10 15 20 25 30 T ra n s a c ti o n s  p e r  M in u te Testbed runtime (min) Add new column Increase VARCHAR size Decrease VARCHAR size (a) Private Tables  0  2000  4000  6000  8000  10000  12000  14000  16000  0 5 10 15 20 25 30 T ra n s a c ti o n s  p e r  M in u te Testbed runtime (min) Add new column Increase VARCHAR size Decrease VARCHAR size (b) Sparse Columns Figure 6: SQL Server Throughput put dropped almost to zero. The overall loss of throughput was greater for Private Tables, as indicated by the amount of time it took to complete the runs. However the behavior of Private Tables is probably preferable in the SaaS setting be- cause the throughput drop is never as deep, thus the servers donì°½í²t need to be overprovisioned as much. In any case, nei- ther of these mappings is ideal in that the application should have more control over when such resource-intensive opera- tions occur. 4.2 IBM DB2 Figure 7(a) shows the results of running our testbed on IBM DB2 using three different mappings: Private Tables, Extension Tables, and XML using pureXML. The axes are the same as in Figure 5. In comparison to Private Tables, Extension Tables ex- hibits the same performance variations as in SQL Server. However XML produces a decrease in performance in most cases. The decrease is particularly severe for reads, which re- quire executing a correlated subquery containing an XQuery statement embedded in a call to the XMLTABLE function, as described in Section 3.2. Figure 7(b) shows a break down of the Private Table and XML results by tenant size. Re-  1  10  100  1000  10000  100000 Sel 1 Sel 50 Sel 1000 R eport Ins 1 Ins 50 Ins 1750 U pd 1 U pd 100 R e s p o n s e  T im e  [ m s e c ] Query Classes Private Tables Extension Tables XML (a) Overall  1  10  100  1000  10000  100000 Sel 1 Sel 50 Sel 1000 R eport Ins 1 Ins 50 Ins 1750 U pd 1 U pd 100 R e s p o n s e  T im e  [ m s e c ] Query Classes Private Table (Small Tenant) Private Table (Medium Tenant) Private Table (Large Tenant) XML (Small Tenant) XML (Medium Tenant) XML (Large Tenant) (b) By Tenant Size Figure 7: DB2 Performance call from Section 2 that larger tenants have more extension fields, ranging from 0 to 100. The results show that for reads, the performance decrease of XML is proportional to the number of extension fields. Note that in the Insert 1750 case, the results do not include the time to construct the XML document (for no particularly good reason) and there is no variation based on tenant size. XML gives the application complete control over schema evolution. In this setting, the application is responsible for performing any bulk transformations associated with schema alterations that impact existing data. To st",Stefan Aulbach,"Technische Universit?t M?nchen, Germany",stefan.aulbach@in.tum.de,Dean Jacobs,"SAP AG, Walldorf, Germany",dean.jacobs@sap.com,Alfons Kemper,"Technische Universit?t M?nchen, Germany",alfons.kemper@in.tum.de,Michael Seibold,"Technische Universit?t M?nchen, Germany",michael.seibold@in.tum.de,,,,,,,,,,,,,,,,,,
20200104,1126,Orestis Polychroniou,Columbia University,orestis@cs.columbia.edu,,A Comprehensive Study of Main-Memory Partitioning and its Application to Large-Scale Comparison- and Radix-Sort,"ABSTRACT Analytical database systems can achieve high throughput main-memory query execution by being aware of the dynam- ics of highly-parallel modern hardware. Such systems rely on partitioning to cluster or divide data into smaller pieces and thus achieve better parallelism and memory locality. This paper considers a comprehensive collection of variants of main-memory partitioning tuned for various layers of the memory hierarchy. We revisit the pitfalls of in-cache parti- tioning, and utilizing the crucial performance factors, we in- troduce new variants for partitioning out-of-cache. Besides non-in-place variants where linear extra space is used, we introduce large-scale in-place variants, and propose NUMA- aware partitioning that guarantees locality on multiple pro- cessors. Also, we make range partitioning comparably fast with hash or radix, by designing a novel cache-resident index to compute ranges. All variants are combined to build three NUMA-aware sorting algorithms: a stable LSB radix-sort; an in-place MSB radix-sort using different variants across memory layers; and a comparison-sort utilizing wide-fanout range partitioning and SIMD-optimal in-cache sorting. To the best of our knowledge, all three are the fastest to date on billion-scale inputs for both dense and sparse key domains. As shown for sorting, our work can serve as a tool for build- ing other operations (e.g., join, aggregation) by combining the most suitable variants that best meet the design goals. 1. INTRODUCTION The increasing main-memory capacity of contemporary hardware allows query execution to occur entirely in mem- ory. If the entire database also fits in RAM, analytical query workloads that are typically read-only need no disk access after the initial load, setting the memory bandwidth as the only performance bound. Since analytics are at the core of business intelligence tasks today, the need for high- throughput main-memory query execution is apparent. ?This work was supported by National Science Foundation grant IIS-0915956 and a gift from Oracle Corporation. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re- publish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGMOD  íí14, June 22?27, 2014, Snowbird, UT, USA. Copyright 2014 ACM 978-1-4503-2376-5/14/06 ...$15.00. http://dx.doi.org/10.1145/2588555.2610522. To maximize memory bandwidth and capacity, a few CPUs can be combined in a shared-memory system using a fast interconnection. Such hardware combines the parallelism of multiple multi-core CPUs with a higher aggregate memory bandwidth. The shared-memory functionality is provided by the non-uniform-memory-access (NUMA) interconnection, adding an additional layer in the memory hierarchy. In a modern multi-core CPU, the best performance is achieved when all cores work in a shared-nothing fashion and the working set is small enough to fit in the fast (and private per core) caches. The same approach was more effi- cient even before the advent of the multi-core era [11], since random RAM accesses are too expensive out-of-cache. Query execution is decomposed into a series of operations, the most time consuming of which are typically joins and aggregations. To speed up these operations using hardware parallelism, we partition into small pieces using the keys, then process each piece independently. For instance, an effi- cient algorithm for joins is to hash partition in parallel until the input is split into cache resident pieces before we execute the join using a hash table [11]. In fact, even in-cache join can further partition into trivial parts with very few distinct items, before executing a nested loop to join them [7]. This paper considers a comprehensive menu of partition- ing options across several dimensions. The three types of partitioning are hash, radix and range partitioning, depend- ing on the function that takes the key as an input and out- puts the destination partition. Partitioning also depends on the layer of the memory hierarchy that it targets, namely in-cache, out-of-cache and across NUMA regions. Finally, we distinguish partitioning variants based on whether they use auxiliary space that is linear to the input size or not. Until recently, prior work used the in-cache versions of partitioning and, if parallel, the non-in-place variant, which can be trivially distributed across threads. In all cases, when the input is larger than the cache, the performance is throt- tled by TLB misses [11] and cache conflicts [14]. Satish et al. [14] suggested in-cache buffering to mitigate TLB misses and Wassenberg et al. [15] used non-temporal writes on cache line sized buffers to facilitate hardware write-combining. Efficient out-of-cache partitioning [14, 15] assumes free access to linear auxiliary space, to write the output. We introduce several in-place out-of-cache partitioning variants utilizing the same crucial performance factors: an in-place method analogous to the shared-nothing non-in-place method; a modified non-in-place method that generates the output as a list of blocks that overwrites the input; and a parallel non-in-place method that combines the previous two. 755 To support scaling to multiple CPUs, we consider how the NUMA layer affects partitioning performance and modify both in-place and non-in-place out-of-cache partitioning to guarantee minimal transfers across NUMA boundaries, also ensuring sequential accesses so that hardware pre-fetching can hide the latency of the NUMA interconnection [1]. All of the above algorithms target the data shuffling part of partitioning and implicitly assume that the partition func- tion is cheap and can be computed at virtually no cost. While this assumption holds for radix and hash partitioning given a suitable hash function choice, the cost of computing a range partition function is higher than the cost to transfer the tuple, especially when the number of partitions increases beyond the TLB capacity. The standard (and slow) imple- mentation is a binary search in a sorted array of delimiters that define the partition ranges. The slowdown is caused by the logarithmic number of cache loads. We introduce a specialized SIMD-based cache-resident index that speeds up range function computation up to 6 times and makes range partitioning a practical choice for many applications. All partitioning variants discussed in this paper are shown in Figure 1, where we also mark our contributions. We ap- ply all variants to design and implement three large-scale NUMA-aware sorting algorithms. We use sorting, rather than joins or aggregations for two reasons. First, because it is a wider problem that can be a sub-problem for both join and aggregation. Second, we can apply all partitioning variants to build unique sorting algorithms, such that each is more scalable in distinct cases depending on input size, key domain size, space requirements, and skew efficiency. The first sorting algorithm we propose is stable least- significant-bit (LSB) radix-sort based on non-in-place out- of-cache radix partitioning [14] where we add two innova- tions. We use hybrid range-radix partitioning to provide perfect load balancing, and guarantee that each tuple will cross NUMA boundaries at most once, even if the algorithm would by default re-organize the entire array in each pass. The second sorting algorithm we propose is an in-place most-significant-bit (MSB) radix-sort that uses all variants of in-place partitioning that we introduce, one for each dis- tinctive level in the memory hierarchy: shared out-of-cache in-place partitioning, shared-nothing out-of-cache partition- ing, and in-cache partitioning. We reuse the range-radix idea of LSB radix-sort for NUMA optimality and load balancing. The third sorting algorithm we propose is a comparison- sort that uses the newly optimized range partitioning. We perform very few out-of-cache range partitioning passes with a very wide fanout until we reach the cache, providing NUMA optimality. In the cache, we employ sorting [6] that scales to the SIMD length, modified to use the cache more effectively. radix hash range partition in-cache non-in-place out-of-cache out-of-cache in-place in-cache shared in block lists in segments sharedshared-nothing NUMA oblivious NUMA aware previously known our contributions Figure 1: Partitioning variants and contributions We use fixed length integer keys and payloads, typical of analytical database applications. We evaluate on both dense and sparse key domains. If order-preserving compression is used [12, 16], any sparse or dense domain with fixed or vari- able length data is compacted into a dense integer domain. Skewed workload distribution can reduce parallelism in some na?íì§¤íì§ve approaches. In our context, when we statically distribute partitions to threads, we ensure that the parti- tions are as balanced as possible. Specifically, we never use radix partitioning to any range of bits to divide the work- load. Instead, we combine range with radix partitioning to guarantee that, if specific bit ranges have very few distinct values, we can find delimiters that split the workload equally among threads, independently of the key value range. We summarize our contributions: ? We introduce several new variants for main-memory partitioning, most notably large-scale in-place parti- tioning and efficient range partitioning, and also guar- antee minimal NUMA transfers across multiple CPUs. ? We combine partitioning variants to design three sort- ing algorithms, all the fastest of their class for billion- scale inputs, and evaluate the best options depending on input size, key domain, available space, and skew. The rest of the paper is organized as follows. Section 2 outlines related work. In Section 3 we describe partitioning variants. In Section 4 we discuss sorting. Section 5 presents our experimental results, and we conclude in Section 6. 2. RELATED WORK We first outline related work on partitioning. Manegold et al. [11] identified the TLB thrashing problem when na?íì§¤íì§vely partitioning to a large number of outputs. Satish et al. [14] introduced efficient out-of-cache partitioning and Wassen- berg et al. [15] identified the significance of write-combining. Manegold et al. [11] proposed partitioning to cache-resident hash tables to join and Kim et al. [7] reused the same design on a multi-core CPU. Wu et al. [17] proposed hardware ac- celerated partitioning for performance and power efficiency. We briefly outline recent work on sorting for modern hard- ware, due to space constraints. Inoue et al. [6] proposed in- cache SIMD-vector comb-sort followed 2-way SIMD merg- ing. Chhugani et al. [5] proposed in-cache sorting networks followed by cyclic merging in buffers to avoid being memory bound. Kim et al. [7] compared sort-merge-join against hash join, projecting that sort-merge-join will eventually outper- form hash with wider SIMD. Satish et al. [14] compared radix-sort and merge-sort in CPUs and GPUs on multiple key domain sizes and concluded in favor of merge-sort. How- ever, the result is based on small arrays and only LSB radix- sort is considered. Wassenberg et al. [15] improved over Satish et al. [14] and claimed that radix-sort is better. Kim et al. [9] studied network-scale sorting maximizing network transfer with CPU computation overlap. Albutiu et al. [1] studied the NUMA effects using sort-merge-join on multiple CPUs with billion-scale arrays. Balkesen et al. [4] claimed that non-partitioning hash joins are competitive, but Balke- sen et al. [3] improved over Blanas et al. [4] and concluded that partitioning joins are generally faster, even without us- ing fast partitioning [14, 15]. Balkesen et al. [2] further im- proved joins on multiple CPUs using fast partitioning. Thus, on the fastest CPUs [3], partitioning appears to be the best choice for both hash joins and radix-sort-merge-joins. 756 3. PARTITIONING 3.1 In-Cache We start by considering the versions that best operate when the table fits in the cache. The non-in-place version (Algorithm 1) uses a separate array from the input to store the output, while the in-place version (Algorithm 2) uses one array for both input and output. Each partition is generated in a single segment. In-cache partitioning can be run in parallel, if the threads operate in a shared-nothing fashion. Algorithm 1 Non-in-place in-cache partitioning i íì§  0 // P : the number of partitions for p íì§  0 to P -1 do offset[p] íì§  i // point at the start of each partition i íì§  i + histogram[p] end for for iin  íì§  0 to |Tin|-1 do t íì§  Tin[iin] // Tin: the input table iout  íì§  offset[f(t.key)] + + // f : the partition function Tout[iout] íì§  t // Tout: the output table end for The simplest non-in-place version does only two random accesses per item. When operating in the cache, we need the output and the offset array to be cache-resident. A slightly more complicated version of the algorithm allows the parti- tioning to happen in-place, by swapping items across loca- tions. In short, we start by reading an item, find the correct partition and the output destination through the offset ar- ray, swap it with the item stored there, and continue for the new item until the cycle is closed. Each item is moved exactly once and we stop when the whole array is covered. Item swaps are performed in cycles of transfers, defined as swap cycles. When the items are processed low-to-high [1], the cycle starts by doing a read and then swaps until it reaches the same location it initially read from, to write back. This case occurs 1/P of time on average but requires branching. In Algorithm 2 below, the partitions are written high-to-low and swap cycles close when all items of a parti- tion have been placed, avoiding branching for every tuple. Algorithm 2 In-place in-cache partitioning i íì§  0 // P : the number of partitions for p íì§  0 to P -1 do i íì§  i + histogram[p] offset[p] íì§  i // point at the end of each partition end for p íì§  iend  íì§  0 while histogram[p] = 0 do p+ + // skip initial empty partitions end while repeat t íì§  T [iend] // T : the input & output table repeat p íì§  f(t.key) // f : the partition function i íì§  ??offset[p] T [i] íì§§ t // swap until i = iend repeat iend  íì§  iend + histogram[p+ +] // skip if empty until p = P or iend 6= offset[p] until p = P 3.2 Out-of-Cache Out-of-cache performance is throttled by increased cache conflicts [14] and cache pollution with output tuples [15]. TLB thrashing occurs when the number of partitions ex- ceeds the TLB capacity [11], unless the entire dataset can be placed in equally few large OS pages to be TLB resident. 3.2.1 Non-in-place To mitigate these problems, prior work [14] proposed using the cache as an intermediate buffer before writing back to memory. Also, when write backs occur, they bypass the higher cache levels entirely and avoid polluting the cache [15]. Recent work [2] uses the same basic technique for out- of-cache radix partitioning during hash join execution. Buffering data for each partition reduces the working set size and eliminates the TLB problem when operating in the buffer. TLB misses still occur, but 1/L of the time, if L is the number of tuples buffered for each partition before writing to output. If the buffer for each partition is exactly as big as a cache line, writing the full cache line to memory is accel- erated by write-combining and avoids polluting the higher cache levels with output data. The partitioning fanout is now bounded by the number of cache lines in the fast core- private cache, rather than the TLB entries. Buffer flushing is optimally done using wider registers [15]. To maximize the cache use, we use the last buffer slot to save the output offset and access one cache line per iteration (Algorithm 3). To extend the above method to multiple columns stored in separate arrays, the standard case in RAM-resident database data, we use one cache line per column in the buffer of each partition. A generic implementation can use one cache line per column and flush it separately depending on the column width. We can also interleave the columns in a single tuple and de-interleave the columns when the buffer is flushed. For example, when partitioning arrays of 32-bit keys and 32-bit payloads, we store 64-bit tuples in the cached buffer. Tuple (de-)interleaving can be accelerated using SIMD. Parallel execution of the non-in-place out-of-cache parti- tioning is trivial. The input can be split to equal pieces, one for each thread. By executing a prefix sum of all individ- ual histograms, one can ensure that each partition output is written in a distinct location. Threads are only synchronized after individual histograms are built. This is the only known technique for parallel partitioning on shared segments. Algorithm 3 Non-in-place out-of-cache partitioning iout  íì§  0 // P : the number of partitions for p íì§  0 to P -1 do buffer[p][L-1] íì§  iout // L: # of tuples per cache line iout  íì§  iout + histogram[p] end for for iin  íì§  0 to |Tin|-1 do t íì§  Tin[iin] // Tin/Tout: the input/output table p íì§  f(t.key) // f : the partition function iout  íì§  buffer[p][L-1] + + buffer[p][iout mod L] íì§  t if iout mod L = L-1 then for ibuf  íì§  0 to L-1 do Tout[iout + ibuf ? L] íì§  buffer[p][ibuf ] // no cache end for buffer[p][L-1] íì§  iout + 1 end if end for 757 3.2.2 In-place, Shared-Nothing Segments Adapting the out-of-cache buffering technique to in-place partitioning requires a more complicated approach. The ba- sic idea is to perform the swaps inside the buffer, so that the sparse RAM locations are accessed only 1/L of the time, re- ducing the overhead from TLB misses. Compared with non- in-place out-of-cache partitioning, which uses the buffer as an intermediate layer to group tuples before writing them, in-place out-of-cache partitioning performs all tuples swaps in the buffer, and accesses RAM one cache line at-a-time. Before the main partitioning loop starts, we load cache lines from all starting partition locations. Item swaps be- tween partitions occur using the last L tuples that are stored in the buffer. When a buffer has swapped all L items, the cache line is streamed to the RAM location it was loaded from and the buffer is re-filled with the next L items of the same partition. Thus, we operate in the buffer (L? 1)/L of the time and do not miss in the TLB. The offsets are stored inside the buffer and the last L items of each partition are handled differently to eliminate branching in the inner loop. If having T contiguous segments per partition (T is the number of threads) is acceptable, then we can run in-place partitioning in parallel. However, unlike the non-in-place variant, generating one segment per partition across threads is impossible with coarse-grained synchronization. Algorithm 4 In-place out-of-cache partitioning i íì§  0 // P : the number of partitions for p íì§  0 to P -1 do end[p] íì§  i i íì§  i + histogram[p] for ibuf  íì§  0 to L-1 do buffer[p][ibuf ] íì§  T [i? (i mod L) + ibuf ] end for item0[p] íì§  buffer[p][0] // save 1st item out of buffer buffer[p][0] íì§  i [...] // special handling for partitions smaller than L end for p íì§  0 while histogram[p] = 0 do p+ + // skip initial empty partitions end while t íì§  T [0] // T : the input & output table loop repeat p íì§  f(t.key) // f : the partition function i íì§  ??buffer[p][0] buffer[p][i mod L]  íì§§ t // swap until i mod L = 0 // L: # of tuples per cache line [...] // (rare) branch for end of partition (exits here) for ibuf  íì§  0 to L-1 do T [i] íì§  buffer[p][ibuf ] // no cache end for for ibuf  íì§  0 to L-1 do buffer[p][ibuf ] íì§  T [i? L] // cache end for t íì§  item0[p] item0[p] íì§  buffer[p][0] buffer[p][0] íì§  i if i ? end[p] < L then [...] // (rare) branch for last L items of partition end if end loop 3.2.3 In-place, List of Blocks For large-scale out-of-cache partitioning, the requirement of producing all partitions in P non-splitting segments can be relaxed. Instead of writing each partition output sequen- tially, we can write large blocks that only contain items from a single partition. When the block is full, we get a new block at some new available location. The block size must be large enough to amortize sequential writes, but not too large, in order to avoid external fragmentation from non-full blocks. To access data from a single partition only, we create a small linked list that connects all blocks that contain data of the same partition. While the access is not entirely se- quential as in the single segment case, the list hops after scanning each block are amortized by a sufficient block size. This method can be done in place, if we remove P  íì§B items from the start of the input and save it in private space (B is the block capacity in tuples). We start range partitioning the input from the (P  íì§B)-th tuple. By the time any partition is filled, the input pointer will have advanced enough for the output to safely use the space of input we read before, without overwriting tuples not yet read. At the end, we also add the data initially copied out back to the correct block lists. For each partition, only the last block of the block list can be non-full. Thus, unused space has an upper bound of P  íì§B and is negligible compared to size of the input. Block-based partitioning has a number of nice properties. First, it uses the fast non-in-place out-of-cache partition- ing. Second, it does not require the pre-computation of a histogram. Third, it can be done in place by ensuring no overlap between input and output data. Finally thread par- allelism is trivial; the only requirement is to connect the linked lists of blocks from all threads for each partition. 3.2.4 In-place, Shared Segments In order to partition and shuffle data in parallel inside the same segment, we need fine-grain synchronization. Since us- ing OS latches are overly expensive, we use atomic instruc- tions. Atomic fetch-and-add reads a memory location, in- crements it by some value and returns its previous value. Imagine an array of items and multiple threads where each item must be processed by exactly one thread. Each thread can safely use item at index i which is returned by invok- ing fetch-and-add(c,1) on a shared counter c. When done, the thread asks for the next item to process or terminates if i exceeds the number of items. We apply the same idea to in-place partitioning using one shared counter for each partition to represent the number of tuples swapped so far. We use fetch-and-add on the shared counter of partition p, to  íì§¸lock íì§¹ the cell of the next yet unread item of partition p. We store the first index that initiates the cycle. After swapping an arbitrary number of keys, when we return to the original partition p, we store the last tuple in the initial location. Only the P counters are shared across threads. As mentioned in Section 3.1, we define a swap cycle as a sequence of swaps that starts by reading a key from a specific partition and after a number of swaps, returns to the same partition to write a key in the initially read location. We cannot know in advance how large a swap cycle will be, thus we cannot lock all locations the cycle will go through before actually moving tuples. Imagine a scenario where the first partition has only one item found in the last cell of the array. Then, one thread would perform a single swap cycle covering all items before the last cell is reached and the cycle is closed. 758 To solve this first problem, threads lock only one location at a time for one swap. However, when close to comple- tion, multiple threads may compete for swap cycles, creating deadlocks. For example, assuming one item per partition, if thread t1 reads item kx (must go to lx) from location ly (must bring ky here) and thread t2 reads kz (must go to lz) from lx (must bring kx here), t1 will find no space for kx, be- cause the offset of partition X was incremented by t2 when it read kz. If t1 waits, t2 will reach ky. Then, a deadlock will occur, since t1 holds (kx, ly) and t2 holds (ky, lx). To solve this second problem and avoid waiting for others, when a thread finds a partition to be full, it records both the current key and the locked location that the swap cycle started from. In the above example, t1 records (kx, ly) and t2 records (ky, lx). A final fix step occurs  íì§¸offline íì§¹ and takes trivial time, as the number of such pairs is upper bounded by the number of partitions P , times the number of threads. So far, we presented a way for multiple threads to partition items in-place concurrently, but this solution is impractical if used as is. First, we make no use of buffering to improve out-of-cache performance and second, for each key we move to its destination, we update a shared variable triggering cache invalidations on every tuple move. To make this ap- proach practical, we change the unit of transfer from tuples to blocks. Each block must have a fixed size and all tuples must belong to the same partition. We generate such blocks using the technique described previously (see Section 3.2.3). Out-of-cache accesses are amortized by the block size, as is the synchronization cost of accessing shared variables. Algorithm 5 Synchronized in-place partitioning Pactive  íì§  {} // Pactive: set of yet unfinished partitions Tdeadlock  íì§  {} // Tdeadlock: set of tuple & location pairs i íì§  0 // P : the number of partitions for p íì§  0 to P -1 do Pactive  íì§  Pactive + {p} offset[p] íì§  i i íì§  i + histogram[p] end for while |Pactive| > 0 do p íì§  any  íì¨ Pactive i íì§  used[p] + + // atomic fetch-and-add if i  íí histogram[p] then Pactive  íì§  Pactive? {p} goto loop-end end if ibeg  íì§  i + offset[p] t íì§  T [ibeg] // T : the input & output table pnext  íì§  f(t.key) // f : the partition function while p 6= pnext do i íì§  used[p] + + // atomic fetch-and-add if i  íí histogram[pnext] then Tdeadlock  íì§  Tdeadlock + {t, iinit} goto loop-end end if i íì§  i + offset[pnext] T [i] íì§§ t // swap pnext  íì§  f(t.key) end while T [ibeg] íì§  t loop-end: end while [...] // handle tuples that could cause deadlock (Tdeadlock) 3.3 Across NUMA Moving RAM-resident data across multiple CPUs raises questions about the effectiveness of NUMA RAM transfers. Accessing remote memory locations goes through an inter- connection channel that issues operations to remote RAM modules, increasing the latency. Normally, random accesses are much slower than sequential access and the gap increases when the accesses reference remote RAM regions and go through the CPU interconnection. Prior work [1] proposed doing sequential accesses to remote memory, since hardware pre-fetching hides the latency. To avoid imbalanced use of the NUMA layer when all transfers are directed to a subset of CPUs, we can pre-schedule the transfers and supervise them via synchronization to ensure load balancing [10]. One way to make NUMA-oblivious code scale on multiple CPUs is to allocate both arrays to be physically interleaved across all RAM regions. The OS can support interleaved al- location, where the physical locations of a single array are in- terleaved across all NUMA regions. Randomization of page placement balances accesses across the NUMA interconnec- tion, but precludes NUMA locality. Thus, if we do random accesses, we pay the extra NUMA latency. Cache-line buffer- ing, used by out-of-cache partitioning to avoid TLB misses and facilitate write-combining, also mitigates the NUMA overhead. Still, we measured out-of-cache partitioning to be up to 55% slower on four NUMA regions on interleaved space. The overhead for single tuple random access is higher. A more NUMA-friendly allocation is to split space into large segments bound to a specific region. We can have one segment per thread or one segment per NUMA region. We use the second approach for sorting (see Section 4.1). 3.3.1 Non-in-place Using NUMA-bound segmented allocation for threads or CPUs and if extra space is allowed, we can ensure that all tuples will cross the NUMA boundaries at most once. We use shared-nothing partitioning locally and then use a sep- arate step to shuffle across CPUs. We can use the NUMA interconnection in a balanced way without manual sched- ules [10]. We distribute each segment across all threads of the destination CPU, and do the transfers in a per thread random order. Since some tuples are already on destination, the expected number of transfers is (x? 1)/x for x regions. The NUMA-oblivious partitioning might perform faster than the two step method of shared-nothing partitioning followed by NUMA shuffling, since out-of-cache partition- ing mitigates latencies. The decision to guarantee minimal transfers by incurring shuffling, depends on the hardware. 3.3.2 In-place Assuming NUMA-bound segmented allocation, the only in-place variant where threads do not work in a shared- nothing fashion is during block shuffling (see Section 3.2.4). During the phase of block shuffling on multiple NUMA re- gions, threads can read and write blocks from all regions, but all",Orestis Polychroniou,Columbia University,orestis@cs.columbia.edu,Kenneth A. Ross,Columbia University,kar@cs.columbia.edu,,,,,,,,,,,,,,,,,,,,,,,,
20200105,1388,Yang Cao,"RCBD and SKLSDE Lab, Beihang University",yang.cao@ed.ac.uk,,Making Pattern Queries Bounded in Big Graphs,"Abstract  It is cost-prohibitive to find matches Q(G) of a pattern query Q in a big graph G. We approach this by fetching a small subgraph GQ of G such that Q(GQ) = Q(G). We show that many practical patterns are effectively bounded under access constraints A commonly found in real life, such that GQ can be identified in time determined by Q and A only, independent of the size |G| of G. This holds no matter whether pattern queries are localized (e.g., via subgraph isomorphism) or non-localized (graph simulation). We provide algorithms to decide whether a pattern Q is effectively bounded, and if so, to generate a query plan that computes Q(G) by accessing GQ, in time independent of |G|. When Q is not effectively bounded, we give an algorithm to extend access constraints and make Q bounded in G. Using real-life data, we experimentally verify the effectiveness of the approach, e.g., about 60% of queries are effectively bounded for subgraph isomorphism, and for such queries our approach outperforms the conventional methods by 4 orders of magnitude. I. INTRODUCTION Given a pattern query Q and a graph G, graph pattern matching is to find the set Q(G) of matches of Q in G. It is used in, e.g., social marketing, knowledge discovery, mobile network analysis, intelligence analysis for identifying terrorist organizations [25], and the study of adolescent drug use [17]. When G is big, graph pattern matching is cost-prohibitive. Facebook has 1.26 billion nodes and 140 billion links in its social graph, about 300PB of user data [28]. When the size |G| of G is 1PB, a linear scan of G takes 1.9 days using SSD with scanning speed of 6GB/s. Worse still, graph pattern matching is intractable if it is defined with subgraph isomorphism [31], and it takes O((|V |+ |VQ|)(|E|+ |EQ|))-time if we use graph simulation [20], where |G| = |V |+|E| and |Q| = |VQ|+|EQ|. Can we still efficiently compute exact answers Q(G) when G is big while we have constrained resources, such as a single processor? We approach this by making big graphs small, capitalizing on a set A of access constraints, which are a combination of indices and simple cardinality constraints defined on the labels of neighboring nodes of G. We determine whether Q is effectively bounded under A, i.e., for all graphs G that satisfy A, there exists a subgraph GQ  íì¨ G such that (a) Q(GQ) = Q(G), and (b) the size |GQ| of GQ and the time for identifying GQ are both determined by A and Q only, independent of |G|. If Q is effectively bounded, we can generate a query plan that for all G satisfying A, computes Q(G) by accessing (visiting and fetching) a small GQ in time independent of |G|, no matter how big G is. Otherwise, we will identify extra access constraints on an input G and make Q bounded in G. A large number of real-life queries are effectively bounded under simple access constraints, as illustrated below. award year movie actressactor country 2011-2013u 1 u 2 u 3 u 4 u 5 u 6 Fig. 1. Pattern query Q0 on IMDb Example 1: Consider IMDb [22], a graph G0 in which nodes represent movies, casts, and awards from 1880 to 2014, and edges denote various relationships between the nodes. An example search on IMDb is to find pairs of first-billed actor and actress (main characters) from the same country who co- stared in a award-winning film released in 2011-2013. The search can be represented as a pattern query Q0 shown in Fig. 1. Graph pattern matching here is to find the set Q0(G0) of matches, i.e., subgraphs G íí of G0 that are isomorphic to Q0; we then extract and return actor-actress pairs from each match G íí. The challenge is that G0 is large: the IMDb graph has 5.1 million nodes and 19.5 million edges. Add to this that subgraph isomorphism is NP-complete. Not all is lost. Using simple aggregate queries one can readily find the following real-life cardinality constraints on the movie dataset from 1880?2014: (1) in each year, every award is presented to no more than 4 movies (C1); (2) each movie has at most 30 first-billed actors and actresses (C2), and each person has only one country of origin (C3); and (3) there are no more than 135 years (C4, i.e., 1880-2014), 24 major movie awards (C5) and 196 countries (C6) in total [22]. An index can be built on the labels and nodes of G0 for each of the constraints, yielding a set A0 of 8 access constraints. Under A0, pattern Q0 is effectively bounded. We can find Q0(G0) by accessing at most 17923 nodes and 35136 edges in G0, regardless of the size of G0, by the following query plan: (a) identify a set V1 of 135 year nodes, 24 award nodes and 196 country nodes, by using the indices for constraints C4-C6; (b) fetch a set V2 of at most 24 íì© 3 íì© 4 = 288 award-winning movies released in 2011?2013, with no more than 288 íì© 2 = 576 edges connecting movies to awards and years, by using those award and year nodes in V1 and the index for C1; (c) fetch a set V3 of at most (30+30)?288 = 17280 actors and actresses with 17280 edges, using V2 and the index for C2; (d) connect the actors and actresses in V3 to country nodes in V1, with at most 17280 edges by using the index for C3. Output (actor, actress) pairs connected to the same country in V1. The query plan visits at most 135 + 24 + 196 + 288 + 17280 = 17923 nodes, and 576 + 17280 + 17280 = 35136 978-1-4799-7964-6/15/$31.00 ? 2015 IEEE ICDE Conference 2015161 edges, using the cardinality constraints and indices in A0, as opposed to tens of millions of nodes and edges in IMDb. 2 This example tells us that graph pattern matching is feasible in big graphs within constrained resources, by making use of effectively bounded pattern queries. To develop a practical ap- proach out of the idea, several questions have to be answered. (1) Given a pattern query Q and a set A of access constraints, can we determine whether Q is effectively bounded under A? (2) If Q is effectively bounded, how can we generate a query plan to compute Q(G) in big G by accessing a bounded GQ? (3) If Q is not bounded, can we make it  íì§¸bounded íì§¹ in G by adding simple extra constraints? (4) Does the approach work on both localized queries (e.g., via subgraph isomorphism) and non-localized queries (via graph simulation)? Contributions. This paper aims to answer these questions for graph pattern matching. The main results are as follows. (1) We introduce effective boundedness for graph pattern queries (Section II). We formulate access constraints on graphs, and define effectively bounded pattern queries. We also show how to find simple access constraints from real-life data. (2) We characterize effectively bounded subgraph queries Q, i.e., patterns defined by subgraph isomorphism (Section III). We identify a sufficient and necessary condition to decide whether Q is effectively bounded under a set A of access con- straints. Using the condition, we develop a decision algorithm in O(|A||EQ|+||A|||VQ|2) time, where |Q| = |VQ|+|EQ|, and ||A|| is the number of constraints in A. The cost is independent of big graph G, and query Q is typically small in practice. (3) We provide an algorithm to generate query plans for effectively bounded subgraph queries (Section IV). After Q is found effectively bounded under A, the algorithm generates a query plan that, given a graph G that satisfies A, accesses a subgraph GQ of size independent of |G|, in O(|VQ||EQ||A|) time. Moreover, we show that the plan is worst-case-optimal, i.e., for each input Q and A, the largest GQ it finds from all graphs G that satisfy A is the minimum among all worst-case GQ identified by all other query plans. (4) If Q is not bounded under A, we make it instance-bounded (Section V). That is, for a given graph G that satisfies A, we find an extension AM of A such that under AM , we can find GQ  íì¨ G in time decided by AM and Q, and Q(GQ) = Q(G). We show that when the size of indices in AM is predefined, the problem for deciding the existence of AM is in low polynomial time (PTIME), but it is log-APX-hard to find a minimum AM . WhenAM is unbounded, all query loads can be made instance- bounded by adding simple access constraints. (5) We extend the study to simulation queries, i.e., patterns interpreted by graph simulation (Section VI). It is more chal- lenging to cope with the non-localized and recursive nature of simulation queries. Nonetheless, we provide a characterization of effectively bounded simulation queries. We also show that our algorithms for checking effective boundedness, generating query plans, and for making queries instance-bounded can be adapted to simulation queries, with the same complexity. (6) We experimentally evaluate our algorithms using real-life data (Section VII). We find that our approach is effective for both localized and non-localized queries: (a) on graphs G of billions of nodes and edges [1], our query plans outperform the conventional methods that computes Q(G) directly by 4 and 3 orders of magnitude on average, for subgraph and simulation queries, respectively, accessing at most 0.0032% of the data in G; (b) 60% (resp. 33%) of subgraph (resp. simulation) queries are effectively bounded under simple access constraints; and (c) all queries can be made instance-bounded in G by extend- ing constraints and accessing 0.016% of extra data in G; and 95% become instance-bounded by accessing at most 0.009% extra data. Our algorithms are efficient: they take at most 37ms to decide whether Q is effectively bounded and to generate an optimal query plan for all Q and constraints tested. This work is the first effort to study effectively bounded graph queries, from fundamental problems to practical algo- rithms. It suggests an approach to querying graphs: (1) given a query Q, we check whether Q is effectively bounded under a set A of access constraints; (2) if so, we generate a query plan that given a graph G satisfying A, computes Q(G) by accessing GQ of size independent of |G|, no matter how big G grows; (3) if not, we make Q instance-bounded in G with extra simple constraints. The approach works for both localized subgraph queries and non-localized simulation queries. Given the prohibitive cost of querying big graphs, this approach helps even when only limited queries are effectively bounded. In fact, we find that many queries on real-life datasets are actually effectively bounded under very simple access constraints. Moreover, when a finite set of queries is not effectively bounded, we can make them instance-bounded. All proofs of the results of the paper can be found in [3]. Related Work. We categorize related works as follows. Effective boundedness. The study of effective boundedness traces back to scale independence. The latter was proposed [5] to approximately answer relational aggregate queries under certain conditions, for key/value stores. It aims to guarantee that a bounded amount of work is required to execute all queries in an application, regardless of the size of the underlying data. The idea was formalized in [12], along with a notion of access constraints for relational queries. Recently, the notion of [12] is revised in [10] by requiring that the amount of data accessed (i.e., GQ) can be identified in time determined by query Q and access constraints A only, referred to as effective boundedness; it is characterized for SPC queries [10]. This work differs from the previous work in the following. (1) We introduce access constraints on graph data, to specify cardinality constraints on the labels of neighboring nodes, and guide us to retrieve small subgraphs GQ. (2) Under such constraints, we formalize and characterize the effective bound- edness of graph patterns, an issue harder than its counterpart for relational queries [10], [12]. (3) We propose instance boundedness for queries that are not effectively bounded. Resource-bounded and anytime algorithms. Related are also resource-bounded [16] and anytime algorithms [32]. The former study reachability queries and personalized pattern queries, in which some pattern nodes are designated to match 162 fixed nodes in a graph G. It is to compute approximate answers by accessing no more than íì§íì§|G| nodes and edges in G, for íì§íì§  íì¨ (0, 1) [16]. Anytime algorithms [32] allow users either to specify a budget on resources (e.g., running time; known as contract algorithms [33]), or to terminate the run of the algorithms at any time and get intermediate answers (known as interruptible algorithms [19]). Contract anytime algorithms have been explored for (a) budgeted search such as bounded- cost planning [4], [29], [30], [32] under a user-specified budget; and (b) graph search via subgraph isomorphism, to find intermediate approximate answers within the budget, either by assigning dynamically maintained budgets and costs to nodes during the traversal [8], or by deciding search orders based on the frequencies of certain features in queries and graphs [27]. This work differs from the prior work as follows. (1) We aim to compute exact answers for pattern queries in big graphs, as opposed to heuristic answers that may not have a provable accuracy bound. (2) We characterize what pattern queries can be answered exactly within a cost independent of the size of big graph, based on access constraints; in contrast, the prior work does not study under what budget accurate answers are warranted by using the semantics of the data. (3) We study general pattern queries, which may be either localized or non- localized, and may not be personalized [16]. Graph indexing and compression. There are typically two ways to reduce search space. (1) Graph indexing uses pre- computed global information of G to compute distance [11], shortest paths [18] or substructure matching [26]. (2) Graph compression computes a summary Gc of a big graph G and uses Gc to answer all queries posed on G [7], [13], [24]. In contrast to the prior work, (1) we compute exact answers rather than heuristic. (2) Instead of using the same graph Gc to answer all queries posed on G, we adopt a dynamic reduction scheme that finds a subgraph GQ of G for each query Q. Since GQ consists of only the information needed for answering Q, it allows us to compute Q(G) by using GQ much smaller than Gc and hence, much less resources. (3) When Q is effectively bounded, for all graphs G we can find GQ of size independent of |G|; in contrast, |Gc| may be proportional to |G|. Making big graphs small. There have been other techniques for reducing a big graph into small ones, e.g., distribute query answering [23], pattern matching using views [15], and incremental pattern matching [14]. These are complementary to this work and can be readily combined with ours, e.g., our methods can be readily adapted to distributed settings. II. EFFECTIVELY BOUNDED GRAPH PATTERN QUERIES In this section we define access schema on graphs and effectively bounded graph pattern queries. We start with a review of graphs and patterns. Assume an alphabet íì§ííª of labels. Graphs. A data graph is a node-labeled directed graph G = (V,E, f, íì§íì§¯), where (1) V is a finite set of nodes; (2) E  íì¨ V íì©V is a set of edges, in which (v, v íí) denotes the edge from v to v íí; (3) f() is a function such that for each node v in V , f(v) is a label in íì§ííª, e.g., year; and (4) íì§íì§¯(v) is the attribute value of f(v), e.g., year = 2011. u 1 Q 1 A B  íì§ u 2 v 1 v 2 v 3 v 2n A AB B G 1 Cu3 Du4 Cv2n+1 Dv2n+2 Fig. 2. Pattern query Q1 and data graph G1 We write G as (V,E) or (V,E, f) when it is clear from the context. The size of G, denoted by |G|, is defined to be the total number of nodes and edges in G, i.e., |G| = |V | + |E|. Remark. To simplify the discussion, we do not explicitly define edge labels. Nonetheless, our techniques can be readily adapted to edge labels: for each labeled edge e, we can insert a  íì§¸dummy íì§¹ node to represent e, carrying e  íís label. Labeled set. For a set S  íì¨ íì§ííª of labels, we say that VS  íì¨ V is a S-labeled set of G if (a) |VS | = |S| and (b) for each label lS in S, there exists a node v in VS such that f(v) = lS . In particular, when S = ?, the S-labeled set in G is ?. Common neighbors. A node v is called a neighbor of another node v íí in G if either (v, v íí) or (v íí, v) is an edge in G. We say that v is a common neighbor of a set VS of nodes in G if for all nodes v íí in VS , v is a neighbor of v íí. In particular, when VS is ?, all nodes of G are common neighbors of VS . Subgraphs. Graph Gs = (Vs, Es, fs, íì§íì§¯s) is a subgraph of G if Vs  íì¨ V , Es  íì¨ E, and for each (v, v íí)  íì¨ Es, v  íì¨ Vs and v íí  íì¨ Vs, and for each v  íì¨ Vs, fs(v) = f(v) and íì§íì§¯s(v) = íì§íì§¯(v). Pattern queries. A pattern query Q is a directed graph (VQ, EQ, fQ, gQ), where (1) VQ, EQ and fQ are analogous to their counterparts in data graphs; and (2) for each node u in VQ, gQ(u) is the predicate of u, defined as a conjunction of atomic formulas of the form fQ(u) op c, where c is a constant, and op is one of =, >, <,  íí and  íí. For instance, in pattern Q0 of Fig. 1, gQ(year) = year  íí 2011  íì© year  íí 2013. We simply write Q as (VQ, EQ) or (VQ, EQ, fQ). We consider two semantics of graph pattern matching. Subgraph queries. A match of Q in G via subgraph isomor- phism [31] is a subgraph G íí(V  íí, E íí, f  íí) of G that is isomorphic to Q, i.e., there exists a bijective function h from VQ to V  íí such that (a) (u, u íí) is in EQ if and only if (h(u), h(u íí))  íì¨ E íí, and (b) for each u  íì¨ VQ, fQ(u) = f  íí(h(u)) and gQ(íì§íì§¯(h(u))) evaluates to true, where gQ(íì§íì§¯(h(u))) substitutes íì§íì§¯(h(u)) for fQ(u) in gQ(u). Here Q(G) is the set of all matches of Q in G. Simulation queries. A match of Q in G via graph simula- tion [20] is a binary match relation R  íì¨ VQ íì©V such that (a) for each (u, v)  íì¨ R, fQ(u) = f(v) and gQ(íì§íì§¯(v)) evaluates to true, where gQ(íì§íì§¯(v)) substitutes íì§íì§¯(v) for fQ(u) in gQ(u); (b) for each node u in VQ, there exists a node v in V such that (i) (u, v)  íì¨ R, and (ii) for any edge (u, u íí) in Q, there exists an edge (v, v íí) in G such that (u íí, v íí)  íì¨ R. For any Q and G, there exists a unique maximum match relation RM via graph simulation (possibly empty) [20]. Here Q(G) is defined to be RM . Simulation queries are widely used in social community analysis and social marketing [9]. 163 Data locality. A query Q is localized if for any graph G that matches Q, any node u and neighbor u íí of u in Q, and for any match v of u in G, there must exist a match v íí of u íí in G such that v íí is a neighbor of v in G. Subgraph queries are localized. In contrast, simulation queries are non-localized. Example 2: Consider a simulation query Q1 and graph G1 shown in Fig. 2, where G1 matches Q1. Then Q1 is not localized: u2 matches v2, . . . , v2n?2 and v2n, but for all k  íì¨ [2, n], v2k?2 has no neighbor in G that matches the neighbor u3 of u2 in Q. To decide whether u2 matches v2, we have to inspect all the nodes on an unbounded cycle in G1. 2 We will study effective boundedness for subgraph queries in Sections III?V, and then extend the results to non-localized simulation queries in Section VI. To formalize effectively bounded patterns, we first define access constraints on graphs. Access schema on graphs. An access schema A is a set of access constraints of the following form: S  íì§ (l, N), where S  íì¨ íì§ííª is a (possibly empty) set of labels, l is a label in íì§ííª, and N is a natural number. A graph G(V,E, f) satisfies the access constraint if ? for any S-labeled set VS of nodes in V , there exist at most N common neighbors of VS with label l; and ? there exists an index on S for l such that for any S-labeled set VS in G, it finds all common neighbors of VS labeled with l in O(N)-time, independent of |G|. We say that G satisfies access schema A, denoted by G |= A, if G satisfies all the access constraints in A. An access constraint is a combination of (a) a cardinality constraint and (b) an index on the labels of neighboring nodes. It tells us that for any S-node labeled set VS , there exist a bounded number of common neighbors Vl labeled with l and moreover, Vl can be efficiently retrieved with the index. Two special types of access constraints are as follows: (1) |S| = 0 (i.e., ?  íì§ (l, N)): for any G that satisfies the constraint, there exist at most N nodes in G labeled l; and (2) |S| = 1 (i.e., l  íì§ (l íí, N)): for any G that satisfies the access constraint and for each node v labeled with l in G, at most N neighbors of v are labeled with l íí. Intuitively, constraints of type (1) are global cardinality constraints on all nodes labeled l, and those of type (2) state cardinality constraints on l íí-neighbors of each l-labeled node. Example 3: Constraints C1-C6 on IMDb given in Example 1 can be expressed as access constraints ?i (for i  íì¨ [1, 6]): ?1: (year, award) íì§ (movie, 4); ?4: ?  íì§ (year, 135); ?2: movie íì§ (actors/actress, 30); ?5: ?  íì§ (award, 24); ?3: actor/actress íì§ (country, 1); ?6: ?  íì§ (country, 196). Here ?2 denotes a pair movie  íì§ (actors, 30) and movie  íì§ (actress, 30) of access constraints; similarly for ?3. Note that ?4 ? ?6 are constraints of type (1); ?2 ? ?3 are of type (2); and ?1 has the general form: for any pair of year and award nodes, there are at most 4 movie nodes connected to both, i.e., an award is given to at most 4 movies each year. We use A0 to denote the set of these access constraints. 2 Effectively bounded patterns. A pattern query Q is effectively bounded under an access schema A if for all graphs G that satisfy A, there exists a subgraph GQ of G such that (a) Q(GQ) = Q(G); and (b) GQ can be identified in time that is determined by Q and A only, not by |G|. By (b), |GQ| is also independent of the size |G| of G. Intuitively, Q is effectively bounded under A if for all graphs G that satisfy A, Q(G) can be computed by accessing a bounded GQ rather than the entire G, and moreover, GQ can be efficiently accessed by using access constraints of A. For instance, as shown in Example 1, query Q0 is effec- tively bounded under the access schema A0 of Example 3. Discovering access constraints. From experiments with real- life data we find that many practical queries are effectively bounded under simple access constraints S  íì§ (l, N) when |S| is at most 3. We discover access constraints as follows. (1) Degree bounds: if each node with label l has degree at most N , then for any label l íí, l íì§ (l íí, N) is an access constraint. (2) Constraints of type (1): such global constraints are quite common, e.g., ?6 on IMDb: ?  íì§ (country, 196). (3) Functional dependencies (FDs): our familiar FDs X  íì§ A are access constraints of the form X  íì§ (A, 1), e.g., movie íì§ year is an access constraint of type (2): movie  íì§ (year, 1). Such constraints can be discovered by shredding a graph into relations and then using available FD discovery tools. (4) Aggregate queries: such queries allow us to discover the semantics of the data, e.g., grouping by (year, country, genre) we find (year, country, genre)  íì§ (movie, 1800), i.e., each country releases at most 1800 movies per year in each genre. Maintaining access constraints. The indices in an access schema can be incrementally and locally maintained in re- sponse to changes to the underlying graph G. It suffices to inspect ?G  íì¨ NbG(?G), where ?G is the set of nodes and edges deleted or inserted, and NbG(?G) is the set of neighbors of those nodes in ?G, regardless of how big G is. III. EFFECTIVE BOUNDEDNESS OF SUBGRAPH QUERIES To make practical use of effective boundedness, we first answer the following question, denoted by EBnd(Q,A): ? Input: A pattern query Q(VQ, EQ), an access schema A. ? Question: Is Q effectively bounded under A? We start with subgraph queries. The good news is that (a) there exists a sufficient and necessary condition, i.e., a characterization, for deciding whether a subgraph query Q is effectively bounded under A; and better still, (b) EBnd(Q,A) is decidable in low polynomial time in the size of Q and A, independent of any data graph. 164 We prove these results in the rest of the section. A. Characterizing the Effective Boundedness The effective boundedness of subgraph queries is charac- terized in terms of a notion of coverage, given as follows. The node cover of A on Q, denoted by VCov(Q,A), is the set of nodes in Q computed inductively as follows: (a) if ?  íì§ (l, N) is in A, then for each node u in Q with label l, u  íì¨ VCov(Q,A); and (b) if S  íì§ (l, N) is in A, then for each S-labeled set VS in Q, if VS  íì¨ VCov(Q,A), then all common neighbors of VS in Q that are labeled with l are also in VCov(Q,A). Intuitively, a node u is covered by A if in any graph G sat- isfying A, there exist a bounded number of candidate matches of u, and the candidates can be retrieved by using indices in A. Obviously, (a) u is covered if its candidates are bounded by type (1) constraints. (b) If for some ? = S  íì§ (l, N) in A, u is labeled with l and is a common neighbor of VS that is covered by A, then u is covered by A, since its candidates are bounded (by N and the bounds on candidate matches of VS), and can be retrieved by using the index of ?. The edge cover of A on Q, denoted by ECov(Q,A), is the set of edges in Q defined as follows: (u1, u2) is in ECov(Q,A) if and only if there exist an access constraint S  íì§ (l, N) in A and a S-labeled set VS in Q such that (1) u1 (resp. u2) is in VS and VS  íì¨ VCov(Q,A) and (2) fQ(u2) = l (resp. fQ(u1) = l). Intuitively, (u1, u2) is in ECov(Q,A) if one of u1 and u2 is covered by A and the other has a bounded number of candidate matches by S  íì§ (l, N). Thus, we can verify their matches in a graph G by accessing a bounded number of edges. Note that VCov(Q,A)  íì¨ VQ and ECov(Q,A)  íì¨ EQ. The node and edge covers characterize effectively bounded subgraph queries (see [3] for a proof, which uses three lemmas and the data locality of subgraph queries). Theorem 1: A subgraph query Q is effectively bounded under an access schema A if and only if (iff) VCov(Q,A) = VQ and ECov(Q,A) = EQ. 2 Example 4: For query Q0(V0, E0) of Fig. 1 and access schema A0 of Example 3, one can verify that VCov(Q0,A0) = V0 and ECov(Q0,A0) = E0. From this and Theorem 1 it follows that Q0 is effectively bounded under A0. 2 B. Checking Effectively Bounded Subgraph Queries Capitalizing on the characterization, we show that whether Q is effectively bounded under A can be efficiently decided. Theorem 2: For subgraph queries Q, EBnd(Q,A) is in (1) O(|A||EQ|+ ||A|||VQ|2) time in general; and (2) O(|A||EQ|+ |VQ|2) time when either ? for each node in Q, its parents have distinct labels; or ? all access constraints in A are of type (1) or (2). 2 Algorithm EBChk Input: A subgraph query Q and an access schema A. Output:  íì§¸yes íì§¹ if Q is effectively bounded and  íì§¸no íì§¹ otherwise. 1. for each S  íì§ (l, N) in A (S 6= ?) do 2. find all V? uS 7 íì§ (u,N) in Q and add them to íì§íí; /*f(u) = l*/ 3. B := {v  íì¨ VQ | ?  íì§ (fQ(v), N) is in A}; 4. C := B; /*Initialize VCov(Q,A)*/ 5. InitAuxi(L, ct); /*Initialize auxiliary structures*/ 6. while B is not empty do 7. v = B.pop(); 8. for each íì§íì¨ in L[v] do 9. Update (ct[íì§íì¨]); /*Update counter ct[íì§íì¨]*/ 10. if ct[íì§íì¨] = ? and u 6 íì¨ C do /*suppose íì§íì¨: V? uS 7 íì§ (u,N)*/ 11. B := B  íì¨ {u}; C := C  íì¨ {u}; 12. if VQ  íì¨ C and all edges in Q are in ECov(Q,A) then 13. return  íì§¸yes íì§¹; 14. return  íì§¸no íì§¹; Fig. 3. Algorithm EBChk Here |A| denotes the total length of access constraints in A, ||A|| is the number of constraints in A, and a node u íí is a parent of u in Q if there exists an edge from u íí to u in Q. Algorithm. We prove Theorem 2 by providing a checking algorithm. The algorithm is denoted by EBChk and shown in Fig. 3. Given a subgraph query Q(VQ, EQ) and an access schema A, it checks whether (a) VQ  íì¨ VCov(Q,A) and (b) EQ  íì¨ ECov(Q,A); it returns  íì§¸yes íì§¹ if so, by Theorem 1. To check these conditions, we actualize A on Q: for each S  íì§ (l, N) in A (S 6= ?), and each node u in Q with fQ(u) = l, the actualized constraint is V? uS 7 íì§ (u,N), where V? uS is the maximum set of neighbors of u in Q such that (a) there exists a S-labeled set VS  íì¨ V? uS and (b) for each u íí in V? uS , fQ(u íí)  íì¨ S. Actualized constraints help us deduce VCov(Q,A): a node u of Q is in VCov(Q,A) if and only if either ? there exists ?  íì§ (l, N) in A and fQ(u) = l; or ? V? uS 7 íì§ (u,N) and there exists a S-labeled set of Q that is a subset of V? uS  íì¨© VCov(Q,A). When VCov(Q,A) is in place, we can easily check whether EQ  íì¨ ECov(Q,A) by definition and using the actualized constraints, without explicitly computing ECov(Q,A). We next present the details of algorithm EBChk. Auxiliary structures. EBChk uses three auxiliary structures. (1) It maintains a set B of nodes in Q that are in VCov(Q,A) but it remains to be checked whether other nodes can be deduced from them. Initially, B includes nodes whose labels are covered by type (1) constraints in A (line 3). EBChk uses B to control the while loop (lines 5-10): it terminates when B = ?, i.e., all candidates for VCov(Q,A) are found. (2) For each node v, EBChk uses an inverted index L[v] to store all actualized constraints V? uS 7 íì§ (u,N) such that v  íì¨ V? uS . That is, L[v] indexes these constraintsthat can be used on v. (3) For each actualized constraint íì§íì¨ = V? uS 7 íì§ (u,N), EBChk maintains a set ct[íì§íì¨] to keep track of those labels of S that are not covered by nodes in V? uS  íì¨© VCov(Q,A) yet. Initially, ct[íì§íì¨] = S. When ct[íì§íì¨] is empty, EBChk concludes that there 165 is a S-labeled subset of V? uS covered by VCov(Q,A), and thus deduces that u should also be in",Yang Cao,"RCBD and SKLSDE Lab, Beihang University",yang.cao@ed.ac.uk,Wenfei Fan,University of Edinburgh,wenfei@inf.ed.ac.uk,Jinpeng Huai,"RCBD and SKLSDE Lab, Beihang University",huaijp@buaa.edu.cn,Ruizhe Huang,University of Edinburgh,s1335233@sms.ed.ac.uk,,,,,,,,,,,,,,,,,,
20200106,1389,Abdeltawab M. Hendawi,"Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA",hendawi@cs.umn.edu,,Predictive Tree: An Efficient Index for Predictive Queries On Road Networks,"Abstract Predictive queries on moving objects offer an im- portant category of location-aware services based on the objects-expected future locations. A wide range of applications utilize this type of services, e.g., traffic management systems, location-based advertising, and ride sharing systems. This paper proposes a novel index structure, named Predictive tree (P-tree), for process- ing predictive queries against moving objects on road networks. The predictive tree: (1) provides a generic infrastructure for answering the common types of predictive queries including predictive point, range, KNN, and aggregate queries, (2) updates the probabilistic prediction of the object's future locations dynamically and incrementally as the object moves around on the road network, and (3) provides an extensible mechanism to customize the probability assignments of the object's expected future locations, with the help of user defined functions. The proposed index enables the evaluation of predictive queries in the absence of the objectsì°½í² historical trajectories. Based solely on the connectivity of the road network graph and assuming that the object follows the shortest route to destination, the predictive tree determines the reachable nodes of a moving object within a specified time window T in the future. The predictive tree prunes the space around each moving object in order to reduce computation, and increase system efficiency. Tunable threshold parameters control the behavior of the predictive trees by trading the maximum prediction time and the details of the reported results on one side for the computation and memory overheads on the other side. The predictive tree is integrated in the context of the iRoad system in two different query processing modes, namely, the precomputed query result mode, and the on-demand query result mode. Extensive experimental results based on large scale real and synthetic datasets confirm that the predictive tree achieves better accuracy compared to the existing related work, and scales up to support a large number of moving objects and heavy predictive query workloads. I. INTRODUCTION The availability of hundreds of millions of smart phones [6] in usersì°½í² hands during their movements in daily lives fired the explosion of a vast number of location aware services [5], [11], [20], [29]. Predictive queries [10], [12], [13] offer a fundamental type of location-based services based on usersì°½í² future locations. Common types of predictive spatial queries include predictive range query, e.g., ì°½íµfind all hotels that are This work is partially supported by the National Science Foundation, USA, under Grants IIS-0952977 and IIS-1218168. located within two miles from a userì°½í²s anticipated location after 30 minutesì°½íµ, predictive KNN query, e.g., ì°½íµfind the three taxis that are closest to a userì°½í²s location within the next 10 minutesì°½íµ, and predictive aggregate query, e.g., ì°½íµfind the number of cars expected to be around the stadium during the next 20 minutesì°½íµ. In fact, Predictive queries are beneficial in various types of real applications such as (1) traffic management, to predict areas with high traffic in the next half hour, so appropriate decisions are taken before congestion appears, (2) location- aware advertising, to distribute coupons and sales promotions to customers more likely to show up around a certain store during the sale time in the next hour, (3) routing services, to take into consideration the predicted traffic on each road segment to find the shortest path of a userì°½í²s trip starting after 15 minutes from the present time, (4) ride sharing systems, to match the drivers that will pass by a riderì°½í²s location within few minutes, and (5) store finders, to recommend the closest restaurants to a userì°½í²s predicted destination in 15 minutes. In this paper, we address the problem of how to process pre- dictive queries for moving objects on road networks efficiently. To this end, we introduce a novel index structure, named the Predictive tree (P-tree), proposed to precompute the predicted moving objects around each node in the underlying road network graph over time. The predictive tree is best described as generic and extensible, from a functionality perspective, dynamic and tunable from a performance perspective. A. Challenges Existing studies on predictive query processing have gone a long way in advancing predictive location-based services. However, existing techniques suffer from both functional limitations and performance deficiencies. From a functional perspective, they suffer from one or more of the following limitations: (1) They consider an Euclidean space [9], [28], [25], [30] where objects can move freely in a two dimensional space. Yet, practical predictive location-based services target moving objects on road networks as described by the motivat- ing applications earlier in this section. (2) Many techniques utilize prediction models that must be trained using a massive 978-1-4799-7964-6/15/$31.00 ? 2015 IEEE ICDE Conference 20151215 a mount of objectsì°½í² historical trajectories in order to produce accurate predictions [2], [9], [13], [15], [24], [28]. However, practical scenarios and industrial experience reveal that such historical data is not easily obtainable for many reasons, either due to usersì°½í² privacy and data confidentiality on one side or due to the unavailability of historical data in rural areas on the other side. (3) Most of the previous solutions were designed to support a specific query type only, e.g., [13], [25], [30] support predictive range query, [3], [22], [30] support predictive KNN query, and [9], [24] support predictive aggregate query. B. Approach Before summarizing the contributions of the proposed pre- dictive tree index, we briefly highlight the basic idea of the index in order to build the proper context. Once an object starts a trip, we construct a predictive tree for this object such that the objectì°½í²s start node in the road network graph becomes the root of the tree. The predictive tree consists of the nodes reachable within a certain time frame T from the objectì°½í²s start location. More specifically, we assume that moving objects follow shortest paths during their travel from source to destination [16], [18]. Hence, we organize the nodes inside the predictive tree according to the shortest path from the objectì°½í²s start node, which is marked as the root of the tree. Accordingly, each branch from the root node to any node in the tree represents the shortest route from the root to this node. Then, our prediction is based on a probability assignment model that assigns a probability value to each node inside the objectì°½í²s predictive tree. In general, the probability assignment is made according to the nodeì°½í²s position in the tree, the travel time between the object and this node and the number of the sibling nodes. In practice, the probability assignment process is tricky and varies from one application to another. At each node in the given road network that is indexed in R-tree, we keep track of a list of objects predicted to appear in this node, along with their probabilities, and travel time cost from the objectsì°½í² current locations to this node. This list represents a raw precomputed answer that can be customized according to the type of the received query (i.e., point, range or kNN predictive query) at query processing time. When an object moves from its current node to a different node, we incrementally update the predictive tree by pruning all nodes in the tree that are no longer accessible through a shortest route from the objectì°½í²s new location. Mostly, this pruning shrinks the number of possible destinations, yet, increases the focus of the prediction. Consequently, the precomputed answer at each node in the object predictive tree is updated to accommodate the effect of the objectì°½í²s movements. This update is reflected to the original nodes in the road network. When a predictive query is received, we fetch the up-to-date answer from the node of interest and compile it according to the query type. To adjust the behavior of the predictive tree and, hence, control the overall predictive query processing performance, we leverage two tunable parameters, a maximum time T and a probability threshold P . These parameters compromise between the maximum prediction time a predictive tree can support and the details in the reported query results on one side, and system resources overheads, i.e., CPU and memory, on the other side. The proposed predictive tree is implemented within the iRoad framework. The iRoad offers two query processing modes of leveraging the predictive tree to control the inter- action between its components: (1) the precomputed query result mode, in which the predicted results are computed and materialized in advance; and (2) the on-demand query result mode which is a lazy approach that postpones all computation till a query is received. C. Contributions In general, the contributions of this paper can be summa- rized as follows: ? We propose a novel data structure named Predictive tree (P-tree) that supports predictive queries against moving objects on road networks. ? We introduce a probability model that computes the like- lihood of a node in the road network being a destination to a moving object. The probability model is introduced to the predictive tree as a user defined function and is handled as a black box by the index construction and maintenance algorithms. ? We introduce two tunable parameters T and P that are experimentally proved to be efficient tools to control the predictive tree index, the system performance, the prediction time, and the results details as well. ? We provide an incremental approach to update the pre- dictive tree as objects move around. Hence, we utilize the existing index structure and incur minimal cost in response to the movement of the object. ? We propose the iRoad framework that leverages the introduced predictive tree to support a wide variety of predictive queries including predictive point, range, and KNN queries. ? we provide an experimental evidence based on real and synthetic data that our introduced index structure is efficient in terms of query processing, scalable in terms of supporting large number of moving objects and heavy query workloads, and achieves a high-quality prediction without the need to reveal objectsì°½í² historical data. The remainder of this paper is organized as follows. Sec- tion II sets the preliminaries and defines our problem. Sec- tion III presents the iRoad system. Section IV describes the the predictive tree and its associated construction, maintenance and querying algorithms. Experimental results are presented in Section V. The study of related work is given in Section VI. Finally, Section VII concludes the paper. II. PRELIMINARIES In this section, we formalize the basic predictive query we address in this paper. Then, we define different types of predictive queries that the predictive tree can support within the iRoad framework. After that, we explain the intuition of the leveraged prediction model. 1216 Fig. 1. iRoad System Architecture A. Basic Query In this paper, we focus on addressing the predictive point query as our basic query on the road network. In this query, we want to find out the moving objects with their corresponding probabilities that are expected to be around a specified query node in the road network within a future time period. The example of such query could be like, ì°½íµFind out all the cars that may pass by my location in the next 10 minsì°½í¶. The predictive point query we address in this paper can be formalized as: ì°½íµGiven (1) a set of moving objects O, (2) a road network graph G(N, E, W), where N is the set of nodes, E is the set of edges, and W is the edge weights, i.e., travel times, and (3) a predictive point query Q(n, t), where n ì°½í°í N, and t is a future time period, we aim to find the set of objects R ì°½í°í O expected to show up around the node n within the future time t. The returned result should identify the objects along with their probabilities to show up at the node of interest. For example, within the next 30 mins, object o1 is expected to be at node n3 with probability 0.8, R(Q(n3,30)) = {< o1,0.8>}. B. Extensions We consider the aforementioned predictive point query as a building block upon which our framework can be extended to support other types of predictive queries including: (i) Predictive range query, where a user defines a query region that might contain more than one node and asks for the list of objects expected to be inside the boundaries of that region within a specified future time, (ii) Predictive KNN query to find out the most likely K objects expected to be around the node of interest within a certain time period, and (iii) Predictive aggregate query to return the number of objects predicted to be within a given location in the next specified time duration. C. Prediction Model Our prediction model employed by the introduced predictive tree index structure is based on two corner stones. (1) The assumption that objects follow the shortest paths in their routing trips. The intuition behind this assumption is based on the fact that in most cases, the moving objects on road networks, e.g., vehicles, travel through shortest routes to their destinations [16], [18]. In fact, this assumption is aligned with the observation in [4] that moving objects do not use random paths when traveling through the road network, rather they follow optimized ones, e.g., fastest route. As a result, this (a) Network & Objects (b) Predictive Trees Integrated With R-Tree Fig. 2. Example Of The Proposed Index Structure model prevents the looping case that appears in the traditional turn-by-turn probability model and assigns a probability value for the moving object to turn when facing an intersection [13]. (2)The probability assignment model that assigns a proba- bility value to each node inside the objectì°½í²s predictive tree. In fact, the probability assignment is affected by the nodeì°½í²s position with respect to the root of the tree, the travel time cost between the object in its current location to this node, and the number of the sibling nodes. In general, our predictive tree is designed to work with different probability assignment models. For example, a possible probability model can give higher values to nodes in business areas, e.g., down town, rather than those in the suburbs. In our default probability model, each node in the predictive tree has a value equal to one divided by the number of nodes accessible from the root within a certain time range. III. THE IROAD SYSTEM The proposed predictive tree is implemented in the context of the iRoad System. More precisely, the predictive tree and its construction, maintenance and querying algorithms form the core of the iRoad System. The iRoad System is a scalable framework for predictive query processing and analysis on road networks. The architecture of the iRoad system consists of three main modules, namely, the state manager, the pre- dictive tree builder and the query processor, Figure 1. In this section, we present an overview of the iRoad System and give a brief description of its key components. Moreover, we focus on the interaction and workflow between these components under both the precomputed query result mode and the on- demand query result mode. A. State Manager The state manager is a user facing module that receives a stream of location updates from the moving objects being monitored by the system. The state manager maintains the following data structures. (1) An R-tree [7] that is generated on the underlying road network graph. It differs from the conventional R-tree in that at each leaf node, i.e., a node in the road network, in addition to storing the corresponding MBR, it also keeps track of two lists: (a) current objects that records the pointers to the objects around this node, and (b) 1217 predicted objects that maintains the predicted results of the objects that most likely to show up around that node. (2) A trajectory buffer that stores the most recent one or more nodes in the road network that are visited by the moving object in its ongoing trip. (3) A predictive tree such that root of a predictive tree is the current location of the moving object. Figure 2(a) gives an example of a set of objects moving on a road network, while Figure 2(b) depicts how the predictive trees are integrated within the basic data structures layout to facilitate the processing of predictive queries. As we mentioned, the system can be running under either (1) a precomputed query result mode or (2) an on-demand query result mode. The first is the default mode inside the iRoad framework. In either modes, upon the receipt of a location update of a moving object, the R-tree is consulted and the new location is mapped to its closest node Nnew in the road network. If the new node Nnew is the same as the objectì°½í²s old node Nold, the object movement is not significant enough to change the systemì°½í²s state and no further action is taken. Otherwise, the object has moved to a different node and an evaluation of the impact of the objectì°½í²s movement is triggered in the system. We differentiate between the precomputed and the on-demand query result modes as follows. Precomputed query result mode: In this mode, the predic- tive tree builder is invoked immediately once the moving ob- ject changes its current node and, consequently, the predictive tree is either constructed from scratch or updated in response to the objectì°½í²s movement. Remember that the predictive tree is constructed from scratch if the incoming location update belongs to a new object that is being examined by the system for the first time. Also, the predictive tree is constructed from scratch if Nnew is not a child of the root of the objectì°½í²s in- hand predictive tree. As will be described in Section IV, this case happens if the object decided not to follow the shortest path, e.g., made a u-turn or started a new trip. Otherwise, the tree is incrementally maintained. Note that, in this mode, the trajectory buffer data structure boils down to one single node (i.e., the current node) of the moving object because of the eagerness to update the predictive tree with the receipt of every location update. Hence, the past trajectory is entirely factored in the predictive tree. On-demand query result mode: In this mode, the tra- jectory buffer stores all nodes the moving object passed by since the start of its current trip. Initially, We do not perform any computation until a query is received. Then, we identify the vicinity nodes within the time range determined by the query. Those nodes might contribute in the predicted results. For each object in these nodes, we construct its predictive tree and run a series of updates according to the list of passed nodes in its trajectory buffer, Figure 3. For example, in this figure, nodes A, G, and E are within the time range specified in the query at node B. Then, we construct the predictive tree for each object, O1, O2, O3, in those nodes and update them according the passed nodes by each one. Obviously, O1, O3 will contribute in the predicted objects at node B, while O2 will not contribute as node B is no longer a possible destination Fig. 3. On-Demand Approach for O2 based on its trajectory buffer. Then, we get rid of any data structure, i.e., the predictive trees and predicted results, directly once the query processing is completed and the results are carried back to the query issuer. We ending by adding the objectì°½í²s current node Nnew, i.e,. Node B in this example, to the objectì°½í²s trajectory buffer. B. Predictive Tree Builder The predictive tree builder is the component that encom- passes the predictive tree construction and maintenance algo- rithms. It takes as input, (1) the moving objectì°½í²s trajectory buffer, (2) the moving objectì°½í²s current predictive tree (if exists), (3) the tunable parameters (T and P) that trade the prediction length and accuracy for systemì°½í²s resources, and (4) a user defined probability assigned function. The predictive tree builder reflects the most recent movements of the object (as recorded in the objectì°½í²s trajectory buffer) to the objectì°½í²s predictive tree. Upon the completion of a successful invocation of the tree builder, an up-to-date predictive tree rooted at the objectì°½í²s current location is obtained and the objectì°½í²s trajectory buffer is modified to accommodate the objectì°½í²s current node. The predictive tree builder is invoked in two different ways. In a precomputed query result mode, the builder is invoked by the state manager upon the receipt of every location update. The state manager pushes the incoming location update of a moving object Oi to the predictive tree builder that eagerly reflects the location update in the predictive tree of Oi. Afterwards, the tree builder updates the precomputed query results at every node in the road network that is on the shortest path route from the object Oiì°½í²s current location. In an on-demand query result mode, the predictive tree builder is invoked by the query processor once a query Q is received. The predictive tree builder consults the road network graph and retrieves a list of nodes Nvicinity that are within the time distance determined by the query Q. Then, it pulls, from the state manager, the predictive trees and the trajectory buffers of moving objects whose current nodes are in Nvicinity . In other words, lazy or selective processing of moving objects that are believed to affect the query result is carried over without taking the burden of updating the predictive tree of every single moving object in the system. C. Query processor The main goal behind predictive query processing in the iRoad system is to be generic and to provide an infrastructure for various query types. This goal is achieved by mapping a query type to a set of nodes (Nvicinity) in the road network graph such that the query result is satisfied by predictions 1218 Algorithm 1 Predictive Tree Construction Input: Node n, T ime Range T , Road Network Graph G(N,E,W ) 1: Step 1. Initialize the data structures 2: Set n as the root of the Predictive Tree PT 3: Visited nodes list NL $ ? 4: Min-Heap MH $ ? 5: for all Edge ei connected with n do 6: Insert the node ni ì°½í°í ei íì§¸C MH 7: end for 8: Step 2. Expand the road network and create the predictive tree 9: while the minimum time range Tmin in MH < T do 10: Get the node nmin with Tmin from MH 11: if The nmin /ì°½í°í NL then 12: Insert nmin íì§¸C PT 13: Insert nmin íì§¸C NL 14: for all Edge ej connected with nmin do 15: Insert the node nj íì§¸C MH 16: end for 17: end if 18: end while 19: Return PT associated with these nodes. For predictive point queries as an example, the point query is answered using the information associated with the road network node that is closest to the query point. For predictive range queries, all nodes in the range are considered to compute the query result. For predictive KNN queries, we sort those predicted objects associated with Nvicinity based on their probabilities. Nvicinity is rationally expanded till K objects are retrieved, if visible. In a precomputed query result mode, generic results are prepared in advance and are held in memory. The process is triggered by an update in objectì°½í²s location and the precom- puted results are constructed/updated for all nodes along the shortest path route of that object. Therefore, most of the work is done during the location update time. Upon the receipt of a query, the query processor fetches the precomputed results only from nodes in Nvicinity , adapts them according to the type of the received query and gives a low latency response back to the user. In an on-demand query result mode, nothing is precomputed in advance and all computation will be performed after the receipt of the userì°½í²s query. Nvicinity is identified and the pre- dictive tree of objects whose current node belong to Nvicinity are constructed/upadted as described earlier in this section. Then, the results are collected and adapted to the query type in a similar way to the precomputed result approach. IV. PREDICTIVE TREE In this section, we describe the proposed predictive tree index structure that is leveraged inside the iRoad framework to process predictive queries based on the predicted destinations of the moving objects within a time period T . We first introduce the main idea and the motivation to build the predictive tree. After that, we provide a detailed description for the two main operations in the predictive tree: 1) predictive tree construction, and 2) predictive tree maintenance. The idea of the predictive tree is to identify all the possible destinations that a moving object could visit in a time period T by traveling through the shortest paths. As there may only exist one shortest path from a start node to a destination node, we can guarantee it will be a tree structure (i.e., without any loop). The intuition for constructing the predictive tree with a time boundary T is based on two real facts: 1) most of the moving objects travel through shortest path to their destinations [16], [18], and 2) majority of the real life trips are within a time period, e.g., 19 minutes [17], [18]. As a result, we only need to care about the possible destinations reachable through a shortest route from the objectì°½í²s start location within a bounded time period. Based on that, we build the predictive tree to hold only the accessible nodes around a moving object and assign a probability for each one of them. The predictive trees leveraged in the iRoad system signif- icantly improves the predictive query processing efficiency for two main reasons. 1) The possible destinations of the prediction shrinks as a result of using the time boundary T . Yet, prediction computation is performed on few number of nodes instead of millions of nodes in the underlying road network, e.g., road network of California state in USA has about 1,965,206 nodes and 5,533,214 edges [23]. 2) Inside the predictive tree, we maintain only those nodes with probability higher than a certain probability threshold parameter P , e.g., 10%. By doing this, we cut down the computation overhead consumed for continuously maintaining the predicted results at each node in the predictive trees. Moreover, we control iRoad to focus on those nodes that more likely to be reached by a moving object. Yet, the query reported results can be more reasonable to users. A. Predictive Tree Construction Main idea. When a moving object starts its trip on the road network, we build a predictive tree based on its starting location to predict its possible destinations within a certain time frame T . We propose a best-first network expansion algorithm for constructing predictive tree for time period T , e.g., 30 minutes. We set the objectì°½í²s initial node as the start node, then, we visit the nodes and edges on the road network that are reachable using a shortest path from this start node [21]. The algorithm proceeds to traverse and process the edges in the road network based on the travel time cost from the start node until all the costs to the remaining edges are over T . Algorithm. The pseudo code for the predictive tree con- struction algorithm is given in Figure 1. The algorithm takes the road network G = {N,E,W}, a starting node n and a time range T as input. The algorithm consists of two main steps: ? Initialization. We first initialize the predictive tree under construction by setting the start node n as the root of the tree. We also create the visited nodes list NL to store the nodes that have been processed by the algorithm so far. An empty min-heap, MH , is employed to order the nodes based on its distance to the root node n. After that, we insert the nodes that are directly connected with the 1219 Fig. 4. Example of Constructing And Expanding The Predictive Tree Started At Node A. root node n into the min-heap MH , (Lines from 2 to 7 in Algorithm 1). ? Expansion. We continuously pop the node nmin that is the closest to the root node from the min-heap. Then, we check if that node has been visited by our algorithm before, which means there was a shorter path from the root to this node nmin. If visited nodes list NL does not contain nmin, we insert the node nmin to it as well as a child to the current expanding branch of the predictive tree PT . After that, we insert to the min-heap MH the node nj that is connected with the yet processed node nmin for further expansion. The algorithm stops when the distance between the next closest node in the min- heap is over the boundary T , (Lines from 8 to 18 in Algorithm 1). Example. Figure 4 gives an example for constructing a predictive tree for node A from the given road network. For this example, we set the time period T to 20 minutes. Figure 4(a) gives the original road network structure, where circles represent nodes and lines between nodes represent edges and the number on each edge represents the time cost to traverse that edge. In the first iteration, we start by setting the root of the tree to node A. Then, we insert nodes B and C into the min-heap, as they are the connected ones to the root node A, Figure 4(b). After that, we expand the closest child to the root, B, where we insert D and E into the min- heap MH and put B in the predictive t",Abdeltawab M. Hendawi,"Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA",hendawi@cs.umn.edu,Jie Bao,"Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA",baojie@cs.umn.edu,Mohamed F. Mokbel,"Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA",mokbel@cs.umn.edu,Mohamed Ali,"Institute of Technology, University of Washington, Tacoma , WA, USA",mhali@uw.edu,,,,,,,,,,,,,,,,,,
20200107,1390,Michael Mattig,"Department of Mathematics and Computer Science University of Marburg, Germany",mattig@mathematik.uni-marburg.de,,Kernel-Based Cardinality Estimation on Metric Data,"ABSTRACT The efficient management of metric data is extremely important in many challenging applications as they occur e.g. in the life sciences. Here, data typically cannot be represented in a vec- tor space. Instead, a distance function only allows comparing individual elements with each other to support distance queries. As high-dimensional data suffers strongly from the curse of di- mensionality, distance-based techniques also allow for better handling of such data. This has already led to the development of a plethora of metric indexing and processing techniques. So far, the important problem of cardinality estimation on metric data has not been addressed in the literature. Standard vector-based techniques like histograms require an expensive and error-prone embedding. Thus, random sampling seems to be the best choice for selectivity estimation so far, but errors are very high for mod- erately small queries. In this paper, we present a native cardinality estimation technique for distance queries on metric data based on kernel-density estimation. The basic idea is to apply kernels to the one-dimensional distance function among metric objects and to use novel global and local bandwidth optimization methods. Our results on real-world data sets show the clear advantage of our method in comparison to its competitors. 1 INTRODUCTION Statistics about the distribution of data in a database are used for two very important aspects of data management: query optimiza- tion and data exploration. In query optimization, they allow esti- mating the costs of operations, choosing appropriate algorithms, and computing the order of joins. For very large databases, where computations take a very long time, small in-memory statistics can deliver approximate answers. Those are often sufficient to determine whether it is worth further investigating the data in a particular direction. While one- and multidimensional vector data is very common in traditional applications, there are many domains for which data is in a metric space only. This means data is not describable by a d-dimensional vector, instead there exists only a metric mea- suring distances between pairs of objects. Examples include the life sciences, where e.g. proteins are usually described by their geometrical structure or at least a sequence of amino acids. Mul- timedia data comes in different datatypes such as JPEG or MPEG which are also not appropriate for a relational representation. In such domains there is a severe lack of native statistical sup- port. Thus, a standard approach is to transform metric data into a multidimensional vector space and to apply one of the standard estimation techniques [18]. There are two serious opposing ef- fects. First, a metric embedding causes in general a considerable information loss. In order to alleviate this, the number of dimen- sions needs to be sufficiently high. Second, the well-known curse ? 2018 Copyright held by the owner/author(s). Published in Proceedings of the 21st International Conference on Extending Database Technology (EDBT), March 26-29, 2018, ISBN 978-3-89318-078-3 on OpenProceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0. of dimensionality is already noticeable for a moderate number of dimensions. Thus, statistics provide only accurate results for low-dimensional vector spaces [1]. In this paper, we present the first native method for cardinality estimation of distance queries in metric spaces. The basic idea is to consider the distances of objects in a metric space and to use kernel techniques to estimate the underlying distance distri- bution. By tuning the bandwidth of the kernels and the kernel function, we obtain a robust estimator for the cardinality of dis- tance queries in metric spaces. Moreover, our approach is also beneficial for high-dimensional vector spaces by treating them as metric spaces, thus considering only the distance among objects, to overcome the shortcomings of standard vectorial statistics. The main contributions of this paper are: ? We show the deficiencies of traditional cardinality estima- tion techniques on metric data sets. ? We present the first effective and efficient method for cardinality estimation in metric space. ? Extensive experiments on real-world data show the valid- ity of our approach. The rest of the paper is structured as follows. Section 2 de- scribes several applications for cardinality estimation in metric spaces, formally defines the problem, and emphasizes the dif- ferences of vector and metric data. Section 3 presents related work in the areas of cardinality estimation in general, techniques for embedding metric data into vector space and kernel-based techniques for cardinality estimation. Section 4 presents our distance-based kernel estimator approach in metric space. Sec- tion 5 describes our methods for global and local bandwidth optimization. Section 6 presents our experimental findings. Fi- nally, Section 7 concludes the paper. 2 PRELIMINARIES We first give a formal description of the problem of cardinality estimation on metric data. Then, we discuss several applications that greatly benefit from a suitable solution to this problem. Fi- nally, we discuss the fundamental differences between vector and metric data that lead to the ineffectiveness of established methods. 2.1 Problem Specification Let X be a set of N objects {x1, . . . ,xN }  íì¨ X. These objects are all of a certain type, in particular a type which can differ from Rn . Moreover a distance function distX : X  íì© X  íì§ R+ is given which fulfills the three properties of a metric, namely (a) identity of indiscernibles: distX(x ,y) = 0íì§íì§ x = y, (b) symmetry: distX(x ,y) = distX(y,x) and (c) triangle inequality: distX(x , z)  íí distX(x ,y)+distX(y, z), with x ,y, z  íì¨ X. We will refer to the combination of X and distX as metric data. In mathematics the pair (X,distX) is called metric space. Cardinality estimation for metric data can be formalized as follows: Given a distance queryQ = (xQ , rQ ), with object xQ  íì¨ X     Series ISSN: 2367-2005 349 10.5441/002/edbt.2018.31 and distance rQ  íì¨ R+, efficiently approximate the cardinality of the set {x  íì¨ X | distX(xQ ,x)  íí rQ }. We will refer to the distance rQ as query radius. The true cardinality is denoted by c(Q) and the estimated cardinality by c?(Q). The goal is to minimize the error of the estimation, but also the construction costs and the size, as well as the query time of the estimator. Note that the actual cardinality can, of course, be calculated by computing the distance to every other item in the data set. This requires a linear number of distance calculations. Each of them can be very costly as, e.g., in video dissimilarity. Hence, we want to minimize the computational costs induced by an estimator. 2.2 Applications Cardinality estimation in metric spaces has many applications. Among others we want to mention the domain of Machine Learn- ing and Data Mining, where algorithms are usually based on a distance measure. The most prominent example is the so-called k-nearest neighbor (kNN) classifier which can be used to classify any kind of data, if it is endowed with a distance measure. The basic idea is to retrieve thek objects from a database which have the smallest distances to a certain query object. Assuming that the objects within the database carry a certain class label (e.g. customers of an insurance with label churn or no churn), the query is classified with the majority label from the set of the k nearest neighbors. kNN classifiers are known to be inefficient since for each run of such an algorithm a complete scan of the data set is required. To accelerate this algorithm typically metric index structures [28] are employed that allow the efficient retrieval of elements within a given distance of a query object. However, it is hard to specify the radius for the corresponding queries since the kNN classifier requires rather the set of k nearest neighbors than a certain set of neighbors exhibiting a certain maximal distance to the query object. For calculating the minimum radius, leading to a retrieval of k results, cardinality estimation can be used. For example, [14] make use of cardinality estimation to assign objects to different Locality Sensitive Hashing tables of different radii. This improves kNN queries on data sets where the distances of the k nearest neighbours of items vary greatly over the data set. A single LSH table could not sufficiently answer such queries. Another example is the estimation of densities, e.g. for Bayes Classifiers, where the density around an element x is propor- tional to the amount of elements in a database that are in a small vicinity to x . This vicinity is typically specified by a certain small distance. Obviously, a reliable cardinality estimation approach would increase the efficiency of such classifiers enormously. If a query is expressed as a conjunction of multiple proximity predicates, each of them with a different distance function, car- dinality estimation is useful for computing an efficient order of their computation. In an optimal execution plan queries should be applied in an order that leads to quickly decreasing result sets. Cardinality estimation can be used to answer exactly this question and to find an order in which the different distance measures are to be applied. Applications in which such scenarios occur are, e.g., pharmaceutical chemistry, where different dis- tance measures covering certain requirements are applied onto protein and/or ligand databases to get the final result in form of a very small set of therapeutically effective drugs. In general, this is a metric scenario, since proteins cannot be described on the structural level by vectors without a considerable loss of information. 2.3 Vector Data vs. Metric Data In order to emphasize the fundamental differences of metric data to vector data that lead to the in-applicability of established methods, we now briefly review important properties of a vector space. We limit our discussion to vector spaces over the real numbers. Here, ad-dimensional vector space consists of elements x = (x1, ...,xd )with a real value xi  íì¨ R called coordinate for each dimension. Individual elements can be added to each other and multiplied with scalar values v  íì¨ R. This, e.g., allows to compute the mean of multiple elements which is not possible in a metric space. Thus one of the most basic data summarization operators is not available in a metric space. Furthermore, the coordinates of the vector allow determining the location of an element with respect to other elements. Such a direction cannot be determined in a metric space. A set of vectors can be ordered globally by component-wise sorting or by a space-filling curve [27] that better preserves the proximity of subsequent elements. In contrast, elements in a metric space can only be ordered based on the distance to a single reference object. Furthermore, it is straight-forward to divide a vector space into a finite number of distinct subsets by incrementally subdividing the space along the dimensions. In a metric space such subsets have to be defined using a center object and a radius. In general, such partitions will overlap if the complete data space should be covered. A vector space has ameasure that allows calculating the vol- ume of subspaces and their intersections. In particular, this is the foundation for the definition of a density and a distribution of a data set. The notions of volume, density and distribution are not available in a metric space. Finally, in a vector space, the costs of distance calculations between elements is linear in the number of dimension if an Lp norm (typically p = 2 for Euclidean distance) is used. In a metric space a distance function can be arbitrarily complex, such as e.g. the edit distance between two strings which has a quadratic runtime. Furthermore, we can calculate a bounding box of a vector data set in linear time by finding the minimum and maximum value for each dimension. In contrast, finding the maximum distance between elements in a metric space requires a quadratic number of distance computations. In summary, metric data lacks most of the tools available in traditional scenarios for cardinality estimation. This makes most established methods infeasible as we discuss in the Section 3. However, as discussed previously, metric data appears in many different applications naturally. Furthermore, it supports distance queries, which are also highly relevant for vector data [4]. As our experiments will show later, using distance-based techniques helps lowering the impact of the curse of dimensionality. 3 RELATEDWORK The most basic idea for estimating the size of a query result is to perform the query on a sample of the data and scale up the resulting cardinality by the sample  íís fraction of the total data size. Using Reservoir Sampling [32], a random data selection can be computed in linear time. We can apply this method also on metric data. However, small sample sizes result in underestimates often equal to zero because metric spaces are sparse. Histograms are the most popular technique for cardinality estimation in database systems [18]. They divide a domain into multiple buckets and store the number of contained elements. When estimating the cardinality within a given query range, they 350 approximate the actual cardinality usually by assuming a uniform distribution within the buckets. Computing optimal histograms that minimize the error induced by this assumption is NP-hard [25]. The most prominent example of an efficient heuristic is MinSkew [2]. It recursively subdivides the space by splitting the most skewed bucket until the desired number of buckets is reached. Other techniques like rkHist [11] and R-V histogram [1] start from the leaves of a spatial index structure and merge them together for limiting the amount of buckets. The introduced histograms are, however, not applicable for metric data. There is no straight-forward criterion for subdivid- ing a metric space into a finite amount of disjoint buckets. The missing notion of uniform distribution within a bucket and the unavailability of a volume measure make the incorporation of such buckets into a cardinality estimate impossible. It is possi- ble to transform metric data into vector data in order to build a spatial histogram, though. We can then extract the cardinality estimate for a distance query by calculating the intersection of the query (in form of a hyper-sphere) with the histogram buckets. However, such a transformation into a vector space is costly and introduces an error in form of distance distortions. Compression techniques like wavelets and cosine transfor- mations are also suitable for cardinality estimation [24]. Both techniques are applicable to multi-dimensional vector data and are shown to provide accurate results. They approximate the actual data distribution by means of a basis function and several coefficients, thus drastically reducing the amount of data. The cardinality estimate is computed as a cumulative joint distribu- tion of the individual dimensions of the data set. However, in a metric space we are not able to use these techniques as the data has no such dimensions and there is no notion of a distribution. Another method for approximate query processing is Local Sensitive Hashing (LSH). LSH performs very well on data from a high-dimensional vector space. It is for example used for approx- imate similarity search [15] and thus related to distance queries in metric spaces. There has been work in cardinality estimation of similarity joins using LSH [21]. Also, multiple LSH indexes with different radii can be used for cardinality estimation by counting collisions of hash buckets [14]. However, LSH requires a similarity-preserving hash function which does not universally exist for metric data. A more recent approach uses Machine Learning [4] for car- dinality estimation. It is, to the best of our knowledge, the only method supporting distance queries. The query-driven approach learns to differentiate several prototype queries and predicts the cardinality of unseen queries by assignment to a prototype and subsequent interpolation using regression. The optimization of the query prototypes is performed via gradient descent where the prototype query is moved across the data space. This manip- ulation of a query object is not possible in a metric space. Thus, like the other approaches, this approach is infeasible for metric data, unless it is mapped into a vector space first. A distance preserving mapping of data from a metric space to a vector space is called embedding. The goal is to find for each xi  íì¨ X an embedding yi  íì¨ Rd , such that the induced stress [19] on the distances is minimized. This stress measure incorporates the deviations of the resulting distances among objects with respect to the original distances. There are different approaches available to embed metric data into a vector space [3]. One prominent example is Multidimen- sional scaling (MDS) [20]. It tries to preserve the pairwise dis- tances in vector space by using such a stress function [19] and minimizing it subsequently. This minimization can be performed by eigendecomposition or gradient descent. However, both meth- ods are expensive to compute, and thus, not suitable for very large data sets. Landmark MDS [9] was introduced as an alternative to MDS for big data scenarios. It uses samples of the data called land- marks and applies MDS on them. The remaining points are then embedded based on the distances to the l landmark elements. Kernel estimators [26] are a competitor of histograms which exhibit a fast convergence for 1-dimensional data [7] and have been generalized to multi-dimensional data [16]. Note, that both approaches do not support distance queries on metric data. Here, samples distribute their weight using a kernel function K , e.g. Epanechnikov [12] or Gaussian. This weight corresponds to the probability of data points existing in the vicinity of the sample. One approximates the underlying probability density function f? of a data set at the evaluation point x by using a set of samples S and summing up over all samples: f? (x) = 1 |S |  íì§h íì§2 s  íì¨S K( x?s h ) = 1 |S | íì§2 s  íì¨S Kh (x ? s). Here, h is the smoothing-factor called band- width. The cardinality estimate results from integrating the ker- nel density function within a given rectangle query and scaling the result up. In a d-dimensional vector space typically product kernels are used where the density function is integrated for each dimension separately. This is only feasible for rectangular queries and not for distance queries. Hence, the application of existing kernel-density estimators for distance queries on met- ric data embedded into a vector space is not straight-forward. Approximating the distance query as a hyper-sphere introduces an error that is also influenced by the curse of dimensionality. Our approach makes use of kernels, but we avoid the curse of dimensionality by using the one-dimensional distance function. The choice of the actual kernel function is considered to be of low impact according to the literature [8]. Nevertheless, we consider different kernel functions in the experiment section of this paper. However, the selection of the kernel bandwidth h has a much more crucial impact on the resulting estimator quality. There are two general approaches for the bandwidth selection: global and locally adaptive methods [31]. Using a global (fixed) bandwidth means that all samples and evaluation points use the same bandwidth. One method of obtaining this bandwidth is by minimizing the mean integrated squared error (MISE) [30]. In contrast to traditional applications, the underlying distribution that shall be fitted by the kernel estimator is known in cardinality estimation. It is given by the data itself. This enables other opti- mization techniques than those used in the statistics literature. Recent work [17] used a gradient descent based approach to find the optimal bandwidth for a given set of training queries. They fit a global bandwidth for each dimension of the vector space. However, a global bandwidth is usually not optimal, as the result- ing estimator oversmoothes the distribution in dense regions and undersmoothes in sparse regions of the data set. While the au- thors of [17] were able to exploit the different distributions in the individual dimensions, we found the error of a global bandwidth for different query sizes in our metric scenario to be significantly high. Furthermore, a gradient descent based approach to band- width estimation turned out to get stuck in local optima of poor quality in our experiments. We thus also investigate locally adap- tive kernel estimators that vary the bandwidth either based on 351 ?? ?? ?????(??, ?) ????? ? 0 ???????? Figure 1: The incorporation of a kernel-sample s into the cardinality estimation for a query Q = (xQ , rQ ). The omit- ted y-axis corresponds to the probability density. Algorithm 1: Generic Kernel Estimation Algorithm Input :Kernel function Kh : R íì§ R+, centered at 0 Optimized bandwidths B : X  íì© X  íì© R+  íì§ R+ Samples S  íì¨ X  íì¨ X Total data set size |X | Distance function distX : X  íì© X  íì§ R+ Query Q = (xQ , rQ ) with object and radius Output :Estimated cardinality c?(Q) 1 total  íì§  0.0; 2 foreach s  íì¨ S do 3 h  íì§  B(s,xQ , rQ ); 4 s?  íì§  distX(xQ , s); 5 contribution  íì§   íì§¼ rQ 0 Kh (x ? s?) dx ; 6 total  íì§  total + contribution; 7 end 8 probability  íì§  total/|S |; 9 return ?probability  íì§ |X |?; the sample point or the evaluation point. The latter is also called balloon estimator [30]. Other work in kernel-based techniques for cardinality estima- tion in vector spaces focuses also on improving the efficiency of the estimation process. One approach is reducing the number of samples to a so-called coreset [33] that maximizes both quality and efficiency of the estimator. In the scope of this paper we do not yet consider such improvements but focus on demonstrating the general applicability of kernel estimators to this new scenario of metric data. 4 DISTANCE-BASED KERNEL ESTIMATORS Kernel estimators allow us to overcome a fundamental problem of using a sample directly for estimating the cardinality of a query result. Namely that the information is concentrated at a sample point. In contrast to a histogram we also get a continuous distribution. In a metric space it is, however, not straight-forward how we can apply a kernel function on a sample point, as there are no dimensions in which they could gradually distribute the mass of a sample. The central idea of our proposed technique is therefore to apply the kernel function on the distance to a sample point in order to incorporate the probability of elements in the vicinity fractionally. In the following we show how to incorporate a sample point into the cardinality estimate. Here, the query Q = (xQ , rQ ) with object xQ and radius rQ is located at distance s? B distX(xQ , s) 0.00 0.10 ? 1 0 1 2 3 Bandwidth M ed ia n  of  R el at iv e  E rr or s 0.00 0.10 0 50 0 15 00 25 00 Bandwidth Su m  o f S qu ar ed  E rr or s Figure 2: Influence of the bandwidth on the estimation er- ror on the Moby data set (cf. Section 6) for a fixed query size. The left-hand side shows the median of the relative errors (Equation (2)). The right-hand side shows the sum of squared errors (measureMLS ). from the sample point s . As depicted in Figure 1, we introduce an axis expressing the distance to xQ . For that wemap xQ to x?Q B 0, the origin of the axis. The sample point s is then mapped onto s? . The kernel function Kh is then centered at point s? by subtracting s? from its argument. We take the area under the curve of the kernel function between x?Q and rQ as the contribution of this sample to the cardinality estimate. Algorithm 1 shows the full estimation process. For each sam- ple point we calculate the contribution and compute the sum. For this we first compute the optimized bandwidth by calling the function B for the given sample point and query with object and radius. In case of a global bandwidth, this function ignores the parameters and always returns the same bandwidth. In case of a locally adaptive approach, it either uses the sample or evaluation point (query) to obtain a specific bandwidth. We detail algorithms for computing the bandwidth in the next section. Given the opti- mized bandwidth, the distance between sample and query object, and the radius, we calculate the contribution of the sample to the running total . After all samples are processed, the probability is then the total divided by the number of samples, see line 8. Finally, we scale the resulting probability up by the total data set size and return this value as the cardinality estimate. The general workflow of our technique consists of (1) collect- ing a set S of samples, (2) determining the optimal bandwidths B and (3) applying Algorithm 1 to estimate the cardinality of new queries. In the following we present the process of optimizing the bandwidths. 5 BANDWIDTH OPTIMIZATION It is well-known [31] that the bandwidth of a kernel function has a crucial impact on the resulting cardinality estimate. A too small bandwidth leads to undersmoothing, a too large bandwidth to oversmoothing. The two edge cases are an infinitely small bandwidth that converges to sampling and an infinitely large bandwidth that converges to a uniform distribution. We thus take particular care of finding an optimal value. We distinguish between a global bandwidth for all samples and queries, and locally adaptive methods where the bandwidth is individually fitted to accommodate for sparser and denser regions of the data space. 352 5.1 Global The computation of the optimal global bandwidth for a kernel function and a given data set is an optimization problem. We first formalize this problem and then present our optimization strategy. 5.1.1 Optimization Problem. We want to find a bandwidth h that minimizes the error of estimates for future queries on the given data set. As we do not know the future queries, we extract a set of training queries Q from the data set and minimize the error for these queries. Afterwards, we validate the performance against an independent set of test queries that we extracted from the data set beforehand. We formally define the optimization problem for a fixed kernel function as arg min h ErrorX (h,Q) , (1) where h is the bandwidth,X is the data set and ErrorX a function that computes the error of the queries Q on X for the given bandwidth h. We define an appropriate error measure for Equation (1) in two steps. First, we define an auxiliary function errorX (h,Q) B c?h (Q) ? c(Q) c(Q) , (2) where c?h (Q) is the estimated cardinality using bandwidth h and c(Q) the actual cardinality of queryQ on data setX . This measure differs slightly from the common relative error metric, as we do not take the absolute value in the numerator. This allows us to assess over- and underestimates separately. It returns values in the interval [?1, íí]. Two values are of particular interest: ?1 indicates that the estimator returns simply a result of zero even though there are results contained in the query. On the other hand, an error of zero indicates a perfect result: the estimated cardinality is equal to the true number of elements the query returns. There is no upper bound for our measure. However, one should notice, that a value of 1 means already an overestimation by a factor of 2. To compute the error of a set of queries Q we combine the errors errorX (Q) of the individual queriesQ  íì¨ Q using ameasure M : R |Q |  íì§ R+. M computes for a set of errors E a single value that is then subject to minimization. Two examples for M are the deviation of the median error from zero, and the sum of squared errors (LS for least squares): Mmedian (E) B | median(E) | MLS (E) B íì§2 e  íì¨E e2 . For M  íì¨ {Mmedian ,MLS }, the final optimization problem is defined as arg min h ErrorX (h,Q) = arg min h M({errorX (h,Q) | Q  íì¨ Q}) (3) 5.1.2 Optimization Strategy. The minimization of the error function (3) requires an efficient and robust optimization method. Figure 2 shows the relationship between bandwidth and error for an example data set. On the left-hand side of the plot we ob- serve that starting from an infinitely small bandwidth results first underestimate the true cardinality. A higher bandwidth reduces the error to a certain degree. At some point the bandwidth over- smoothes the distribution, leading to very high overestimations. The right-hand side shows the mean squared errors. While the general trend of the error function is clearly visible, we can also see that the results are noisy. This poses a difficult to find global optimum as the multitude of local optima has to be overcome. A method that has shown to be very effective in practice are Evolution Strategies. An Evolution Strategy (ES) is a global numeric optimization approach inspired by the Darwinian theory of natural selection. We implemented the approach of Beyer and Schwefel [6]. Here, ? parents produce another set of íì§íì§¬ offspring. From the thus ob- tained set of ? + íì§íì§¬ individuals the best ? individuals a",Michael Mattig,"Department of Mathematics and Computer Science University of Marburg, Germany",mattig@mathematik.uni-marburg.de,Thomas Fober,"Department of Mathematics and Computer Science University of Marburg, Germany",thomas@mathematik.uni-marburg.de,Christian Beilschmidt,"Department of Mathematics and Computer Science University of Marburg, Germany",beilschmidt@mathematik.uni-marburg.de,Bernhard Seeger,"Department of Mathematics and Computer Science University of Marburg, Germany",seeger@mathematik.uni-marburg.de,,,,,,,,,,,,,,,,,,
20200108,1391,Michael Vollmer,"Karlsruhe Institute of Technology (KIT) Karlsruhe, Germany",michael.vollmer@kit.edu,,Iterative Estimation of Mutual Information with Error Bounds,"ABSTRACT Mutual Information (MI) is an established measure for linear and nonlinear dependencies between two variables. Estimating MI is nontrivial and requires notable computation power for high estimation quality. While some estimation techniques allow trad- ing result quality for lower runtimes, this tradeoff is fixed per task and cannot be adjusted. If the available time is unknown in advance or is overestimated, one may need to abort the esti- mation without any result. Conversely, when there are several estimation tasks, and one wants to budget computation time between them, there currently is no efficient way to adjust it dynamically based on certain targets, e.g., high MI values or MI values close to a constant. In this article, we present an itera- tive estimator of MI. Our method offers an estimate with low quality near-instantly and improves this estimate in fine grained steps with more computation time. The estimate also converges towards the result of a conventional estimator. We prove that the time complexity for this convergence is only slightly slower than non-iterative estimation. Additionally, with each step our estimator also tightens statistical guarantees regarding the con- vergence result, i.e., confidence intervals, progressively. These also serve as quality indicators for early estimates and allow to reliably discern between attribute pairs with weak and strong dependencies. Our experiments show that these guarantees can also be used to execute threshold queries faster compared to non-iterative estimation. 1 INTRODUCTION Motivation. Detecting and quantifying dependencies between variables is an essential task in the database community [10, 13, 20, 30]. Conventional methods such as correlation coefficients and covariance matrices only detect linear or monotonous depen- dencies.Mutual Information (MI) in turn is an index that captures any linear and nonlinear dependency [1, 5]. Probability distri- butions of the variables in question serve as input to compute the MI. For real-world data however, these distributions are not available. In this case, MI must be estimated based on samples. Various estimators for MI have been proposed [15, 23, 33], and some offer good results even for small samples [15]. However, continuous variables with an unknown distribution continue to be challenging, since their multivariate distribution is substituted only by a limited sample. A prominent approach for estimation of MI between continuous variables without assumption of the distribution is the nearest-neighbor based method by Kraskov et al. (KSG) [19]. While good estimators are available, they are very rigid in their time requirements and regarding the estimation quality. Once the computation has started, they impose a fixed time requirement and do not yield aby preliminary result if they are terminated ? 2019 Copyright held by the owner/author(s). Published in Proceedings of the 22nd International Conference on Extending Database Technology (EDBT), March 26-29, 2019, ISBN 978-3-89318-081-3 on OpenProceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0. M u tu al  I n fo rm at io n Runtime MIT MIfin tT t tfin Figure 1: MI estimation with dynamic time allocation. prematurely. They also are unable to exploit easier queries like whether the MI value is above a certain threshold but instead determined the value. Such features are highly relevant for high- dimensional data and data streams with irregular arrival rate as we showcase with the following two scenarios. Scenario 1. Consider a modern production plant with smart meters installed on each machine. A first step in data exploration is determining which attributes are strongly dependent. For in- stance dependencies among currents or energy consumption may offer insights into production sequences. For this first step, a query like Which pairs of measurements have a MI value above the thresholdMIT ? often suffices. With conventional MI estima- tors, each pair either induces high computational costs, or results are uncertain because of low estimation quality. Scenario 2. Think of a database with financial data and its real- time analysis. To maintain a diverse portfolio, it is important to track the relationships between stocks. Because bids and trades happen irregularly, new information and market prices arrive at irregular speed. Thus, it is not known how much time is available to monitor stock relationships in the presence of incoming data. Current MI estimators cannot adapt during execution. They risk not producing a result in time, or estimates are of low quality. To improve upon these shortcomings, we study estimation of MI with dynamic allocation of computation time. Ideally, such an estimator should not only offer preliminary results, but also indicate its remaining uncertainty. Figure 1 shows exemplary pro- gression over time of such an estimator based on our experiments with real data. The black line indicates the preliminary estimate after a certain runtime, and the gray area shows the (expected) maximum error of the preliminary estimate. To obtain the defin- itive result MIfin, a user would require time tfin. However, he could also stop the estimator as soon as the estimate is above a threshold MIT with certainty, or he can use the preliminary result available after time t. In this work, we focus on iterative estimation of MI in order to offer this functionality. Here, iterative means quickly providing an estimate, but with the option to improve the estimation if there is time left. In other words, improving the estimate with     Series ISSN: 2367-2005 73 10.5441/002/edbt.2019.08 some time available is what we call an iteration. At the same time, an iterative estimator can terminate the estimation, i.e., stop iterating, when the result is good enough. For efficiency, it is important that computations from previous iterations remain useful and are not repeated or discarded in a later iteration. So far, efficient iterative estimators for MI do not exist. Challenges. The most significant feature of an estimator is its quality of estimation. This is even more so for iterative methods because both preliminary and final estimation quality are important. In other words, the estimate should already be useful after a few iterations, and estimation quality must level up to the one of conventional estimators after many iterations. Ideally, this convergence should happen after a known, finite number of iter- ations. In this article, we target at respective formal guarantees. Next, the quality of preliminary estimates is crucial for us- ability. Determining if a preliminary result is good enough or interesting enough to merit additional computation time requires some information on its certainty. The number of iterations alone is insufficient, as the result quality depends on many other fac- tors such as data characteristics, required accuracy and time con- straints. Instead, each estimate requires an individual indicator of the uncertainty remaining. While the time spent to improve the estimate iteratively is committed dynamically, it must of course be used efficiently. Many conventional estimators use data structures that are ex- pensive to build and cheap to use, such as space-partitioning trees [19, 31, 32]. Such an upfront activity is undesirable for an iterative estimator whose first estimate must arrive soon. At the same time, runtime and scalability do remain important charac- teristics of the estimator. In other words, an iterative estimator must feature guaranteed efficiency for both individual iterations and final estimates. Contributions. In this article, we present IMIE, our Iterative Mutual Information Estimator. To prove its practical usefulness, we establish several features both formally and experimentally. Quality of Estimation. In Section 4, we propose a design for IMIE such that estimates converge to the same value as with the KSG. To make early iterations useful, IMIE also offers statistical error bounds for its early estimates. More precisely, an early estimate provides a confidence interval for the final estimate. We describe the specifics and the statistical soundness in Section 4.3. Complexity. We study the time complexity of initialization and of individual iterations of IMIE. In Section 5 we establish an amor- tized time complexity for IMIE and the nearest-neighbor search used. This complexity is competitive with existing non-iterative estimators. To be precise, we show that iterating IMIE until con- vergence is only slightly slower in terms of time complexity than computing the KSG directly with optimal algorithms. Experimental Validation. We show that IMIE complements the formal guarantees established so far with good actual perfor- mance. To do so, we perform extensive experiments using both synthetic and real data sets in Section 6. On the one hand, we show that the concrete runtime and estimation results of IMIE are comparable to the ones of conventional estimation methods. On the other hand, the experiments show the practical benefits of the early results from IMIE. For instance, IMIE finds attribute pairs above a threshold value significantly faster than non-iterative estimators. 2 RELATEDWORK Iterative estimation ofMI is interesting from two perspectives. On the one hand, it is methodically interesting, as it can be considered an anytime algorithm. On the other hand, it is interesting to consider the benefits it provides over current methods in different settings. Important application scenarios are dependency analysis in high dimensional data and data streams, cf. Scenario 1 and 2. Anytime Algorithms. Anytime algorithms [36] use available time to increase their result quality. One can obtain a low-quality result after a short time and a better one when waiting longer. In data analysis, anytime algorithms exist for clustering [22], classification [35] and outlier detection [2]. So far however, there is no anytime algorithm to estimate MI. So while there is no direct competitor, IMIE extends the set of tools available as anytime algorithms. Additionally, there has been more general work on the optimal use of available anytime algorithms [11, 18], which may improve the performance of IMIE in larger systems. MI on Data Streams. Estimating MI on streams has received some attention recently. The MISE framework [14] summarizes a bivariate stream such that the MI for arbitrary time frames can be queried. To this end, MISE offers parameters for the balance between accuracy of older queries and resource requirements both in terms of memory and computation time. In contrast, the DIMID estimator [4] processes a bivariate stream as sliding win- dow for monitoring tasks. This approach provides fast updates between time steps by approximation with random projection. MI estimation in sliding windows has also been the focus of [32]. That paper provides lower bounds for estimates using Equa- tion 5 both in general and for updates in sliding windows. It also features two dynamic data structures, DEMI and ADEMI, to main- tain such estimates using either simple or complex algorithms and data structures. These approaches have limitations. First, they all impose the necessary execution time, i.e., one cannot adapt this time after the start of stream processing. If the rate of new items increases, the estimator may be unable to keep up. If it decreases, the es- timator cannot use this time to improve results. Second, the ap- proaches are all focused on bivariate streams. While MI is defined for exactly two variables, the number of attribute pairs grows quadratically in the number of dimensions. In contrast, the only information IMIE maintains on a stream is based on individual di- mensions and thus scales linearly with the dimensionality. Third, the approximate results of MISE and DIMID are difficult to use. Their estimation quality is only known on average; this average defines the perceived quality of individual estimates. So if one estimate has a very small error, it is less likely to be appreciated, while the error of a particularly bad estimate may be assumed to be smaller. Dependencies in High Dimensional Data. Even though MI is de- fined for exactly two variables, it hasmany applicationswith high- dimensional data. Prominent ones are image registration [25], which uses MI between two high-dimensional variables, and fea- ture selection [24], which targets at the MI between attributes and a classification label. But estimating the MI between all pairs of attributes has received little attention, despite being the non- linear equivalent of correlation matrices. [26] uses a different approach, i.e., kernel density estimation, and removes redundant computations that arise when using this estimator for each pair. This approach has a worse computational complexity than a pair- wise application of the KSG estimator, without offering better 74 0 1 2 3 4 5 6 7 8 9 1 2 4 3 5 MCy1 (p3) = 2 MCx1 (p3) = 3 y1 (p3) x1 (p3)6 7 p3 p1 p2 p4 p5 p6 X = { 1, 3, 4, 5, 8}6 Y = { 1, 3, 4, 5, 7} 2, x y Figure 2: Illustration of terms used for the KSG. results [15, 23]. While both scale quadratically in the number of attributes, their approach is also quadratic in the number of points. The complexity of the KSG in turn is (n logn) [32]. Ad- ditionally, it does not expose any parameter to modify the result quality. Consequently, there would not be any benefit of a direct experimental comparison with IMIE. 3 FUNDAMENTALS We first cover the background of MI and its estimation. Mutual Information. Shannon has introduced the notion of entropy [28] to quantify the expected information gained from ob- serving a value of a random variable.H (X ) stands for the entropy of a random variable X . The expected information of observing two random variables X and Y is the joint entropy H (X ,Y ). Mu- tual Information quantifies the amount of information that is shared or redundant between the two variables. It is defined as I (X ;Y ) = H (X ) + H (Y ) ? H (X ;Y ). (1) With the definition of entropy for continuous variables [6], the MI of two continuous random variables is I (X ;Y ) =  X  Y pXY (x,y) log ( pXY (x,y) pX (x)pY (y) ) dx dy, (2) where pX ,pY and pXY are the marginal and joint probability density functions of X and Y . The type of logarithm used in Equation 2 determines the unit of measurement. In this work we use the natural logarithm. This means that MI is measured in the natural unit of information (nat). Estimation. One can perceive many sources of data, e.g., smart meters or market prices, as random variables with unknown dis- tribution. Since Equation 2 requires probability density functions, we cannot compute the MI of such sources exactly. Instead, we can only estimate the MI based on available samples. The popular estimator that will serve as foundation of our work is the one by Kraskov, St?gbauer and Grassberger [19], which we call KSG. It is based on the estimator for probability densities by Loftsgaarden and Quesenberry [21], which Kozachenko and Leonenko have studied further in the context of entropy [17]. In the following, we briefly review the terms and computation of the KSG. Let P = {p1 = (xp1 ,yp1 ), . . . ,pn = (xpn ,ypn )}  R 2 be a sample from a random variable with two attributes. Figure 2 illustrates the notions that we define in the following using the sample P = {(1, 5), (6, 1), (5, 4), (4, 7), (3, 3), (8, 2)}. Let X = {xp1 , . . . , xpn } and Y = {yp1 , . . . ,ypn } be the set of values per attribute. For each point p  P , its k  N+ nearest neighbors in P using the maximum distance form the set kNN (p). More formally, it is kNN (p) = argmin S (P\{p }) s .t . |S |=k max s S ~p, s~, (3) with ~p, s~ = max(|xp ? xs |, |yp ? ys |). We define the largest distance between xp and any x-value among the k nearest neigh- bors of p as xk (p) = maxs kNN (p) |xp ?xs |. We use this distance xk (p) to define the x-marginal count MCxk (p) = |{x  (X \ xp ) : |x ? xp |   x k (p)}|, (4) which is the number of points whose x-value is close to p. In Figure 2, vertical dashed lines mark the area of points whose x-values are at least as close as the nearest neighbor of p3. Since this area contains three points excluding p3, it is M x 1 (p3) = 3. The distance  y k (p) and the y-marginal count MC x k (p) are defined analogously. Note that xk (p) and  y k (p) may differ, which results in differently sized areas for the marginal counts, as seen in Figure 2. Using these counts, the KSG estimate is defined as I? (P) = ? (n)+? (k)? 1 k ? 1 n n2. i=1 ? ( MCxk (pi ) ) +? ( MC y k (pi ) ) , (5) where ? is the digamma function. This is ? (z) = ?C + 2.z?1 t=1 1 t for z  N+ and C ? 0.577 being the Euler-Mascheroni constant. While k is a parameter of this estimator, it is generally rec- ommended [15, 16, 19] to use a small k , that is k  10. Gao et al. [9] have proven that the KSG is a consistent estimator for fixed k , that is, it converges towards the true value with increasing sample size. 4 ITERATIVE ESTIMATION In this section we present IMIE, our iterative estimator for MI. The core concept of our approach is considering the KSG estimate itself as the mean of a random variable with a finite population. Using subsamples of this population for early estimates offers beneficial properties such as an expected value equal to the KSG estimate and convergence to the KSG for large sample sizes. We first present IMIE and its underlying data structure as well as the algorithms for the initialization and for subsequent iterations. Then we describe our approach for nearest neighbor search, which is better for iterative algorithms than the standard procedures. Finally, we describe the statistical bounds that IMIE provides with its estimates. 4.1 IMIE For brevity, we introduce some notation in addition to the one from Section 3. For a pointp  P , we define the pointwise estimate (p) = ? ( MCxk (p) ) +? ( MC y k (p) ) . (6) The set of all pointwise estimates is  = {(p1), . . . ,(pn )}. Seeing  as a finite population of size n with mean ? , Equation 5 can be rewritten as I? (P) = ? (n) +? (k) ? 1 k ? ? . (7) Using a (random) subsample ?  , its mean ?? is an (unbiased) estimation of ? . This in turn yields an (unbiased) estimate of I? (P), I?? (P) = ? (n) +? (k) ? 1 k ? ?? . (8) 75 Data Structure 1: IMIE struct { Point[] P Real Mean, Var Int k,m Int[] OrderR , Orderx , Ordery Real Offset }; Algorithm 2: Init (P,k) 1 Persist k and P O(n) 2 Mean, Var,m $ 0 O(1) 3 OrderR , Orderx , Ordery $ (0, 1, . . . , |P | ? 1) O(n) 4 Sort Orderx and Ordery O(n logn) 5 Offset$ ? (|P |) +? (k) ? 1k O(1) The variance  2? of our subsample serves as a quality indicator of this approximation, which we further discuss in Section 4.3. The idea of IMIE is to maintain a subsample ? and use I?? (P) to estimate I? (P). Each iteration then increases the sample size of ? by one, to improve the estimate. Starting with an empty set, this means there are exactly |P | iterations before IMIE yields exactly the same result as the KSG, i.e., I?? (P) = I? (P). Data Structure. IMIE uses and stores P and k as well as some additional information listed in Data Structure 1. In the following we use the zero-indexed array notation P[i] = pi+1. Contrary to the original data sample P , we do not store ? explicitly. In- stead we store its mean Mean, its variance Var and size, which is the number of performed iterationsm. To maintain the current variance efficiently, we use the online algorithm by Welford [34]. To ensure that ? is a random subsample of , we need to draw without replacement. To this end, IMIE maintains an array of indices OrderR , where index i at position j means that (pi ) is added to ? in the j-th iteration. The positions of this array are randomly swapped during iterations to perform the random se- lection. This enables a fast selection of a random element without replacement in each iteration. In addition, we maintain two ar- rays Orderx and Ordery containing references to all points in P ordered by their x- and y-value, respectively. For instance, in- dex i at Orderx [0] means that pi has the smallest x-value in P , i.e., pi = argminpP xp . These ordered arrays are used to find nearest neighbors, as described in Section 4.2. Finally, we store the Offset = ? (n) + ? (k) ? 1k . With this, the (preliminary) MI estimate is available as I?? (P) = Offset ?Mean. Methods. We now present the two methods Init and Iterate. See Algorithms 2 and 3, together with amortized time complexi- ties, derived in Section 5. Init ensures the proper state of Data Structure 1 before the first iteration, i.e., preparing all variables assuming that |? | = 0. Observe that Init is a straightforward method for the simple case of static data with two attributes. For other scenarios, such as high-dimensional or streaming data, some adjustments to the initialization may be appropriate, as discussed in Section 5.3. Iterate increases the size of sample ? by one. This requires computing (p) for a random p  P with (p) < ?. Iterate consists of three phases. In the first one (Lines 1-3), we select a random point p of P that has not been selected earlier. After Algorithm 3: Iterate 1 ID$ Draw random integer from [m,n ? 1] O(1) 2 Swap values of OrderR [m] and OrderR [ID] O(1) 3 p $ P[OrderR [m]] O(1) 4 kNN (p) $ NNSearch(p) (see Algorithm 4) O(  n) 5 Compute xk (p),  y k (p) O(1) 6 ComputeMCxk (p),MC y k (p) O(logn) 7 (p) $ ? ( MCxk (p) ) +? ( MC y k (p) ) O(1) 8 m $m + 1 O(1) 9 Diff old $ (p) ? Mean O(1) 10 Mean$ Mean + Diff old m O(1) 11 Diff new $ (p) ? Mean O(1) 12 Var $ Var(m?1)+Diff old Diff new m O(1) m ? 1 iterations, we swap the index at position m of OrderR with the index at a random position behindm ? 1. This ensures that we do not use any index twice, since positions before m are not considered, and that each unused index has the same probability of being selected. This random swap is one step of the Fisher-Yates Shuffle in the version of Durstenfeld [8], which fully randomizes the order of a sequence. The second phase (Lines 4-7) computes (p) using the ordered lists Orderx and Ordery . The last phase (Lines 8-12) performs the online algorithm [34] to maintain mean and variance of a sample, in our case ?. Example 4.1. Disregarding the dashed lines for now, Figure 3 illustrates the state of Data Structure 1 after initialization and before the first iteration. For the first iteration, we draw an in- teger ID from {0, . . . ,n ? 1}. Suppose that we drew 5. We swap the content of OrderR [0] and OrderR [5]. OrderR [0] now contains 6. This means that this iteration adds (p6) to our implicit sam- ple ?. We then determine its nearest neighbor 1NN (p6) = {p15}, the distances x 1 (p6) and  y 1 (p6) as well as the marginal counts MCx 1 (p6) = 1 andMC y 1 (p6) = 3. The dashed lines in Figure 3 illus- trate the area of counted points in x and y-direction, respectively, identically to Figure 2. It follows that (p6) = ? (1)+? (3) = 0.346. Substituting the appropriate variables, the remaining values are set accordingly, i.e.,m = 0+ 1 = 1,Mean = 0+ 0.346 1 = 0.346 and Var = 00+00.346 1 = 0. The second iteration is analogous, draw- ing ID = 6 at random from {1, . . . ,n ? 1}, thus choosing p7. Its nearest neighbor is p8, and the marginal counts areMC x 1 (p7) = 1 andMC y 1 (p7) = 6, cf. the dashed lines in Figure 4. As a result, it is (p7) = ? (1)+? (6) = 1.129. Analogously to the first iteration, the remaining values arem = 1+1 = 2,Mean = 0.346+ 0.783 2 = 0.738 and Var = 01+0.7830.391 2 = 0.153. Figure 4 graphs the state of Data Structure 1 after both iterations, and the new MI estimate is 1.164 ? 0.738 = 0.426. 4.2 Nearest-Neighbor Search A computation-intensive step in Iterate is the computation of nearest neighbors, which also is a key step for static estima- tion with the KSG. The classic solution [19, 31] is using space- partitioning trees, which are optimal in terms of computational complexity [32]. This efficiency is achieved because the slow tree construction is performed once, and each nearest-neighbor search afterwards is fast. Contrary to the traditional KSG esti- mation, it is not known beforehand how many nearest-neighbor searches IMIE performs. Constructing such a tree for IMIE would 76 Mean = 0 Var = 0.153 m = 0 X Y p1 p7 p13p2 p9 p14 p3 9 2 5 10 4 14 3 1 121115 6 16 8 713 92 5104 14 3112 1115 6 168713 P Orderx Ordery OrderR k = 1 Offset = 1.164p12p4 p10 p8 p11 p15 p5 p6 p16 92 5 104 1431 1211 156 1687 13 Figure 3: State of IMIE after initialization. X Y p1 p7 p13p2 p9 p14 p3 9 2 5 10 4 14 3 1 121115 6 16 8 713 92 5104 14 3112 1115 6 168713 P Orderx Ordery OrderR k = 1 Offset = 1.164p12p4 p10 p8 Mean = 0.738 Var = 0 m = 2 925 104 143 1 1211 156 1687 13 p11 p15 p5 p6 p16 Figure 4: State of IMIE after two iterations ((p6) and (p7)). not only delay the first estimate, but may also be an inefficient choice overall if only few iterations take place. The opposite, i.e., searching nearest neighbors without any preparation, is a linear search. Each iteration would then require time linear in the num- ber of data points. Since IMIE should offer both fast iterations and preliminary estimates after a short time, our approach is a compromise between these two options. The general idea is to use sorted arrays to perform a guided linear search that offers a good amortized time complexity (cf. Section 5). In the following, we elaborate on our NNSearch approach. Let p be the point whose nearest neighbor we are searching for and q the nearest neighbor we have found so far. Then any point r with |xp ?xr | > ~p?q~ cannot be a nearest neighbor with the maximum norm. This means that we only have to consider the interval [xp ? ~p?q~, xp + ~p?q~] in the sorted array Orderx . When we find a closer point during the search, this interval gets smaller, and fewer points need to be considered. For the y-values, this is analogous. To reduce the number of worst-case scenarios, we perform this search simultaneously in both directions and terminate when either one terminates. See Algorithm 4 for an algorithmic description of NNSearch. Example 4.2. Figure 5 illustrates an exemplary run of this procedure for k = 1. The figure shows four states corresponding to the variables of NNSearch(p) after 0, . . . , 3 loops. The query point p is the filled square, and a projection of the points to their x- and y-coordinates is shown at the bottom and the left side, respectively. These projections indicate the order of points in Orderx and Ordery , respectively. Each state after the first loop also illustrates the variables of NNSearch. The nearest neighbor found so far is marked with a circle and is labeled NN , and the distance max = ~p ? NN ~ is used for the dashed lines that highlight the remaining area of nearest neighbor candidates. Points accessed via Orderx in a previous iteration are marked with a diagonal stripe from the upper left to the lower right. This is done analogously for Ordery . Each loop considers the next loops = 0 X Y p loops = 0 X Y max ?y? ?y+ ?x+ ?x? p 1 NN NN loops = 0 X Y ?y+ ?y? ?x+ ?x? p 2 max NN loops = 0 X Y ?y+ ?y? ?x+ ?x? p 3 max Figure 5: Illustration of Algorithm 4 for each loop. unmarked point in both directions for both Orderx and Ordery . Additionally, the small arrows illustrate the minimal distances ?? for any further point accessed when iterating over Orderx or Ordery in the respective direction. After the third loop, the arrows of ?y+ and ?y? both exceed the area of the remaining candidates, represented by the dashed lines. This means that all relevant candidates have been considered via Ordery , and that the current nearest neighbor is correct. 4.3 Statistical Quality Indicators Finally we present statistical guarantees for early estimates by IMIE. Since ? is a subsample of , statistical tests with ?? and  2 ? yield statistically significant assertions regarding ? . Equations 7 and 8 give way to analogous assertions for I? (P). Theorem 4.3 ([27]). Let  be a finite population of size n with mean ? and a variance  2  . When drawing an i.i.d. sample ? of size m from , the sample mean ?? has an expected value of E(?? ) = ? and a variance of  2?? =  2 m ( n?m n?1 ) . Proof. See [27].  While the classic version of the Central Limit Theorem is not formulated for finite populations, it has been proven that some variations are applicable, and that ?? is approximately normally distributed [27]. In other words, drawing a sample of sizem with a sample mean ? is as likely as drawing ? from N(? ,?? ) with ?? =   2?? . So we can estimate the probability that a sample mean ?? is off by more than a specified value ? > 0 by using the cumulative distribution function  of the standard normal distributionN(0, 1). This is illustrated in Figure 6 and is formally described as Pr[|?? ? ? | ? ?] = 2   ( ?? ?? ) . (9) 77 Algorithm 4: NNSearch(p) 1 ix , iy $ index of p in Orderx , Ordery , respectively 2 ?x+,?x?,?y+,?y?, loops$ 0 3 max $ 4 NN $ {} 5 while min(?x?,?x+) < max m",Michael Vollmer,"Karlsruhe Institute of Technology (KIT) Karlsruhe, Germany",michael.vollmer@kit.edu,Klemens B?hm,"Karlsruhe Institute of Technology (KIT) Karlsruhe, Germany",klemens.boehm@kit.edu,,,,,,,,,,,,,,,,,,,,,,,,
20200109,1393,Chris Mayfield,"Purdue University West Lafayette, Indiana, USA",cmayfiel@cs.purdue.edu,,ERACER: A Database Approach for Statistical Inference and Data Cleaning,"ERACER: A Database Approach for Statistical Inference and Data Cleaning, ERACER: A Database Approach for Statistical Inference and Data Cleaning, ERACER: A Database Approach for Statistical Inference and Data Cleaning, ERACER: A Database Approach for Statistical Inference and Data Cleaning, ERACER: A Database Approach for Statistical Inference and Data Cleaning, ABSTRACT Real-world databases often contain syntactic and semantic errors, in spite of integrity constraints and other safety measures incorporated into modern DBMSs. We present ERACER, an iterative statistical framework for inferring missing information and correcting such errors automatically. Our approach is based on belief propagation and relational dependency networks, and includes an efficient ap- proximate inference algorithm that is easily implemented in standard DBMSs using SQL and user defined functions. The system performs the inference and cleansing tasks in an integrated manner, using shrinkage techniques to infer correct values accurately even in the presence of dirty data. We evaluate the proposed methods empirically on multiple synthetic and real-world data sets. The results show that our framework achieves accuracy comparable to a baseline statistical method using Bayesian networks with exact inference. However, our framework has wider applicability than the Bayesian network baseline, due to its ability to reason with complex, cyclic relational dependencies. Categories and Subject Descriptors H.2.8 [Database Applications]: Statistical Databases; H.4 [Information Systems Applications]: Miscellaneous General Terms Algorithms, Experimentation, Performance Keywords Relational dependency network, approximate inference, dis- crete convolution, linear regression, outlier detection 1. INTRODUCTION Although the database community has produced a large amount of research on integrity constraints and other safety measures to ensure the quality of information stored in relational database management systems (DBMSs), real-world databases often contain a significant amount of non-trivial errors. These errors, both syntactic and semantic, are gen- erally subtle mistakes which are difficult or even impossible to express using the general types of constraints available in modern DBMSs. In addition, quality control on data in- put is decreasing as collaborative efforts increase, with the Internet facilitating widespread data exchange, collection, and integration activities. Clearly, there is an increasing need for new approaches to data cleaning for the purpose of maintaining quality in relational databases. Data cleaning (or cleansing, scrubbing, etc.) is the process of identifying and repairing incorrect or corrupt records in a database. The goal is not only to bring the database into a consistent state (i.e., with respect to domain or in- tegrity constraints), but also to ensure an accurate and com- plete representation of the real-world constructs to which the data refer. Two surveys of common techniques and general challenges in this research area include [16] and [22]. Removing impurities from data is traditionally an engineering problem, where ad-hoc tools made up of low-level rules and manually-tuned algorithms are designed for specific tasks. However, recent work has shown the the effectiveness of ap- plying techniques from machine learning and data mining for the purpose of data cleaning [7]. In particular, statis- tical methods make it possible to automate the cleansing process for a variety of domains. For this work we develop statistical methods for cleaning relational databases with the following characteristics: ? Incomplete and erroneous: There are both (1) missing values to be filled in, and (2) corrupted val- ues to be identified. This goes beyond traditional statistical methods which make assumptions about the reliability of the non-missing values. ? Correlated attributes: The values of different at- tributes are correlated, both within and across tuples (involving perhaps multiple relations). Much of the prior work in data cleaning concentrates on values within a single tuple or relation. ? High-level dependencies: The attributes with large domains (i.e., many possible values), exhibit higherlevel dependencies among sets of similar values (for categorical variables) or a numerical functional depen- dency (for continuous variables). As an example of this type of domain, consider the task of inferring missing birth and death years of individuals in genealogical databases. The individuals are related through 75 parent-child relationships and the birth and death years of an individual are correlated due to life expectancies. In ad- dition, the birth dates of parents and children are correlated due to expected parenting ages. Furthermore, since life ex- pectancies and parenthood ages are likely to be similar over time, the dependencies do not need to be modeled for specific birth years. Instead they can be modeled as a higher-level functional dependency such as birth year = parent 's birth year + . A statistical method can learn these dependencies from the available data and then use them to infer missing values automatically. As another example, consider the task of inferring missing data in sensor networks. There are often relationships among the different types of measurements in the same sen- sor (e.g., temperature and humidity), as well as relationships among the measurements of neighboring sensors due to spa- tial locality. Again, a statistical method could learn these dependencies from observed data and then use them to infer missing values (e.g., due to battery loss) and/or clean corrupt values (e.g., due to sensor malfunction). Such a method can also be used for anomaly detection and intrusion detec- tion systems. This paper introduces ERACER, a database-centric statistical framework for integrated data cleaning and imputa- tion. The core techniques are based on belief propagation [20] and relational dependency networks [18]. We show how to implement the inference and cleaning processes efficiently at the database level. This eliminates the expensive process of migrating the data to and from statistical software such as R or Matlab, which is particularly useful when the amount of data aor limited processing time and resources aprevents a more extensive analysis. In contrast to prior work that cleans values within a single tuple, our approach exploits the graphical structure of the data to propagate inferences throughout the database. As a result the imputation and cleaning tasks go hand in hand: additional information in the database helps identify errors more accurately, and cor- rected data values improve the quality of inference for the missing values.",Chris Mayfield,"Purdue University West Lafayette, Indiana, USA",cmayfiel@cs.purdue.edu,Jennifer Neville,"Purdue University West Lafayette, Indiana, USA",neville@cs.purdue.edu,Sunil Prabhakar,"Purdue University West Lafayette, Indiana, USA",sunil@cs.purdue.edu,,,,,,,,,,,,,,,,,,,,,
20200110,1394,Alexander Hall,"Google, Inc.",alexhall@google.com,,Processing a Trillion Cells per Mouse Click,"Processing a Trillion Cells per Mouse Click, Processing a Trillion Cells per Mouse Click, Processing a Trillion Cells per Mouse Click, Processing a Trillion Cells per Mouse Click, Processing a Trillion Cells per Mouse Click, ABSTRACT Column-oriented database systems have been a real game changer for the industry in recent years. Highly tuned and performant systems have evolved that provide users with the possibility of answering ad hoc queries over large datasets in an interactive manner. In this paper we present the column-oriented datastore developed as one of the central components of PowerDrill1. It combines the advantages of columnar data layout with other known techniques (such as using composite range partitions) and extensive algorithmic engineering on key data structures. The main goal of the latter being to reduce the main memory footprint and to increase the efficiency in processing typical user queries. In this combination we achieve large speed-ups. These enable a highly interactive Web UI where it is common that a single mouse click leads to processing a trillion values in the underlying dataset. 1. INTRODUCTION In the last decade, large companies have been placing an ever increasing importance on mining their in-house databases; often recognizing them as one of their core assets. With this and with dataset sizes growing at an enormous pace, it comes as no surprise that the interest in column- oriented databases (column-stores) has grown equally. This spawned several dozens of research papers and at least a dozen of new column-store start-ups, cf. [2]. This is in ad- dition to well established offerings, e.g., by MonetDB [25], Netezza [26], or QlikTech [30]. Since 2011 all major commer- cial database vendors actually provide column-store tech- nologies (cf. [25]). Typically, these products are deployed to import existing databases into the respective column-store. An OLAP or OLTP, i.e., SQL, interface is provided to then mine the data interactively. The key advantage shared by these systems is that column-oriented storage enables reading only data for  relevant columns. Obviously, in denormalized datasets with often several thousands of columns this can make a huge difference compared to the the row-wise storage used by most database systems. Moreover, columnar formats compress very well, thus leading to less I/O and main memory usage. At Google multiple frameworks have been developed to support data analysis at a very large scale. Best known and most widely used are MapReduce [13] and Dremel [23]. Both are highly distributed systems processing requests on thou- sands of machines. The latter is a column-store providing interactive query speeds for ad hoc SQL-like queries. In this paper we present an alternative column-store de- veloped at Google as part of the PowerDrill project. For typical user queries originating from an interactive Web UI (developed as part of the same project) it gives a perfor- mance boost of 10?100x compared to traditional column- stores which do full scans of the data. Background Before diving into the subject matter, we give a little back- ground about the PowerDrill system and how it is used for data analysis at Google. Its most visible part is an interactive Web UI making heavy use of AJAX with the help of the Google Web Toolkit [16]. It enables data visualization and exploration with flexible drill down capabilities. In the back- ground, the ""engine"" provides an abstraction layer for the UI based on SQL: the user constructs charts via drag'n'drop op- erations, they get translated to group-by SQL queries, which the engine parses and processes. It can send out such queries to different backends, e.g., Dremel, or execute them directly on data stored, e.g., in CSV files, record-io files (binary for- mat based on protocol buffers [29]), or in Bigtable [10]. The third large part of the project is the column-store presented in this paper. The Web UI is very versatile; it allows to select arbitrary dimensions, measures, and computed values for grouping and filtering. The dimensions can have a large number of distinct values, such as strings representing Google searches. A user can quickly drill down to values of interest, e.g., all German searches from yesterday afternoon that contain the word ""auto"", by restricting a set of charts to these values. For these reasons, pre-aggregation or indexing of data does not help and we need to query the raw data directly. The nature of the use cases enabled by this UI demand for high availability and low latency. Examples of such use cases include: Responding to customer requests, spam anal- ysis, dealing with alerts in highly critical revenue systems, or monitoring and assessing changes to production systems. The system has been in production since end of 2008 and  was made available for internal users across all of Google mid 2009. Each month it is used by more than 800 users sending out about 4 million SQL queries. After a hard day's work, one of our top users has spent over 6 hours in the UI, triggering up to 12 thousand queries. When using our column-store as a backend, this may amount to scanning as much as 525 trillion cells in (hypothetical) full scans. The column-store developed as part of PowerDrill is tai- lored to support a few selected datasets and tuned for speed on typical queries resulting from users interacting with the UI. Compared to Dremel which supports thousands of dif- ferent datasets (streaming the data from a distributed file system such as GFS [15]), our column-store relies on having as much data in memory as possible. PowerDrill can run interactive single queries over more rows than Dremel, how- ever the total amount of data it can serve is much smaller, since data is kept mostly in memory, whereas Dremel uses a distributed file system. This and several other important distinctions, enable han- dling very large amounts of data in interactive queries. Consider a typical use case such as triggering 20 SQL queries with a single mouse click in the UI. In our production sys- tem on average these queries process 782 billion cells in 30-40 seconds (under 2 seconds per query), several orders of mag- nitude faster than what a more traditional approach as used by Dremel could provide. Contributions The main contributions presented in this paper: ? We describe how-unlike in most column-stores-the data is partitioned and organized in an import phase (Section 2.2). This enables skipping and caching large parts of the data: on average in production 92.41% is skipped and 5.02% cached, leaving only 2.66% to be scanned (see also Section 6). ? We present the basic data-structures used in Section 2.3. Their main goal is to support the partitioned layout of the data and to enable quick skipping of chunks of data. For optimal usage it is assumed they can be held in memory. Experiments show that these simple data-structures also directly give performance benefits of around 100x or more on full scans, compared to two row-wise stor- age formats and Dremel's column-store (Section 2.5). Note that for these experiments we do not partition the data at import. When dropping the ""in memory"" assumption, a still impressive factor of 30x can be achieved. ? In Section 3 we present several successive ""algorithmic engineering"" choices to improve key data-structures. The aim being to reduce the memory footprint for certain typical cases. We pin-point the effects of individ- ual optimizations with experiments measuring mem- ory usage. E.g., for the important case of a field with many distinct values, we obtain a reduction of 16x. ? In Section 4 we describe how queries may be computed in a distributed manner on a cluster of machines. In Section 5 we present selected extensions and finally in Section 6 the highly distributed setup of the actual productionized system running on over 1000 machines. We give measurements concerning the usage in prac- tice which show the positive effect of the partitioning (enabling to skip or cache large parts of the data). Related Work For an introduction to OLAP and basic techniques applied in data-warehouse applications, see the Chaudhuri and Dayal [11]. To obtain an overview of recent work on column-store architectures, please see the concise review [2] and references therein. The excellent PhD thesis by Abadi [1] can serve as a more in-depth introduction and overview of the topic. Recent research in this area includes, e.g., work on how super-scalar CPU architectures affect query processing [9], tuple reconstruction [17], compression in column-stores [34, 9, 3], and a comparison to traditional row-wise storage [4]. Kersten et al. [20] give a more open ended outlook on inter- esting future research directions. The plethora of open-source and commercial column-store systems, e.g., [34, 25, 26, 30, 36] further demonstrates the effectiveness of this paradigm. Melnik et al. [23] recently have introduced Dremel to a wider audience. As mentioned, its power lies in providing interactive responses to ad hoc SQL queries over thousands of datasets. It achieves this by streaming over petabytes of data (stored, e.g., on GFS [15]) in a highly distributed and efficient manner. This is also a key difference to the column-store presented in this paper which heavily relies on having as much data in memory as possible and therefore only is used for a few selected data sources. Melnik et al. also give a nice overview of data anlysis at Google and how interactive approaches like Dremel's complement the offline MapReduce [13] framework. Skipping over data in the context of colum-stores has been explored by other authors, e.g., Slezak et al. [32] or Mo- erkotte [24]. We give some details on these approaches in comparison to ours in Section 2.1. Reordering rows to improve the compression of column- wise stored data has been investigated, e.g., by [18, 21, 3]. We give some details on this at the end of Section 3. Notation and Simplifying Assumptions For the remainder of the paper we will only consider im- porting and processing data from single tables; which, e.g., correspond to log files at Google in the ""protocol buffers"" format [29] or result from denormalizing a set of relational tables in a database. We refer to such an instance as table or just the data which has columns (also referred to as fields) and rows (also referred to as records). In order to store pro- tocol buffer records with nested and repeated records (i.e., lists of sub-records), PowerDrill supports a nested relational model, cf. [5]. For ease of exposition, in the following we focus on unstructured / flat records as opposed to records which may, e.g., contain lists.",Alexander Hall,"Google, Inc.",alexhall@google.com,Olaf Bachmann,"Google, Inc.",olafb@google.com,Robert Bu ?ssow,"Google, Inc.",buessow@google.com,Silviu Ga ?nceanu,"Google, Inc.",silviu@google.com,Marc Nunkesser,"Google, Inc.",marcnunkesser@google.com,,,,,,,,,,,,,,,
20200111,1395,Bahman Bahmani,Stanford University,bahman@stanford.edu,,Fast Personalized PageRank on MapReduce,"Fast Personalized PageRank on MapReduce, Fast Personalized PageRank on MapReduce, Fast Personalized PageRank on MapReduce, Fast Personalized PageRank on MapReduce, Fast Personalized PageRank on MapReduce, ABSTRACT In this paper, we design a fast MapReduce algorithm for Monte Carlo approximation of personalized PageRank vectors of all the nodes in a graph. The basic idea is very efficiently doing single random walks of a given length start- ing at each node in the graph. More precisely, we design a MapReduce algorithm, which given a graph G and a length \lamda, outputs a single random walk of length \lamda starting at each node in G. We will show that the number of MapReduce iterations used by our algorithm is optimal among a broad family of algorithms for the problem, and its I/O efficiency is much better than the existing candidates. We will then show how we can use this algorithm to very efficiently ap- proximate all the personalized PageRank vectors. Our em- pirical evaluation on real-life graph data and in production MapReduce environment shows that our algorithm is significantly more efficient than all the existing algorithms in the MapReduce setting. Categories and Subject Descriptors G.2.2 [Discrete Mathematics]: Graph Theory-Graph al- gorithms; F.1.2 [Computation By Abstract Devices]: Modes of Computation-Parallelism and concurrency General Terms Algorithms, Design, Performance, Experimentation Keywords Personalized PageRank, MapReduce 1. INTRODUCTION Very large scale datasets and graphs are ubiquitous in today's world: world wide web, online social networks, and ?Work done while visiting Microsoft Research. (15)Work done while at Microsoft Research.  huge search and query-click logs regularly collected and pro- cessed by search engines. Because of the massive scale of these datasets, doing analyses and computations on them is infeasible for individual machines. Therefore, there is a growing need for distributed ways of storing and processing these datasets. MapReduce, a simple model of computation, first introduced by Dean and Ghemawat [9], has recently emerged as a very attractive way of doing such analyses. Its effectiveness and simplicity has resulted in its implementation by different internet companies [9, 13, 5, 22], and widespread adoption for a wide range of applications [19], including large scale graph computations [15, 16]. One of the most well known graph computation problems is computing personalized PageRanks (PPR) [12]. Personal- ized PageRanks (and other personalized random walk based measures) have proved to be very effective in a variety of ap- plications, such as link prediction [17] and friend recommen- dation [3] in social networks, and there are many algorithms designed to approximate them in different computational models [14, 3, 10, 25]. In this paper, we study the problem of Fully Personalized PageRank (FPPR) approximation on MapReduce. Specifi- cally, we study the problem of approximating the personalized PageRank vectors of all nodes in a graph in the MapRe- duce setting, and present a fast MapReduce algorithm for Monte Carlo approximation of these vectors. Even though some of the previously designed personalized PageRank approximation algorithms can be implemented in MapReduce, we will show that our algorithm takes much better advantage of the parallel computation model of MapReduce and is hence significantly more efficient than the existing candi- dates in this setting. We also note that our algorithm can be used for computing other personalized random walk based measures (such as personalized SALSA [3]) in MapReduce as well. In this introduction, we first provide some background on personalized PageRank and MapReduce, and then give the problem statements, and also outline our results. 1.1 Background Here we review personalized PageRank, the Monte Carlo approach for PageRank computation, and MapReduce. Here, and throughout the paper, we assume to have a weighted directed graph G = (V,E) with n nodes and m edges. We denote the weight on an edge (u, v) \forall E with u,v and, for the sake of simplifying the presentation of some of the for- mulae, assume for the rest of the paper that the weights on the outgoing edges of each node sum up to 1. 973 1.1.1 Personalized PageRank PageRank is the stationary distribution of a random walk that at each step, with a probability , usually called the tele- port probability, jumps to a random node, and with proba- bility 1? follows a random outgoing edge from the current node. Personalized PageRank is the same as PageRank, ex- cept all the random jumps are done back to the same node, denoted as the ""source"" or ""seed"" node, for which we are personalizing the PageRank. One can easily see that the personalized PageRank of node v, with respect to a source node u, denoted by (v), satis- fies: (v) = u(v) + (1 ? ) 2. {w|(w,v)\forallE} (w)w,v (1) Where u(v) = 1 if and only if u = v (and 0 otherwise). The fully personalized PageRank computation problem is to compute all the vectors ?"" u for all u \forall V . Of course, most applications, such as friend recommendation or query suggestion, only require the top-k values (and corresponding nodes) in each PPR vector (for some suitable value of k). 1.1.2 Monte Carlo Approach There are two broad approaches to computing Personal- ized PageRank. The first approach is to use linear alge- braic techniques, such as Power Iteration [23]. The other approach is Monte Carlo, where the basic idea is to approx- imate Personalized PageRanks by directly simulating the corresponding random walks and then estimating the sta- tionary distributions with the empirical distributions of the performed walks. Based on this idea, Fogaras et al [10] and later Avrachenkov et al [2] proposed the following method for PPR approximation: Starting at each node u \forall V , do a number, R, of random walks starting at u, called ""finger- prints"", each having a length geometrically distributed as Geom( ). Then, the frequencies of visits to different nodes in these fingerprints will approximate the personalized PageR- anks. Our algorithm also belongs to the Monte Carlo family. 1.1.3 MapReduce MapReduce [9] is a simple computation model for process- ing huge amounts of data in massively parallel fashion, using a large number of commodity machines. By automatically handling the lower level issues, such as job distribution, data storage and flow, and fault tolerance, it provides a simple computational abstraction. In MapReduce, computations are done in three phases. The Map phase reads a collection of values or key/value pairs from an input source, and by invoking a user defined Mapper function on each input element independently and in parallel, emits zero or more key/value pairs associated with that input element. The Shuffle phase groups together all the Mapper-emitted key/value pairs sharing the same key, and outputs each distinct group to the next phase. The Reduce phase invokes a user-defined Reducer function on each distinct group, independently and in parallel, and emits zero or more values to associate with the group's key. The emitted key/value pairs can then be written on the disk or be the input of a Map phase in a following iteration. 1.2 Problem Statement In this paper, we study the problem of FPPR approxi- mation on MapReduce (FPPR-MapReduce): Design an efficient MapReduce algorithm that given a weighted directed graph G = (V,E), approximately computes the personalized PageRank vectors ?"" of all nodes u \forall V . As stated earlier, we adopt the Monte Carlo approach, which requires simulating a number, R, of random walks (fingerprints) from each node. Therefore, we will need to solve the following sub-problem, that we call the Single Ran- dom Walk problem (SRW-MapReduce): Design a MapRe- duce algorithm that given a graph G and a length \lamda, outputs one random walk of length \lamda starting from each node in the graph. 1.3 Our Contribution Intuitively speaking, to fully leverage the power of par- allel computation supported by MapReduce, a good algo- rithm should have the following properties: (1) high parallelization and (2) small number of MapReduce iterations. The Monte Carlo approach for FPPR approximation natu- rally has the first property, as any fingerprint starting at any source node can be computed in parallel with and independently from all other fingerprints (for the same or different source nodes). However, as pointed out in [10], some of the fingerprints may be very long, and hence require a large number of MapReduce iterations using the straightforward implementation (e.g., one MapReduce iteration for each step in the walk). For instance, with = 0.2, a fingerprint can be longer than 10 steps with probability 0.11, and can be longer than 20 steps with probability 0.012. These long walks will become the bottleneck of the algorithm, blocking the entire computation, and causing it to take too long to run. In this paper, we develop an algorithm to compute single random walks of a given length for all nodes in a graph, and show that it is optimal in terms of the number of MapReduce iterations among a broad class of algorithms. Based on that, we then develop an efficient algorithm to approximate fully personalized PageRanks on MapReduce, and also analyze its I/O cost. Our empirical evaluation on real-life graph data and in production MapReduce environment demonstrates that our algorithm outperforms the state of the art FPPR approximation algorithms, in terms of efficiency and approx- imation error. The rest of the paper is organized as follows. Section 2 gives the background for computing FPPR on MapReduce. The single random walk algorithm is presented in section 3, and the FPPR approximation algorithm is presented in section 4. We show experimental results in section 5, review the related work in section 6, and finally conclude this paper in section 7.",Bahman Bahmani,Stanford University,bahman@stanford.edu,Kaushik Chakrabarti,Microsoft Research,kaushik@microsoft.com,Dong Xin,Google Inc.,dongxin@google.com,,,,,,,,,,,,,,,,,,,,,
20200112,1396,Robert Fink,"Deptartment of Computer Science, University of Oxford Wolfson Building, Parks Road, OX1 3QD Oxford, UK",robert.fink@cs.ox.ac.uk,,Aggregation in Probabilistic Databases via Knowledge Compilation,"Aggregation in Probabilistic Databases via Knowledge Compilation, Aggregation in Probabilistic Databases via Knowledge Compilation, Aggregation in Probabilistic Databases via Knowledge Compilation, Aggregation in Probabilistic Databases via Knowledge Compilation, Aggregation in Probabilistic Databases via Knowledge Compilation, ABSTRACT This paper presents a query evaluation technique for positive relational algebra queries with aggregates on a representation system for probabilistic data based on the algebraic structures of semiring and semimodule. The core of our eval- uation technique is a procedure that compiles semimodule and semiring expressions into so-called decomposition trees, for which the computation of the probability distribution can be done in time linear in the product of the sizes of the probability distributions represented by its nodes. We give syntactic characterisations of tractable queries with aggregates by exploiting the connection between query tractabil- ity and polynomial-time decomposition trees. A prototype of the technique is incorporated in the prob- abilistic database engine SPROUT. We report on performance experiments with custom datasets and TPC-H data. 1. INTRODUCTION This paper considers the evaluation problem for queries with aggregates on probabilistic databases. The utility of aggregation has been argued for at length. In particular, aggregates are crucial for OLAP and decision support systems. All 22 TPC-H queries involve aggregation. Probabilistic databases are useful to represent and query imprecise and uncertain data, such as data acquired through measurements, integrated from multiple sources, or produced by information extraction [21]. In this paper, we use a rep- resentation system for probabilistic data called pvc-tables. It is based on the algebraic structures of semiring and semi- module to support a mixed representation of aggregated val- ues and tuple annotations for different classes of annotations and aggregations [2]. The pvc-tables can represent any fi- nite probability distribution over relational databases. In addition, the results of queries with aggregates can be represented as pvc-tables of polynomial size. This contrasts with main-stream representation systems such as pc-tables [21], which can require an exponential-size overhead [15]. The problem of query evaluation is #P-hard already for simple conjunctive queries [21]. Aggregates are a further source of computational complexity: for example, already deciding whether there is a possible world in which the SUM of values of an attribute equals a given constant is NP-hard. Existing approaches to aggregates in probabilistic databases have considered restricted instances of the problem: they fo- cus on aggregates over one probabilistic table of restricted expressiveness [4, 20, 16], or rely on expected values and Monte-Carlo sampling [10, 12, 22]. Expected values can lead to unintuitive query answers, for instance when data values and their probabilities follow skewed and non-aligned distributions [19]. Abiteboul et al. investigate XML queries with aggregates on probabilistic data [1]. An algebra pro- posed by Koch represents annotations and data values as rings which enables efficient incremental view maintenance in the presence of aggregations [13]. Our approach considers the problem of exact probabil- ity computation for positive relational algebra queries with aggregates on pvc-tables. The core of our technique is a procedure that compiles arbitrary semimodule and semiring expressions over random variables into so-called decompo- sition trees, for which the computation of the probability distribution can be done in polynomial time in the size of the tree and of the distributions at its nodes. Decomposition trees are a knowledge compilation technique [5] that reflects structural decompositions of expressions into independent and mutually exclusive sub-expressions. Flavours of decomposition trees have been proposed as compilation target for propositional formulas that arise in the evaluation of relational algebra queries (without aggregates) on probabilistic c-tables [18]. It has been shown that more complex tasks, such as conditioning probabilistic databases on given constraints [14] and sensitivity analysis and explanation of query results [11], can benefit from decomposition trees. Example 1. Figure 1 shows six pvc-tables, amongst them the suppliers table S, the products tables P1 and P2, and the table PS pairing suppliers and products. They all have an annotation column  to hold expressions in a semiring K generated by a set of independent random variables, with operations sum (+) and product (,), and neutral elements 0k and 1K . Each valuation of the random variables into a semiring (e.g. integers or Booleans) canonically maps semi- ring expressions into that semiring by interpreting + and , as the corresponding operations of that semiring. Each such valuation defines a possible world of the database. Figure 1d shows the result of the query Q1 that asks for prices of products available in shops. The annotations of the result tuples are constructed as follows: The annotation of a join of two tuples is the product of their annotations, and the annotation obtained from projection or union is the sum of the annotations of the participating tuples [7]. For instance, the tuple <M&S, 10> has the annotation x1y11(z1+z5), whose probability distribution can be computed as a function of probability distributions of the random variables x1, y11, z1, and z5 [21]. Consider the query Q2 from Figure 1e that asks for shops in which the maximal price for the products in P1 or P2 is less than 50. Aggregation is expressed using the $ operator, which in this query groups by the column shop and applies the aggregation MAX on price within each group. The annotations of result tuples are built using semi- module expressions of the form  ? v, where  is a semi- ring expression and v is a data value. Such expressions can be ^summed up' with respect to aggregation opera- tions: For MIN, the sum  +min  is min(, ); for MAX, +max = max(, ); for SUM, +sum = +. The sums correspond to operations in commutative monoids. The annotation  of M&S in Q2's result is constructed as follows. This tuple represents a group of six tuples in the result of Q1, all with the M&S shop value. The annotation  then expresses the conditions (1) that the sum of the price val- ues of these six tuples in the MAX monoid is less than 50, and (2) that the group is not empty (as expressed by ). Depending on the valuation of the variables in , these con- ditions can be true (>) or false (}), or, more generally, the additive or multiplicative neutral element of the semiring. For instance, a valuation  that maps x1, x2, y11, y21, z1, z2, z5 to > and all other variables to } satisfies \, since \(\) \ [>? 10 +max }? 50 +max >? 11 +max }? 60 +max }? 60 +max }? 15  50] , > ã [10 +max 11  50] \ [max(10, 11)  50] \ >. 2 If the variables in such expressions are random variables, then the expressions themselves can be interpreted as ran- dom variables. Moreover, the probability distributions of the obtained expressions reflect the probabilities of query answers taking particular values in a randomly drawn world of the database. Our technique allows to efficiently com- pute probabilities defined by such expressions by structural decomposition. For example, an expression  = ab ? 10 + xy ? 20 can be decomposed in independent sub-expressions ab? 10 and xy? 20 that do not share variable symbols and hence constitute independent random variables. The structure of the paper follows the list of contributions: ? We present an evaluation framework for queries with aggregates (SUM, PROD, COUNT, MIN, MAX) on pvc-tables, a representation system for probabilistic data based on semirings and semimodules. ? We devise a technique for computing the exact proba- bility distribution of query results based on a generic compilation procedure of arbitrary semimodule and semiring expressions into so-called decomposition trees, for which the computation of the probability distribu- tion can be done in time linear in the product of the sizes of the distributions represented by its nodes. ? We give a syntactic characterisation of a class of aggregate queries that are tractable on tuple-independent databases. Our query tractability result follows from the observation that the semiring and semimodule ex- pressions in the result of our tractable queries admit polynomial size decomposition trees and polynomial size probability distributions at their nodes. ? A prototype of our technique is incorporated into the probabilistic database engine SPROUT. ? Extensive performance experiments using our own syn- thetic datasets and TPC-H data are discussed. Besides exact computation, decomposition trees also al- low for approximate probability computation [18]. Due to lack of space, we refer the reader to the MSc thesis of the second author [9]. The pvc-tables can be extended to cope with continuous probability distributions, similar to the ex- tensions of pc-tables in the PIP system [12]. ",Robert Fink,"Deptartment of Computer Science, University of Oxford Wolfson Building, Parks Road, OX1 3QD Oxford, UK",robert.fink@cs.ox.ac.uk,Larisa Han,"Deptartment of Computer Science, University of Oxford Wolfson Building, Parks Road, OX1 3QD Oxford, UK",dan.olteanu@cs.ox.ac.uk,Dan Olteanu,"Deptartment of Computer Science, University of Oxford Wolfson Building, Parks Road, OX1 3QD Oxford, UK",hanlarisa@gmail.com,,,,,,,,,,,,,,,,,,,,,
20200113,1397,Yanhao Wang,National University of Singapore,yanhao90@comp.nus.edu.sg,,Semantic and Influence aware k-RepresentativeQueries over Social Streams,"Semantic and Influence aware k-RepresentativeQueries over Social Streams, Semantic and Influence aware k-RepresentativeQueries over Social Streams, Semantic and Influence aware k-RepresentativeQueries over Social Streams, Semantic and Influence aware k-RepresentativeQueries over Social Streams, Semantic and Influence aware k-RepresentativeQueries over Social Streams, ABSTRACT Massive volumes of data continuously generated on social plat- forms have become an important information source for users. A primary method to obtain fresh and valuable information from social streams is social search. Although there have been exten- sive studies on social search, existing methods only focus on the relevance of query results but ignore the representativeness. In this paper, we propose a novel Semantic and Influence aware k-Representative (k-SIR) query for social streams based on topic modeling. Specifically, we consider that both user queries and elements are represented as vectors in the topic space. A k-SIR query retrieves a set of k elements with the maximum repre- sentativeness over the sliding window at query time w.r.t. the query vector. The representativeness of an element set comprises both semantic and influence scores computed by the topic model. Subsequently, we design two approximation algorithms, namely Multi-Topic ThresholdStream (MTTS) and Multi-Topic Th- resholdDescend (MTTD), to process k-SIR queries in real-time. Both algorithms leverage the ranked lists maintained on each topic for k-SIR processing with theoretical guarantees. Extensive experiments on real-world datasets demonstrate the effectiveness of k-SIR query compared with existing methods as well as the efficiency and scalability of our proposed algorithms for k-SIR processing. 1 INTRODUCTION Enormous amount of data is being continuously generated by web users on social platforms at an unprecedented rate. For ex- ample, around 650 million tweets are posted by 330 million users on Twitter per day. Such user generated data can be modeled as continuous social streams, which are key sources of fresh and valuable information. Nevertheless, social streams are extremely overwhelming for their huge volumes and high velocities. It is impractical for users to consume social data in its raw form. Therefore, social search [7?9, 17, 19, 28, 33, 37, 39] has become the primary approach to facilitating users on finding their interested content from massive social streams. Existing search methods for social data can be categorized into keyword-based approaches and topic-based approaches based on how they measure the relevance between queries and elements. Keyword-based approaches [7?9, 17, 28, 33, 37] adopt the textual relevance (e.g., TF-IDF and BM25) for evaluation. However, they merely capture the syntactic correlation but ignore the semantic correlation. Considering the tweets in Figure 1, if a query ""soccer"" is issued, no results will be found because none of the tweets contains the term ""soccer"". It is noted that the words like ""as- roma"" and ""LFC"" are semantically relevant to ""soccer"". Therefore, elements such as e1, e2 are relevant to the query but missing from the result. Thus, overlooking the semantic meanings of user queries may degrade the result quality, especially against social data where lexical variation is prevalent [14]. To overcome this issue, topic-based approaches [19, 39] project user queries and elements into the same latent space defined by a probabilistic topic model [5]. Consequently, queries and elements are both represented as vectors and their relevance is computed by similarity measures for vectors (e.g., cosine distance) in the topic space. Although topic-based approaches can better capture the semantic correlation between queries and elements, they fo- cus on the relevance of results but neglect the representativeness. Typically, they retrieve top-k elements that are the most coherent with the query as the result. Such results may not be represen- tative in the sense of information coverage and social influence. First, users are more satisfied with the results that achieve an extensive coverage of information on query topics than the ones that provide limited information. For example, a top-2 query on topic 1 in Figure 2 returns {e3, e4} as the result. Nevertheless, compared with e4, e6 can provide richer information to comple- ment the news reported by e3. Therefore, in addition to relevance, it is essential to consider information coverage to improve the result quality. Second, influence is another key characteristic to measure the representativeness of social data. Existing methods for social search [7, 8, 19, 37] have taken into account the in- fluences of elements for scoring and ranking. These methods simply use the influences of authors (e.g., PageRank [24] scores) or the retweet/share count to compute the influence scores. Such a na?ve integration of influence is topic-unaware and may lead to undesired query results. For example, e6 in Figure 1, which is mostly related to 1, may appear in the result for a query on 2 because of its high retweet count. In addition, they do not consider that the influences of elements evolve over time, when previously trending contents may become outdated and new posts continuously emerge. Hence, incorporating a topic-aware and time-critical influence metric is imperative to capture recently trending elements. To tackle the problems of existing search methods, we define a novel Semantic and Influence aware k-Representative (k-SIR) query for social streams based on topic modeling [5]. Specifi- cally, a k-SIR query retrieves a set of k elements from the active elements corresponding to the sliding windowWt at the query time t . The result set collectively achieves the maximum repres- entativeness score w.r.t. the query vector x, each dimension of which indicates the degree of interest on a topic. We advocate the representativeness score of an element set to be a weighted sum of its semantic and influence scores on each topic. We adopt a weighted word coverage model to compute the semantic score so as to achieve the best information preservation, where the weight of a word is evaluated based on its information entropy [31, 42]. The influence score is computed by a probabilistic coveragemodel where the influence probabilities are topic-aware. In addition, we restrict the influences within the sliding windowWt so that the recently trending elements can be selected. The challenges of real-timek-SIR processing are two-fold. First, the k-SIR query is NP-hard. Second, it is highly dynamic, i.e., the results vary with query vectors and evolve quickly over time. Due to the submodularity of the scoring function, existing submodular maximization algorithms, e.g., CELF [16] and SieveStreaming [2], can provide approximation results for k-SIR queries with theoret- ical guarantees. However, existing algorithms need to evaluate all active elements at least once for a single query and often take several seconds to process one k-SIR query as shown in our experiments. To support real-time k-SIR processing over social streams, we maintain the ranked lists to sort the active elements on each topic by topic-wise representativeness score. We first devise theMulti-Topic ThresholdStream (MTTS) algorithm for k-SIR processing. Specifically, to prune unnecessary evalu- ations, MTTS sequentially retrieves elements from the ranked lists in decreasing order of their scores w.r.t. the query vector and can be terminated early whenever possible. Theoretically, it provides ( 12 ?)-approximation results for k-SIR queries and eval- uates each active element at most once. Furthermore, we propose the Multi-Topic ThresholdDescend (MTTD) algorithm to im- prove upon MTTS. MTTD maintains the elements retrieved from ranked lists in a buffer and permits to evaluate an element more than once to improve the result quality. Consequently, it achieves a better (1 ? 1e ? )-approximation but has a higher worst-case time complexity than MTTS. Despite this, MTTD shows better empirical efficiency and result quality than those of MTTS. Finally, we conduct extensive experiments on three real-world datasets to evaluate the effectiveness of k-SIR as well as the effi- ciency and scalability of MTTS and MTTD. The results of a user study and quantitative analysis demonstrate that k-SIR achieves significant improvements over existing methods in terms of in- formation coverage and social influence. In addition, MTTS and MTTD achieve up to 124x and 390x speedups over the baselines for k-SIR processing with at most 5% and 1% losses in quality. Our contributions in this work are summarized as follows. ? We define the k-SIR query to retrieve representative ele- ments over social streams where both semantic and influ- ence scores are considered. (Section 3) ? We propose MTTS and MTTD to process k-SIR queries in real-time with theoretical guarantees. (Section 4) ? We conduct extensive experiments to demonstrate the effectiveness of k-SIR as well as the efficiency and scalability of our proposed algorithms for k-SIR processing. (Section 5)",Yanhao Wang,National University of Singapore,yanhao90@comp.nus.edu.sg,Yuchen Li,Singapore Management University,yuchenli@smu.edu.sg,Kian-Lee Tan,National University of Singapore,tankl@comp.nus.edu.sg,,,,,,,,,,,,,,,,,,,,,
20200114,1398,Zhuhua Cai,"Rice University Houston, TX, 77251",caizhua@gmail.com,,A Comparison of Platforms for Implementing and Running Very Large Scale Machine Learning Algorithms,"A Comparison of Platforms for Implementing and Running Very Large Scale Machine Learning Algorithms, A Comparison of Platforms for Implementing and Running Very Large Scale Machine Learning Algorithms, A Comparison of Platforms for Implementing and Running Very Large Scale Machine Learning Algorithms, A Comparison of Platforms for Implementing and Running Very Large Scale Machine Learning Algorithms, A Comparison of Platforms for Implementing and Running Very Large Scale Machine Learning Algorithms, ABSTRACT We describe an extensive benchmark of platforms available to a user who wants to run a machine learning (ML) inference algorithm over a very large data set, but cannot find an existing implementation and thus must ""roll her own"" ML code. We have carefully chosen a set of five ML implementation tasks that involve learn- ing relatively complex, hierarchical models. We completed those tasks on four different computational platforms, and using 70,000 hours of Amazon EC2 compute time, we carefully compared run- ning times, tuning requirements, and ease-of-programming of each. 1. INTRODUCTION Many platforms have been proposed to provide programming and runtime support for distributed/parallel machine learning (ML) codes, including OptiML [19], GraphLab [11, 8], SystemML [6], and SimSQL [4]. MLBase [10] and ScalOps [21] also address the problem, though the most recent published descriptions indi- cate that these systems are more immature. Other systems such as Pregel [12], Giraph [2], Spark [24], Ricardo [5], Nyad [14], and DryadLinq [22] may not have been developed only for ML, but count it as an important application. We describe an objective benchmark of some of the platforms available to a user who wants to run a specific ML inference al- gorithm over a large data set, but cannot find an existing imple- mentation and thus must ""roll her own"" ML code. Given the wide variety of ML models, this will not be an uncommon occurrence.1 We draw a distinction between a user who wants to implement and apply a brand new ML code, and someone who just wants to use a code, and focus on the former. The implementor will want to balance ease of implementation with performance, whereas an end 1For example, it is telling that of the five standard Bayesian ML inference algorithms we consider in this study, it appears that only the collapsed LDA inference algorithm [3] is available as part of an ex- isting package, and even then we are aware of no ""non-collapsed"" Gibbs sampler implementation (See Section 8 of the paper). user has little concern for the effort required to engineer the code and will be happy with an intricately constructed C and MPI code as long as it is fast and easy to use.2 Our contributions. Our specific contributions are: (1) We shed some light on the relative merits of some (quite differ- ent) platforms for implementing large-scale ML algorithms. Our results will surprise many readers. (2) Second, we demonstrate (through example) what a scientific study of a platform for writing large-scale ML codes might look like. We have carefully chosen a set of tasks that involve learning relatively complex, hierarchical statistical models. We have pur- posely avoided simple, convex models whose parameters can be optimized using easily-implemented techniques such as gradient descent. Their simplicity means they benefit relatively little from the abstractions provided by the platforms we consider. (3) Finally, we hope that our efforts will grow into a widely used, standard benchmark for this sort of platform. In the future, a implementor of a new or existing platform need only implement these codes and compare with our numbers. ",Zhuhua Cai,"Rice University Houston, TX, 77251",caizhua@gmail.com,Zekai J. Gao,"Rice University Houston, TX, 77251",jacobgao@rice.edu,Shangyu Luo,"Rice University Houston, TX, 77251",lsyurd@gmail.com,Luis L. Perez,"Rice University Houston, TX, 77251",lp6@rice.edu,Zografoula Vagena,"LogicBlox, Inc. Atlanta, GA, 30309",foula@acm.org,Christopher Jermaine,"Rice University Houston, TX, 77251",cmj4@rice.edu,,,,,,,,,,,,
20200115,691,Ahmad Ghazal,"Teradata Corporation  100 N. Sepulveda Blvd  Elsegundo, CA 90245, USA  ahmad.ghazal@ teradata.com    Alain Crolotte  Teradata Corporation  100 N. Sepulveda Blvd  Elsegundo, CA 90245, USA",alain.crolotte@teradata.com,,Dynamic Plan Generation for Parameterized Queries,"Dynamic Plan Generation for Parameterized Queries, Dynamic Plan Generation for Parameterized Queries, Dynamic Plan Generation for Parameterized Queries, Dynamic Plan Generation for Parameterized Queries, Dynamic Plan Generation for Parameterized Queries, ABSTRACT  Query processing in a DBMS typically involves two distinct  phases: compilation, which generates the best plan and its  corresponding execution steps, and execution, which evaluates  these steps against database objects. For some queries,  considerable resource savings can be achieved by skipping the  compilation phase when the same query was previously  submitted and its plan was already cached. In a number of  important applications the same query, called a Parameterized  Query (PQ), is repeatedly submitted in the same basic form but  with different parameter values. PQs are extensively used in  both data update (e.g. batch update programs) and data access  queries. There are tradeoffs associated with caching and re- using query plans such as space utilization and maintenance  cost. Besides, pre-compiled plans may be suboptimal for a  particular execution due to various reasons including data skew  and inability to exploit value-based query transformation like  materialized view rewrite and unsatisfiable predicate  elimination. We address these tradeoffs by distinguishing two  types of plans for PQs: generic and specific plans. Generic plans  are pre-compiled plans that are independent of the actual  parameter values. Prior to execution, parameter values are  plugged in to generic plans. In specific plans, parameter values  are plugged prior to the compilation phase. This paper provides  a practical framework for dynamically deciding between  specific and generic plans for PQ 's based on a mix of rule and  cost based heuristics which are implemented in the Teradata  12.0 DBMS.  Categories and Subject Descriptors  C.0 Computer Systems Organization, GENERAL,  Hardware/software interfaces.  General Terms: Algorithms, Performance, Theory.  Keywords: compilation, dynamic, optimizations.  1. INTRODUCTION  Query processing in a DBMS typically involves two distinct  phases. The first phase, which we call the compilation phase,  checks the syntax, semantics and access rights. This phase also  includes the generation of the execution plan using query rewrite  and cost-based optimization. The resulting execution plan (in  some executable code) is fed to the second phase which executes  the plan against database objects and produces the query result.  The query processing time is the sum of compilation and  execution times.  In order to minimize the overhead of the compilation phase,  many DBMSs cache the execution plan in order to reuse it when  the same query is submitted again. When a fully-specified query  (i.e. non-parameteric query) is submitted again, the compilation  phase can be skipped altogether and the cached plan is retrieved  and passed to the execution phase. However, there are various  scenarios that can render the cached plan non-reusable including  structural changes to the underlying data model such as DDL  definition changes or constraint definition changes such as  CHECK constraints or Referential Integrity changes. A cache can  also be invalidated due to statistics collection. Previous work, e.g.  [2][7][10] has addressed this issue by systematically purging or  repairing compiled plans.  Exact query-match based exploitation of the plan cache is also  not appropriate for parameterized queries (PQs) which contain one  or more parameters or parameter markers that take different values  during each execution. As a result, PQs require a special  infrastructure to exploit the plan cache. One approach to produce a  cacheable plan is to assume a uniform distribution for the columns  being compared with a parameter value and generate the plan (i.e.  optimize the query) using the average (or some  ""typical "")  estimate. In this paper, we refer to a plan thus produced as a  generic plan. This was the approach exclusively used prior to  Teradata 12.0 DBMS.  In addition to allowing us to exploit caching to reduce query  processing overhead, a generic plan is also the optimal plan for  some classes of queries as we will discuss later. However, a  generic plan may be sub-optimal for many kinds of queries. The  reason is that the most efficient execution plan for different  parameter values may be different and the performance  degradation caused by using a generic plan may exceed the  savings from using a cached plan. A plan that is picked as efficient  for a typical (average) value of a parameter may be inefficient for  a particular value if there exists a skew in the data distribution or if  the optimization involves value-based transformations like  materialized view rewrite, unsatisfiable predicate elimination or  data partition elimination. In the presence of data skew, different  values of a parameter give rise to different selectivity estimates for  filtering and join predicates which in turn may cause the optimizer  to pick differing execution plans. Similarly, a query rewrite  optimization performed based on a particular value may not be  correctly used for another value, rendering the resulting plan  inappropriate for caching.   A simple alternative to avoid such sub-optimal plans is not to  use a plan cache and instead perform the compilation phase for  each submission of the query where the parameters are replaced  by a specific value. We refer to such a plan as a specific plan. A  specific plan is generally optimal in terms of run time performance  for the specific parameter values but incurs compilation overhead  for each execution of the query. This overhead is wasteful if the  optimization time is a large portion of the overall processing time  or if the plan is independent of the value of the parameter. Also, if  the query is known to be a short running query, then it is  preferable to cache such queries since by definition the execution  time of such queries will be small and the gain from using a  specific plan is minimal.  This paper presents an adaptive approach that dynamically  decides between a generic and a specific plan for a particular PQ.  A key component of our solution is to capture and factor in the  actual run time characteristics of the DBMS when the query is  executed in order to pick a planning type appropriate for the  workload currently executing in the system. Our solution is based  on a mix of rule and cost based heuristics which are implemented  in the Teradata 12.0 DBMS. The rule based heuristic solution is  based on a characterization of those classes of queries for which a  specific or generic plan can be reliably determined. For other  classes of queries, we devised a heuristic algorithm that depends  on the compilation and execution costs as well as workload  characteristics, particularly expected overall run time and assigned  priority, of queries.  The rest of the paper is organized as follows. Section 2  provides a background discussion including definition of  parameterized queries, implementation approaches of generic and  specific plans along with concrete examples of queries that benefit  from each approach. Section 3 details our adaptive algorithm and  Section 4 presents experimental results. We review related  literature in Section 5 and we conclude in Section 6.",Ahmad Ghazal,"Teradata Corporation  100 N. Sepulveda Blvd  Elsegundo, CA 90245, USA  ahmad.ghazal@ teradata.com    Alain Crolotte  Teradata Corporation  100 N. Sepulveda Blvd  Elsegundo, CA 90245, USA",alain.crolotte@teradata.com,Dawit Seid,"Teradata Corporation  100 N. Sepulveda Blvd  Elsegundo, CA 90245, USA  dawit.seid@ teradata.com    Manjula Koppuravuri  Teradata Corporation  Queens Plaza  Hyderabad, 500 003, India",manjula.koppuravuri@teradata.com,Ramesh Bhashyam,"Teradata Corporation  Queens Plaza  Hyderabad, 500 003, India",bhashyam.ramesh@teradata.com,Alain Crolotte ,"Teradata Corporation 100 N. Sepulveda Blvd Elsegundo, CA 90245, USA ",alain.crolotte@teradata.com ,Manjula Koppuravuri,"Teradata Corporation Queens Plaza Hyderabad, 500 003, India",manjula.koppuravuri@teradata.com,Vinod G,"Teradata Corporation  Queens Plaza  Hyderabad, 500 003, India",vinod.g@teradata.com,,,,,,,,,,,,
20200116,1399,Fei Xu,"University of Florida Gainesville, FL, USA",feixu@cise.ufl.edu,,E = MC3: Managing Uncertain Enterprise Data in a Cluster-Computing Environment,"E = MC3: Managing Uncertain Enterprise Data in a Cluster-Computing Environment, E = MC4: Managing Uncertain Enterprise Data in a Cluster-Computing Environment, E = MC5: Managing Uncertain Enterprise Data in a Cluster-Computing Environment, E = MC6: Managing Uncertain Enterprise Data in a Cluster-Computing Environment, E = MC7: Managing Uncertain Enterprise Data in a Cluster-Computing Environment, ABSTRACT Modern enterprises must manage uncertain data for purposes of risk assessment and decisionmaking under uncertainty. The Monte Carlo approach embodied in the MCDB system of Jampani et al. is well suited for such a task. MCDB can support industrial strength business-intelligence queries over uncertain warehouse data. Moreover, MCDB's extensible approach to specifying uncertainty can also capture complex stochastic prediction models, allowing sophis- ticated ""what-if"" analyses within the DBMS. The MCDB computations can be highly CPU intensive, but offer the potential for massive parallelization. To realize this potential, we provide a new system, called MC3 (Monte Carlo Com- putation on a Cluster), that extends the MCDB approach to the map-reduce processing framework. MC3 can exploit the robustness and scalability of map-reduce, and can han- dle data stored in non-relational formats. We show how MCDB query plans over ""tuple bundles"" can be translated to sequences of map-reduce operations over nested data, and describe different parallelization schemes. We also provide and analyze several novel distributed algorithms for adding pseudorandom number seeds to tuple bundles. These al- gorithms ensure statistical correctness of the Monte-Carlo computations while minimizing the seed length. Our ex- periments show that MC3 can scale well for a variety of workloads. Categories and Subject Descriptors H.2 [Information Systems]: Database Management General Terms Algorithms, Design, Languages, Performance Keywords Uncertain Data, Map-Reduce, Monte Carlo, JSON, JAQL  1. INTRODUCTION There is an increasing need for tools that facilitate en- terprise risk assessment and decision making in the face of uncertain data. The problem of data uncertainty is be- coming acute, due to the increasing use of data integration, automated information extraction, and data anonymization for privacy protection, as well as the growing prevalence of RFID and sensor data. Database researchers have therefore developed a variety of prototype systems [1, 2, 3, 16, 26, 28, 32] for managing uncertain data. Among these prototypes, the Monte Carlo relational Database System (MCDB) [16] seems especially promising for general decision-support ap- plications. MCDB's Monte Carlo approach permits processing of in- dustrial strength Business Intelligence (BI) queries - e.g., complex SQL aggregation queries - over warehouses where the data is uncertain and has complex statistical depen- dencies between attributes and tuples. Perhaps more im- portantly, the MCDB uncertainty model is completely ex- tensible: uncertainty is specified via user-defined Variable Generation (VG) functions, which are used to pseudoran- domly generate realized values for uncertain attributes. As a consequence, the MCDB model subsumes the uncertainty models used in current prototype systems. For example, MCDB can capture discrete models of uncertainty such as the attribute-value and tuple-inclusion uncertainty models used in systems such as MayBMS, Trio, and Mystiq [1, 2, 3]. Moreover, MCDB is well suited to a very important class of scenarios in which uncertainty arises due to the need to extrapolate missing data using probabilistic models, as is often the case with financial, banking, marketing, fraud-detection, and decision-support applications. In this latter setting, MCDB permits sophisticated, data-intensive stochastic modeling and prediction without the need to con- tinually move data back and forth between the DBMS and a statistical or simulation package such as R or ARENA. Thus the user can assess not only the uncertainty in the results of BI queries over uncertain data, but can also ask what-if questions such as ""What will be the mean effect on my prof- its next quarter if I increase my prices by 5%?"" or ""What is the probability that the average value of my New York cus- tomers' portfolios will drop by more than 10% over the next month?"" To achieve the foregoing new functionality without unacceptably increasing processing overhead, MCDB uses a novel processing technique in which a query plan is executed exactly once, but over ""tuple bundles"" rather than ordinary 441 tuples. A tuple bundle represents the values of a tuple over all Monte Carlo replications - equivalently, over all sampled ""possible worlds"" - see Section 2.1. In this paper, we provide a new system, called MC3 (Monte Carlo Computation on a Cluster), that extends the MCDB approach to a map-reduce framework. Our motivation for this work is threefold: ? As the amount of data continues to increase expo- nentially, massively-parallel processing techniques are becoming increasingly important. Especially in more complex settings - see the finance and marketing ex- amples in the following sections - our new uncertainty- handling technology can exacerbate this problem of handling massive data, because MCDB's Monte Carlo computations can be highly CPU-intensive. For wide adoption of the MCDB approach to uncertainty, it is therefore very desirable to provide the MCDB func- tionality on an affordable, massively parallel platform. ? The MCDB prototype incorporates a major rework- ing of the standard relational query-processing engine. Because of the effort required, it is unlikely that this technology will be directly incorporated into commer- cial relational database products; an alternative path to market is needed. ? Since most real-world data is not stored in relational databases, it is important to be able to deal with data in a wide variety of formats. To address the first issue, we note that Monte Carlo com- putations can be performed independently for each tuple bundle, and Monte Carlo replications for a given tuple bun- dle can be executed independently of each other. Thus the MCDB computations have the potential to be massively par- allelized. MC3 realizes this potential: the excellent scalabil- ity and ease of parallel programming made possible by the map-reduce approach are ideal for our purposes. Our MC3 prototype uses Hadoop, an open-source implementation of Google's map-reduce processing framework. Hadoop's map- reduce has been shown to be highly scalable, as demon- strated by Yahoo's recent Daytona Terabyte sort record of 209 seconds using 910 servers.1 Preliminary results from Google (68 seconds using 1000 servers) provide additional evidence.2 Our choice of Hadoop - as well as our choice of Javascript Object Notation (JSON) as the MC3 internal data model - addresses the second issue raised above. The Hadoop infras- tructure and JSON data format are becoming increasingly popular. Appealing features of Hadoop include fault toler- ance and the capability to allocate and reallocate resources (CPU, memory, storage) as needed; this functionality al- lows massive parallelism to be achieved using commodity hardware, further increasing the appeal of the map-reduce approach. Although it appears hard to precisely delineate the class of queries that can be processed by MC3, we believe that it is quite large: MCDB can handle virtually any BI SQL query, it appears that virtually any such query can be rewritten as a directed acyclic graph of operators (i.e., a query plan) that can be processed by MC3. We speculate that many probabilistic XML queries can also be handled by MC3. As a consequence of these considerations, tech- niques for managing uncertain data in this setting have the potential to be widely used. With respect to the third issue, the use of JSON means that MC3 can gracefully deal with data provided in non- relational formats, without any need to reformat the data prior to processing. Indeed, we obtain this functionality ""for free"" from the Hadoop platform. In this paper, we primar- ily deal with JSON data that can be viewed as reformatted probabilistic relational data. However, work on probabilis- tic XML data [19] leads us to believe that extensions to full-fledged probabilistic JSON data should be achievable. Such extensions would then permit MC3 to interact with many recently developed repositories for scaled-out cluster environments, in which data attributes may be multi-valued and records in the same table may differ in their number of attributes [4, 7, 27, 29]. Extending the MCDB functionality to the map-reduce set- ting raises a number of challenging questions. How exactly do we map MCDB's tuple-bundle processing methods to Hadoop and JSON? Must we directly generate a query plan as a sequence of map-reduce operations, or can we facilitate this process via use of a higher level query language? What are the different ways in which MCDB queries can be parallelized, and for which scenarios are these various parallelization schemes effective? A key technical challenge is how to ""seed"" tuple bundles so as to generate streams of the pseudorandom numbers that form the basis of the Monte Carlo computations. For statistical correctness, the streams used by the various tuple bundles must be mutually disjoint. Seeding is challenging because it must be done in a highly parallel and distributed fashion, over an enormous number of tuple bundles, and without requiring storage of too much seeding information in each tuple bundle. Our Contributions. The paper's contributions are as follows: ? We provide the first system for managing uncertain data in a map-reduce environment, showing how to represent MCDB tuple bundles as JSON arrays and how to translate an MCDB query plan to map-reduce. ? We show how query-plan generation can be facilitated by use of JAQL, an open-source language for querying JSON data. ? We identify two MCDB-specific parallelization schemes called inter-tuple and intra-tuple parallelism, show how to implement these schemes using map-reduce, and identify scenarios under which each scheme is effective. ? We develop and analyze an efficient distributed-seed- ing method called SeedSkip that is based on a ran- dom number generator with skip-ahead functionality, as well as a ""fallback"" method called SeedMult that is based on multiple pseudorandom number generators and can be used when SeedSkip does not apply. ? We show, via a set of experiments, that our paralleliza- tion techniques can yield linear scaleup when process- ing uncertain data, and that intra-tuple parallelism can provide linear speedup for certain very expensive VG functions.  We note that other parallel-processing platforms, data for- mats, and query languages can potentially be used to extend MCDB. Our goal was proof-of-concept, and our plat- form choices were partially made as a matter of convenience. We believe, however, that at least some of our techniques, and the lessons learned, are applicable to other possible extensions of the MCDB methodology to forward-looking information-management architectures. Paper Organization. The remainder of the paper is orga- nized as follows. Section 2 gives some background informa- tion. Section 3 gives an overview of how MCDB function- ality is realized using map-reduce, JSON, and JAQL. Sec- tion 4 considers the distributed-seeding problem, and Sec- tion 5 presents our experimental study. We conclude the paper in Section 6. ",Fei Xu,"University of Florida Gainesville, FL, USA",feixu@cise.ufl.edu,Kevin Beyer,"IBM Almaden Research Center San Jose, CA, USA",kbeyer@us.ibm.com,Vuk Ercegovac,"IBM Almaden Research Center San Jose, CA, USA",vercego@us.ibm.com,Peter J. Haas,"IBM Almaden Research Center San Jose, CA, USA",phaas@us.ibm.com,Eugene J. Shekita,"IBM Almaden Research Center San Jose, CA, USA",hekita@us.ibm.com,,,,,,,,,,,,,,,
20200117,1340,Jaroslaw Szlichta,University of Toronto & IBM Toronto Centre for Advanced Studies,szlichta@cs.toronto.edu,,Business-Intelligence Queries with Order Dependencies in DB2,"Business-Intelligence Queries with Order Dependencies in DB2, Business-Intelligence Queries with Order Dependencies in DB3, Business-Intelligence Queries with Order Dependencies in DB4, Business-Intelligence Queries with Order Dependencies in DB5, Business-Intelligence Queries with Order Dependencies in DB6, ABSTRACT Business-intelligence queries often involve SQL functions and al- gebraic expressions. There can be clear semantic relationships between a column's values and the values of a function over that col- umn. A common property is monotonicity: as the column's values ascend, so do the function's values. This we call an order dependency (OD). Queries can be evaluated more efficiently when the query optimizer uses order dependencies. They can be run even faster when the optimizer can also reason over known ODs to infer new ones. Order dependencies can be declared as integrity constraints, and they can be detected automatically for many types of SQL functions and algebraic expressions. We present optimization techniques us- ing ODs for queries that involve join, order by, group by, partition by, and distinct. Essentially, ODs can further exploit interesting orders to eliminate or simplify potentially expensive sorts in the query plan. We evaluate these techniques over our implementation in IBM R? DB2 R? V10 using the TPC-DS R? benchmark schema and some IBM customer inspired queries. Our experimental results demonstrate a significant performance gain. We additionally devise an algorithm for testing logical implication for ODs which is polynomial over the size of the set of given ODs. We show that the inference algorithm which we have implemented in DB2 is sound and complete over sets of ODs over natural domains. This enables the optimizer to infer useful ODs from known ODs. 1. INTRODUCTION 1.1 Motivation As business-intelligence (BI) applications have become more co- mplex and data volumes grow, so have the analytic queries needed to support them. This increasing complexity raises performance issues and numerous challenges for query optimization. Worse, traditional optimization methods often fail to apply when logical subtleties in database schemas and in queries circumvent them. For example, data-warehouse schemas will use surrogate keys, while predicates in business analytic queries will use natural values (such as sale_date = '2010-07-01'). Real world queries will use SQL functions (such as year(d_date)) and algebraic expressions (such as d_date + 30 days). These subtleties cause the optimizer to miss opportunities to use indexes, partition elimination and pipeline operations, and to add potentially expensive operations such as sort even when the data is already sorted appropriately. This is because semantic relation- ships between the functions and expressions the queries use and the data in the database-and between data themselves in the schema, as between surrogate and natural keys-are opaque. If these rela- tionships could be discovered and used, more efficient query plans would result. The relationship on which we focus in this work is order. If the rows of a table were ordered by its date column d_date, they would also necessarily be ordered by d_date + 30 days. Indeed, the function (over d_date) of d_date + 30 days is monotonically increasing with respect to d_date. For this, we say d_date or- ders d_date + 30 days.1 If an index on d_date could be used to provide results ordered by d_date, then the same index would provide the results ordered by d_date + 30 days, since this is the same order. This semantic relationship of order is a type of depen- dency, and we call it an order dependency (OD) [17, 18, 21]. It is akin to the well-known concept of functional dependencies (FDs). (In fact, ODs strictly subsume FDs.) While it will be readily obvious to any reader that d_date orders d_date+ 30 days, this observation is not for free for the optimizer. It would need explicit mechanisms to recognize the dependency. While this particular order dependency rightfully seems trivial, we shall see there are many that are not. Then ""when"" and ""how"" to exploit such dependencies in query planning is far from trivial too. This work is about this aspect of query optimization. Consider then the SQL query in Query 1 over the TPC-DS2 schema. In the schema, date_dim is a dimension table with the primary key d_date_sk with one row per day. (The attribute d_date_sk is a sequential number.) The table has columns d_date, 1In this case, d_date + 30 days orders d_date also. We then say the two are order equivalent. However, ""orders"" is not in- herently symmetric. Consider year(d_date) and d_date. In this case, d_date orders year(d_date), but year(d_date) does not or- der d_date. 2http://www.tpc.org     750 10.5441/002/edbt.2014.81 select D.d_date + 30 days, max(S.ws_ext_sales_price) as most from date_dim D, web_sales S where S.ws_sold_date_sk = D.d_date_sk and D.d_date between date('1998-01-01') and date('2002-01-01') group by D.d_date + 30 days order by D.d_date + 30 days; Query 1: Plus thirty days. d_month, d_quarter, and d_day, and additional columns that qualify the day (such as whether it is the weekend, a holiday, and, if so, the name of the holiday). The table web_sales is a large fact table recording all individual sales, with ws_sold_date_sk as a foreign key referencing date_dim on d_date_sk. Let there be a tree index for date_dim on d_date. The opti- mizer will miss that the index could be used in evaluating Query 1 to accomplish both the group-by and the order-by. How might the query be rewritten manually to resolve this? ? group by d_date + 30 days and order by d_date: This is not legal SQL; the attribute in the order-by is not listed in the group-by (as such). ? group by d_date and order by d_date + 30 days: This is accepted by DB2; derived attributes-functions and algebraic expressions derived over the attributes listed in the group-by (which may include derived attributes itself)-can be used in the select and order-by clauses. However, this does not resolve the inefficiency. The query plan still explicitly sorts to ""satisfy"" the order-by. ? group by d_date and order by d_date: This does work! The index can now be employed to imple- ment the group-by and to satisfy the order-by. Of course, it is not the responsibility of the SQL programmer to write queries painstakingly-or of an automated BI report sys- tem that generates SQL queries in the back-end-in such a way to assure the optimizer will handle it well. This would violate the declarative principle of SQL. Even if we tried to put the onus on programmers to be careful, they cannot be expected to know what is problematic and what is not. While a clever SQL programmer can sometimes skirt such pitfalls by careful composition (as here), more often it is not possible. So, we have to fix it. The optimizer needs to recognize that d_date and d_date + 30 days are seman- tically equivalent for order, thus skipping the superfluous sorting step, regardless of how the query is written. Next, consider Query 2. In SQL, date and time are complex data types. These are central to BI applications, and provide for rich drill down and roll up. In TPC-DS in table date_dim, some of date's hierarchy is materialized in columns: d_year, d_quarter, d_month, and d_day. select D.d_year, D.d_quarter, D.d_month, D.d_day sum(S.ws_sales) as total from date_dim D, web_sales S where S.ws_date_sk = D.d_date_sk and D.d_year between 2001 and 2004 group by D.d_year, D.d_quarter, D.d_month, D.d_day order by D.d_year, D.d_quarter, D.d_month, D.d_day; Query 2: Eliminating quarter. Let there be a tree index for date_dim on d_year, d_month, d_day. Unfortunately, this index would not help in a query plan, even for the group-by: d_quarter intervenes. Note that d_month functionally determines d_quarter. The query's author cannot elim- inate mention of d_quarter in the group-by, however, as it appears in the select. Fortunately, by the work in [16], DB2 can eliminate it internally from the group-by, based on the recognition of the func- tional dependency (FD). The index can then be used to implement the group-by operation. However, this FD, d_month C d_quarter, is not logically suf- ficient likewise to remove d_quarter from the order-by clause. The optimizer must still apply a sort operator to ""satisfy"" the order- by directive. However, because d_month orders d_quarter- which says more than just that d_month functionally determines d_quarter-the attribute d_quarter can be removed from the order- by clause also, to result in a semantically equivalent query.3 In this work, we show how this is accomplished. 1.2 Contributions and Outline In Section 2, we provide background on order dependencies- notational conventions and definitions-as we use in this paper, and considerations that arise in data-warehouse schema design. In Section 3, we address how to use order dependencies in query op- timization. There are two aspects to this: how and where the op- timizer makes use of OD information; and how OD information is discovered. 1. Optimizing with Order Dependencies. (a) Section 3.1 is divided into two sections. In Section 3.1.1, we go into further depth how ODs are used to optimize. (b) In Section 3.1.2 we present two inference algorithms and show where and how they are invoked in the opti- mizer: Reduce Order OD which puts ODs into a canon- ical form for matching against interesting orders; and Homogenize Order OD which discovers equivalent co- lumns, order-wise. We discuss the utility of these algo- rithms. 2. Detecting Order Dependencies. In Section 3.2, we show how ODs between columns and functions over columns (SQL func- tions and algebraic expressions) can be automatically detected by the optimizer. (a) These techniques have been implemented as a prototype within DB2. (b) We present a suite of real-world IBM customer queries over TPC-DS benchmark that illustrate the issues, which are then used in Section 4 for an experimental perfor- mance evaluation. The optimizer automatically infers the associated OD information and uses it to produce the improved query plans. 3. Declaring Order Dependencies. In Section 3.3, we consider how OD information can be declared, and what types of natural ODs occur in today's schemas. (a) Order dependencies can be explicitly declared in our implementation in DB2 as a type of integrity constraint. (b) We demonstrate how ODs between surrogate and nat- ural keys can be used for strong performance improvement [19]. 4. Inferring Order Dependencies. In Section 3.4, we show how the optimizer can infer new ODs from known ODs. The known ODs may not match interesting orders in query plan- ning, while ODs that logically derive from them would. Thus, such an OD-inference facility is ultimately needed to take 3The values for d_quarter are 1, . . . , 4 and for d_month, 1, . . . , 12. 751 Table 1: Notational conventions. ? Relations ? R represents a relation, and r represents a specific re- lation instance (table). ? A, B and C represent attributes. ? s and t represent tuples. ? t A denotes the value of attribute A in tuple t. ? Sets ? calligraphic letters denoted as X , Y , and Z represent sets of attributes. ? Lists ? bold letters represent lists of attributes: X, Y and Z. Note list X could be the empty list, [ ]. ? square brackets denote an explicit list: [A,B,C]. ? [A |T] denotes that A is the head of the list, andT is the tail of the list (the remaining list when the first element is removed). fuller advantage of these techniques. (a) We define a database to be natural if given order prop- erty over its attributes can be guaranteed. (All real- world domains we have encountered have this property, and thus are natural.) (b) We discuss a general, efficient (polynomial) inference procedure which we have implemented which is sound and complete over natural domains. In Section 4, we present results of a performance study over queries over TPC-DS. 5. Experimental Results. All nine of the test queries show a significant performance gain using the OD-extended optimizer, with an average 30% time improvement over a ten-GB database. In Section 5, we discuss related work, both previous applied work that used dependencies in optimization (upon which we build), and theoretical work on order dependencies which has provided critical foundations for our current implementation. In Section 6, we outline next steps for this work, and conclude.",Jaroslaw Szlichta,University of Toronto & IBM Toronto Centre for Advanced Studies,szlichta@cs.toronto.edu,Parke Godfrey,York University in Toronto & IBM Toronto Centre for Advanced Studies,godfrey@cse.yorku.ca,Jarek Gryz,York University in Toronto & IBM Toronto Centre for Advanced Studies,jarek@cse.yorku.ca,Wenbin Ma,IBM Toronto Laboratory,wenbinm@ca.ibm.com,Weinan Qiu,IBM Toronto Laboratory,davidqiu@ca.ibm.com,Calisto Zuzarte,IBM Toronto Laboratory,calisto@ca.ibm.com,,,,,,,,,,,,
20200118,250,James Wagner,"DePaul University Chicago, Illinois",jwagne32@depaul.edu,,Detecting Database File Tampering through Page Carving,"Detecting Database File Tampering through Page Carving, Detecting Database File Tampering through Page Carving, Detecting Database File Tampering through Page Carving,Detecting Database File Tampering through Page Carving, Detecting Database File Tampering through Page Carving,  ABSTRACT Database Management Systems (DBMSes) secure data against regular users through defensive mechanisms such as access con- trol, and against privileged users with detection mechanisms such as audit logging. Interestingly, these security mechanisms are built into the DBMS and are thus only useful for monitoring or stopping operations that are executed through the DBMS API. Any access that involves directly modifying database files (at file system level) would, by definition, bypass any and all security layers built into the DBMS itself. In this paper, we propose and evaluate an approach that detects direct modifications to database files that have already bypassed the DBMS and its internal security mechanisms. Our approach applies forensic analysis to first validate database indexes and then compares index state with data in the DBMS tables. We show that indexes are much more difficult to modify and can be further fortified with hashing. Our approach supports most relational DBMSes by leveraging index structures that are already built into the system to detect database storage tampering that would currently remain undetectable. 1 INTRODUCTION DBMSes use a combination of defense and detection mechanisms to secure access to data. Defense mechanisms, such as access control, determine the data granularity and system access granted to different database users; defense mechanisms, such as audit logging, monitor all database activity. Regardless of the defense mechanisms, security breaches are still a legitimate concern ? sometimes due to unintentional granting of extra access control and sometimes due to outright hacking, such as SQL injection. Security breaches are typically detected through analysis of audit logs. However, audit log analysis is unreliable to detect a breach that originated from privileged users. Privileged users, by definition, already have the ability to control and modify access permissions. Therefore, audit logs fundamentally cannot be trusted to detect suspicious activity. Additionally, privileged users commonly have access to database files. Consider a system administrator who maliciously, acting as the root, edits a DBMS data file in a Hex editor or through a programming language, such as Python. The DBMS, unaware of external file write activity taking place outside its own pro- grammatic access, cannot log it, and thus the tampering attack remains undetected. Current DBMSes do not provide tools against insider threats ? in general, a built-in security mechanism is vulnerable to in- sider attacks. While a DBMS will not be able to detect direct storage changes, file-level modifications potentially create incon- sistencies within the auxiliary data structures maintained by a DBMS. Forensics tools that examine file contents can be used to detect such inconsistencies, and determine if insider threats have taken place. Recently we proposed the first database foren- sic tool, DBCarver, that can be used to detect deleted data from database pages [31]. However, database forensic tools such as DBCarver merely extract forensic artifacts but do not search for inconsistencies within the data structures maintained by a DBMS. In this paper, we propose a system, DBStorageAuditor, that detects database file tampering by identifying inconsistencies in storage through a direct inspection of internal database struc- tures. DBStorageAuditor utilizes existing database forensic tech- niques and expands them to extract additional necessary storage artifacts. These artifacts are then used to detect inconsistencies within indexes and between indexes and tables. The underlying premise of our approach is that all relational databases follow patterns in storage over which the privileged user has little or no control. We inspect these storage patterns to detect unusual activity. We motivate DBStorageAuditor through an example: Example 1. Malice is the system administrator for a shipping company, FriendlyShipping. Malice is bribed by a competing com- pany to interfere with the orders going to Seattle. Malice does not have access to the DBMS, but she does have access to the server where the database files reside. Malice writes a Python script that will open and directly modify the database file containing the Orders table. The script then opens the database file, finds all records containing the string  'Seattle ', and explicitly overwrites entire records with the NULL ASCII character (decimal value 0). Figure 1 illustrates the result of Malice 's script actions. Since the record was erased without the DBMS (API has never seen that command) all DBMS security was bypassed, and the operation was never recorded in the log file. When FriendlyShipping investigates the missing Seattle orders, the audit log can only explain deleted orders for (2, Chair, New York) and (6, Chair, Detroit). The audit logs contain no trace of the Seattle order being deleted because it was not deleted but rather wiped out externally. To simplify in the above example, we have omitted some details of database file tampering, which we expand on later in Section 5. Barring those details in Example 1, the value in the City index still exists in index storage even though the entire record is erased. Therefore, an inconsistency can be identified by mapping back the index value to the empty gap in table storage. The empty gap in table storage exists because a database only marks a record when it is deleted, and only overwrites the record with data from a newly inserted record. However, making the mapping from the index value to the associated record must be based on the behavioral rules of database storage, such as page and record layout. We use database forensic tools to understand database layout, and using that layout, perform the necessary mapping. It is not impossible for a scrupulous system administrator to (i) tamper with the index and create a cascade of inconsistencies throughout the index structure, or (ii) for an attacker who has privileges to modify database files to acquire privileges to sus- pend or kill logging mechanisms at the operating system level if necessary, or (iii) for a knowledgeable adversary to easily avoid corrupting storage and keep checksum values consistent. How- ever, in spite of increased level of threat, we repeatedly show that accurate knowledge about data layout can be used to gather evidence and prove if any malicious activity has taken place. Previously we developed an approach to detect malicious ac- tivity when DBMS logging is disabled [28]. In this approach we analyzed unlogged activity (executed through a proper DBMS API) but strictly assumed that database files were not exposed to tampering. In this paper, we address the tampering vulnerability where the database files are physically altered. Developing an auditing system for DBMSes is part of our larger goal to open up the database system and its storage to users, for performance and forensics investigation. The rest of the paper is organized as follows: Section 2 cov- ers related work. Section 3 discusses concepts of database stor- age used throughout the paper. Section 4 defines the adver- sary we seek to defend against. Section 5 details how to per- form database file tampering. Section 6 provides an overview of DBStorageAuditor. Section 7 describes how we utilize data- base forensics. Section 8 addresses index tampering. Section 9 proposes a method to organize carved index output making our system scalable. Section 10 discusses how to detect file tampering using inconsistencies between carved index data and table data. Section 11 provides a thorough evaluation of our system.",James Wagner,"DePaul University Chicago, Illinois",jwagne32@depaul.edu,Alexander Rasin,"DePaul University Chicago, Illinois",arasin@depaul.edu,Karen Heart,"DePaul University Chicago, Illinois",kheart@depaul.edu,Tanu Malik,"DePaul University Chicago, Illinois",tmalik1@depaul.edu,Jacob Furst,"DePaul University Chicago, Illinois",jfurst@depaul.edu,Jonathan Grier,"GrierForensics Pikesville, Maryland ",jdgrier@grierforensics.com,,,,,,,,,,,,
20200119,1126,Orestis Polychroniou,Columbia University,orestis@cs.columbia.edu,,Track Join: Distributed Joins with Minimal Network Traffic,"Track Join: Distributed Joins with Minimal Network Traffic, Track Join: Distributed Joins with Minimal Network Traffic, Track Join: Distributed Joins with Minimal Network Traffic, Track Join: Distributed Joins with Minimal Network Traffic, Track Join: Distributed Joins with Minimal Network Traffic, ABSTRACT Network communication is the slowest component of many operators in distributed parallel databases deployed for large- scale analytics. Whereas considerable work has focused on speeding up databases on modern hardware, communica- tion reduction has received less attention. Existing parallel DBMSs rely on algorithms designed for disks with minor modifications for networks. A more complicated algorithm may burden the CPUs, but could avoid redundant transfers of tuples across the network. We introduce track join, a novel distributed join algorithm that minimizes network traffic by generating an optimal transfer schedule for each distinct join key. Track join extends the trade-off options between CPU and network. Our evaluation based on real and synthetic data shows that track join adapts to diverse cases and degrees of locality. Considering both network traffic and execution time, even with no locality, track join outperforms hash join on the most expensive queries of real workloads. 1. INTRODUCTION The processing power and storage capacity of a single machine can be large enough to fit small to medium scale databases. Nowadays, servers with memory capacity of more than a terabyte are common. Packing a few multi-core CPUs on top of shared non-uniform access (NUMA) RAM provides substantial parallelism, where we can run database opera- tions (i.e. sort, join, and group-by) on RAM-resident data at rates of a few gigabytes per second [2, 3, 29, 34, 36]. Database research has also evolved to catch up to the hardware advances. Fundamental design rules of the past on how a DBMS should operate are now being revised due to their inability to scale and achieve good performance on modern hardware. Special purpose databases are now popu- lar against the one-size-fits-all approach [32], while accelera- tors [26] are the implicit manifestation of the same concept. ?Work partly done when author was at the Oracle Labs. The advances in database design for storage and execution on modern hardware have not been met by similar advances in distributed parallel database design. When the most fun- damental work on distributed and parallel databases was published [5, 11, 20], hardware advances of today like multi- core parallelism had not yet occurred. Techniques to speed up short-lived distributed transactions [32] target distributed commit protocols, which suffer from network latencies rather than throughput. Queries where communication is inevitable are less popular research topics or are left for data-centric generic distributed systems for batch-processing [7, 24]. The latest network technologies may be slow relative to main-memory-resident processing. A 40 Gbps InfiniBand measured less than 3 GB/s real data rate per node dur- ing hash partitioning. If done in RAM, partitioning to a few thousand outputs runs close to the memory copy bandwidth [29, 34]. For instance, a server using 4X 8-core CPUs and 1333 MHz quad-channel DDR3 DRAM achieves a partition rate of 30?35 GB/s, more than an order of magnitude higher than the InfiniBand network. Recent work [3] achieves a hash join rate of 4.85 GB/s of 32-bit key, 32-bit payload tu- ples on 4X 8-core CPUs. Such high-end hardware is common in marketed configurations for large-scale analytics. Network optimization is important for both low-end and high-end hardware. In low-end platforms where the network is relatively slow compared to local in-memory processing, we expect the execution time to be dominated by network transfers. Thus, any network traffic reduction directly trans- lates to faster execution. In high-end platforms, given that the network still cannot be as fast as the RAM bandwidth, completion times are also reduced if the reduction in net- work traffic is comparable with the increase in CPU cycles. In order to show how much time databases can spend on the network, we give an example of a real analytical work- load from a large commercial vendor, using a market-leading commercial DBMS. Using 8 machines connected through 40 Gbps InfiniBand (see Section 4 for more details of the con- figuration), we found that the five most expensive queries spend ? 65?70% of their time transferring tuples on the network and account for 14.7% of the total time required to execute the entire analytical workload with more than 1500 queries. All five queries have a non-trivial query plan (4?6 joins), but spend 23%, 31%, 30%, 42%, and 43% of their total execution time on a single distributed hash join. A sophisticated DBMS should have available options to optimize the trade-off between network and CPU utiliza- tion. One solution would be to apply network optimiza- tion at a higher level treating the network as a less desired 1483 route for data transfers, without modifying the underlying algorithms. These approaches are common in generic dis- tributed processing systems [7]. A second solution would be to employ data compression before sending data over the network. This solution is orthogonal to any algorithm but can consume a lot of CPU resources without always yielding substantial compression. A third solution is to create novel algorithms for database operator evaluation that minimize network communication by incurring local processing cost. This approach is orthogonal and compatible with compres- sion and other higher level network transfer optimizations. Grace hash join [9, 17] (throughout the paper we will use the term hash join to refer to Grace hash join on network [9], rather than disk [17]) is the predominant method for executing distributed joins and uses hash partitioning to split the initial problem into shared-nothing sub-problems that can proceed locally per node. Partitioning both tables works almost independently of the table sizes. However, hash join is far from network-optimal because it transfers almost the full size of both tables over the network. Using pre-determined hash functions guarantees load balancing, but limits the probability that a hashed tuple will not be transferred over the network to 1/N on N nodes. We introduce track join, a novel algorithm for distributed joins that minimizes transfers of tuples across the network. The main idea of track join is to decide where to send rows on a key by key basis. The decision uses information about where records of the given key are located. Track join has the following properties: it (i) is orthogonal to data-centric compression, (ii) can co-exist with semi-join optimizations, (iii) does not rely on favorable schema properties, such as foreign key joins, (iv) is compatible with both row-store and column-store organization, and (v) does not assume favor- able pre-existing tuple placement. We implement track join to evaluate the most expensive join operator in the most ex- pensive queries of real workloads. We found that track join reduces the network traffic significantly over known meth- ods, even if pre-existing data locality is removed and all data are used in optimally compressed form throughout the join. Section 2 describes the track join algorithm presenting three variants starting from the simplest. In Section 3, we discuss costs for query optimization, tracking-aware hash joins, and semi-join filtering. Section 4 presents our exper- imental evaluation using both synthetic datasets and real workloads. In Section 5 we briefly discuss future work. In Section 6 we discuss related work and conclude in Section 7.",Orestis Polychroniou,Columbia University,orestis@cs.columbia.edu,Rajkumar Sen,Oracle Labs,rajkumar.sen@oracle.com,Kenneth A. Ross,Columbia University,kar@cs.columbia.edu,,,,,,,,,,,,,,,,,,,,,
20200120,1341,Kristi Morton,"Computer Science and Engineering Department, University of Washington Seattle, Washington, USA",kmorton@cs.washington.edu,,ParaTimer: A Progress Indicator for MapReduce DAGs,"ParaTimer: A Progress Indicator for MapReduce DAGs, ParaTimer: A Progress Indicator for MapReduce DAGs, ParaTimer: A Progress Indicator for MapReduce DAGs, ParaTimer: A Progress Indicator for MapReduce DAGs, ParaTimer: A Progress Indicator for MapReduce DAGs, ABSTRACT Time-oriented progress estimation for parallel queries is a challenging problem that has received only limited attention. In this paper, we present ParaTimer, a new type of timeremaining indicator for parallel queries. Several parallel data processing systems exist. ParaTimer targets environ- ments where declarative queries are translated into ensembles of MapReduce jobs. ParaTimer builds on previous tech- niques and makes two key contributions. First, it estimates the progress of queries that translate into directed acyclic graphs of MapReduce jobs, where jobs on different paths can execute concurrently (unlike prior work that looked at sequences only). For such queries, we use a new type of critical-path-based progress-estimation approach. Second, ParaTimer handles a variety of real systems challenges such as failures and data skew. To handle unexpected changes in query execution times due to runtime condition changes, ParaTimer provides users with not only one but with a set of time-remaining estimates, each one corresponding to a different carefully selected scenario. We implement our es- timator in the Pig system and demonstrate its performance on experiments running on a real, small-scale cluster. Categories and Subject Descriptors H.2.4 [Database Management]: Systems aparallel databases General Terms Algorithms, Design, Experimentation 1. INTRODUCTION Whether in industry or in the sciences, users today need to store, archive, and most importantly analyze increasingly large datasets. For example, the upcoming Large Synoptic Survey Telescope [17] is predicted to generate on the order of 30 TB of data every day. Parallel database management systems [1, 11, 14, 27, 29] and other parallel data processing platforms [6, 8, 12, 15] are designed to process such massive-scale datasets: they enable users to submit declarative queries over the data and they execute these queries in clusters of shared-nothing servers. Although parallelism speeds up query execution, query times in these shared-nothing platforms can still ex- hibit large intra-query and inter-query variance. In such an environment, accurate, time-remaining progress estimation for queries can be helpful both for users and for the system. Indeed, the latter can use timeremaining information to improve resource allocation [30], enable query debugging, or tune the cluster configuration (such as in response to unexpected query runtimes). Accurate progress estimation for parallel queries is a challenging problem because, in addition to the challenges shared with single-site progress estimators [3, 2, 19, 18, 21, 22], parallel environments introduce distribution, concur- rency, failures, data skew, and other issues that must be accounted for. This difficult problem has received only lim- ited attention. Our preliminary prior work [23], which we called Parallax, provided accurate estimates, but only for the limited class of parallel queries that translated into se- quences of MapReduce jobs. We also previously assumed uniform data distribution and the absence of node failures, two assumptions that are unreasonable in practice. To address these limitations, we have developed Para- Timer, a time-remaining indicator for a much broader class of queries and runtime conditions. Many parallel pro- cessing systems exist. Similar to Parallax, we developed ParaTimer for Pig queries [24] running in a Hadoop clus- ter [12], an environment that is a popular open-source paral- lel data-processing engine under active development. Within this context, ParaTimer builds on previous techniques and makes two key contributions. First, ParaTimer estimates the progress of parallel queries expressed as Pig scripts that translate into directed acyclic graphs (DAGs) of MapReduce jobs where jobs on different branches of the DAG can execute concurrently. DAGs require a radically different approach than our prior work for sequences of jobs. As a direct re- sult, unlike Parallax, ParaTimer can handle, for example, Pig scripts with join operators. Second, ParaTimer includes techniques for handling sev- eral real system challenges including failures and data skew. To handle unexpected changes in query execution times such as those due to failures, ParaTimer provides users with a set of time-remaining estimates that correspond to the predicted query execution times in different scenarios (i.e., a 507 single worst-case failure, or data skew at an operator). We call ParaTimer a comprehensive indicator because it provides this set of estimates instead of a single best guess as the other indicators do. Each of ParaTimer 's indicators can be annotated with the scenario that it corresponds to, giving users a detailed picture of possible expected behaviors. While many of the ideas presented in this paper could be adapted to other parallel data processing systems, the Pig/Hadoop environment poses several unique challenges that have informed our design and shaped our implemen- tation. Most notable, a MapReduce-style scheduler requires intermediate result materialization, schedules small pieces of work at a time, and restarts small query fragments when failures occur (rather than restarting entire queries). All three properties affect query progress and its estimates. ParaTimer is designed to be accurate while remaining sim- ple and addressing the above challenges. At a high level, ParaTimer works as follows. For basic progress estima- tion, ParaTimer builds on our prior system Parallax [23]. Parallax estimates time-remaining by breaking queries into pipelines. It estimates time-remaining for each pipeline by considering the work to be done and the speed at which that work will be performed, taking (time-varying) parallelism into account. To get processing speeds, Parallax relies on earlier debug runs of the same query on input data samples generated by the user. To support Pig scripts that translate into MapReduce DAGs where multiple jobs may execute concurrently (such as scripts with join operators), ParaTimer includes a method to identify the critical path in a query plan. It then estimates progress along that path, effectively ignoring other paths. ParaTimer also provides support for a variety of practical challenges, including failures and data skew. For data skew that can be predicted and planned for, ParaTimer takes it into account upfront. For failures and data skew that are not planned, ParaTimer outputs a set of estimates, rather than a single ""best guess, "" that bound the expected query execution time within given possible variations in runtime conditions. An interesting side-benefit of this approach is that when a query time goes outside ParaTimer 's initial bounds, a user knows that there is a problem with either his query or the cluster. ParaTimer 's output can thus aid in performance debugging. Today, parallel systems are being deployed at all scales and each scale raises new challenges. In this paper, we focus on smaller-scale systems with tens of servers because many consumers of parallel data management engines today run at this scale.1 We evaluate ParaTimer 's performance through experiments on an eight-node cluster (set to a maximum degree of parallelism of 32 divided into 16 maps and 16 re- duces). We compare ParaTimer 's performance against Par- allax [23], other state-of-the-art single-node progress indica- tors from the literature [3, 19], and Pig 's current progress indicator [25]. We show that ParaTimer is more accurate than all these alternatives on a variety of types of queries and system configurations. For all queries that we evalu- ated, ParaTimer 's average accuracy is within 5% of an ideal indicator, when given accurate cardinality estimates. The rest of this paper is organized as follows. The next section provides background on MapReduce, Hadoop, and our prior work. Section 3 presents ParaTimer 's approach and key algorithms. Section 4 presents empirical results. Section 5 discusses related work. Section 6 concludes.",Kristi Morton,"Computer Science and Engineering Department, University of Washington Seattle, Washington, USA",kmorton@cs.washington.edu,Magdalena Balazinska,"Computer Science and Engineering Department, University of Washington Seattle, Washington, USA",magda@cs.washington.edu,Dan Grossman,"Computer Science and Engineering Department, University of Washington Seattle, Washington, USA",djg@cs.washington.edu,,,,,,,,,,,,,,,,,,,,,
20200121,1196,Sai Wu,"College of Computer Science and Technology, Zhejiang University, Hangzhou, China",wusai@zju.edu.cn,,PABIRS: A Data Access Middleware for Distributed File Systems,"PABIRS: A Data Access Middleware for Distributed File Systems, PABIRS: A Data Access Middleware for Distributed File Systems, PABIRS: A Data Access Middleware for Distributed File Systems, PABIRS: A Data Access Middleware for Distributed File Systems, PABIRS: A Data Access Middleware for Distributed File Systems, Abstract aVarious big data management systems have emerged to handle different types of applications, which cast very different demands on storage, indexing and retrieval of large amount of data on distributed file system. Such diversity on de- mands has raised huge challenges to the design of new generation of data access service for big data. In this paper, we present PABIRS, a unified data access middleware to support mixed workloads. PABIRS encapsulates the underlying distributed file system (DFS) and provides a unified access interface to systems such as MapReduce and key-value stores. PABIRS achieves dramatic improvement on efficiency by employing a novel hybrid indexing scheme. Based on the data distribution, the indexing scheme adaptively builds bitmap index and Log Structured Merge Tree (LSM) index. Moreover, PABIRS distributes the computation to multiple index nodes and utilizes a Pregel-based algorithm to facilitate parallel data search and retrieval. We empirically evaluate PABIRS against other existing distributed data processing systems and verify the huge advantages of PABIRS on shorter response time, higher throughput and better scalability, over big data with real-life phone logs and TPC-H benchmark. I. INTRODUCTION The explosive growth of big data and the emergence of cloud computing have fueled the quick advances of distributed processing techniques to support storage, retrieval and analysis on massive data. Such quickly growing data bring new challenges to traditional query processing systems, especially when various types of operations are essentially required. The calling logs from billion mobile phone users, for example, are flooding into data centers of telecommunication companies, waiting for querying as well as analysis by the users and decision makers. From time to time, users submit call transaction search queries to retrieve hundreds of their call logs in last few months from billions of available call records, and the information managers are interested in analyzing the user behavior by aggregating the call logs based on the locations, call times and other attributes. The data processing system and the underlying data storage layer are expected to handle the mixed workloads of such high- selective queries and analytic queries in an efficient manner. It turns out that data access is the major bottleneck of the data processing architecture for the mixed workloads. As new data are coming into the system at extremely fast rate, complicated pre-processing techniques dramatically degrade the throughput of data insertion. It is more effective by pushing the data into the distributed file system in a natural way, e.g., simply sorting on the arrival order. Instead of complex optimization before the physical insertion of records into distributed file system, it is more promising to redesign the data access architecture, with new lightweight index over the fast growing data storage layer and well calibrated optimizations based on the in-depth analysis on the characteristics of the data distribution and the workloads. Obviously, such new design of the data access layer heavily depends on the distribution of big and diverse data in the real world. In Figure 1 and Figure 2, we present the statistics of call logs of 1,000 randomly chosen mobile numbers in a distributed file system from a world-class telecommunication company. Each 4MB data block contains call records with sorted in- sertion timestamps, to which new records are continuously appended whenever a new call is made by a mobile phone user. In Figure 1, we report the size of call logs in terms of each caller id, implying that most of the caller ids make a few calls only, while less than 1% of the ids contribute much more call records than the others. This observation follows the well known power law phenomenon commonly appearing in physical world. It results in huge variance on the number of data blocks associated to each caller id, as is shown in Figure 2. The records generated by the top 1% hot caller ids span on almost every block of the distributed file system, potentially incurring high overhead for queries retrieving records. It also brings challenges to the design of the index mechanism on top of the storage layer, when data processing engine tries to locate the sparse records. To fully address these problems, we propose PABIRS, a generic data access middleware for mixed workloads. PABIRS works as an interface between the underlying Distributed File System (DFS) and data management systems, e.g. Hadoop and HBase. It employs a novel hybrid indexing scheme to support efficient data retrieval for various query workloads. Specifically, a cost model component is elicited at the central position in PABIRS, which measures the overhead of different access methods and selects the most effective one. More- over, PABIRS generally supports existing main-stream data processing systems on top, allowing programmers to easily add PABIRS as a middleware layer with minimal efforts. In some sense, PABIRS shares the same design philosophy of the NoDB [2] strategy. However, PABIRS is designed as a middleware of the DFS which is more flexible and can potentially work with any applications using DFS as their storage systems. The most distinguishing feature of PABIRS is its hybrid indexing architecture. As different types of indices were originally designed for different workloads, it is crucial for the cost estimator to understand the workload and facilitate accurate index selection and tuning. For data following the uniform distribution, for example, PABIRS utilizes bitmap index to support fast retrieval, since bitmap index is well known for its high efficiency on sparse record indexing and retrieval. However, bitmap index is incapable of handling skewed distribution with hot keys. LSM index, with a forest of B-trees, is much more superior when records with identical keys frequently appearing in the data. PABIRS applies the dual deployment strategy with both index types, and adaptively chooses an exclusive group of keys for LSM under a unified optimization framework based on the cost evaluation. In its internal architecture, PABIRS disseminates the pro- cessing logics to all distributed file system nodes, where a Pregel engine [17] is run to synchronize the operation units on all the nodes. In particular, the index structure is considered as a graph consisting of multiple levels of vertices and data access service is modeled as a vertex-centric graphical program. The vertices are partitioned among the physical nodes and the search is conducted in parallel. This design makes the index layer of PABIRS a more flexible and extensible component for efficient parallel processing and load balancing. We deploy PABIRS on top of the HDFS [26] and evaluate its performance using the real mobile phone call log data and the well-known TPC-H benchmark. PABIRS presents huge margin of advantages on performance for different work- loads of transaction-based and analytic-based workloads. The remainder of the paper is organized as follows. Section II presents the overview of PABIRS and its architecture. Section III introduces how the hybrid indexing approach works. Section IV discusses the optimization strategies in PABIRS and Section V shows the experiment results. In Section VI, we briefly review previous work and the paper is concluded in Section 7.",Sai Wu,"College of Computer Science and Technology, Zhejiang University, Hangzhou, China",wusai@zju.edu.cn,Gang Chen,"College of Computer Science and Technology, Zhejiang University, Hangzhou, China",cg@zju.edu.cn,Xianke Zhou,"NetEase (Hangzhou) Network Co., Ltd., Hangzhou, China",hzzhouxianke@corp.netease.com,Zhenjie Zhang,"Advanced Digital Sciences Center, Illinois at Singapore Pte. Ltd., Singapore",zhenjie@adsc.com.sg,Anthony K. H. Tung,"School of Computing, National University of Singapore, Singapore",atung@comp.nus.edu.sg,Marianne Winslett,"Deparement of Computer Science, University of Illinois at Urbana-Champaign, USA",winslett@illinois.edu,,,,,,,,,,,,
20200122,1342,Paolo Bellavista,"Universit? di Bologna, Department of Computer Science and Engineering, Bologna, Italy",paolo.bellavista@unibo.it,,Adaptive Fault-Tolerance for Dynamic Resource Provisioning in Distributed Stream Processing Systems,"Adaptive Fault-Tolerance for Dynamic Resource Provisioning in Distributed Stream Processing Systems, Adaptive Fault-Tolerance for Dynamic Resource Provisioning in Distributed Stream Processing Systems, Adaptive Fault-Tolerance for Dynamic Resource Provisioning in Distributed Stream Processing Systems, Adaptive Fault-Tolerance for Dynamic Resource Provisioning in Distributed Stream Processing Systems, Adaptive Fault-Tolerance for Dynamic Resource Provisioning in Distributed Stream Processing Systems, ABSTRACT A growing number of applications require continuous processing of high-throughput data streams, e.g., financial anal- ysis, network traffic monitoring, or Big Data analytics for smart cities. Stream processing applications typically require specific quality-of-service levels to achieve their goals; yet, due to the high time-variability of stream characteris- tics, it is often inefficient to statically allocate the resources needed to guarantee application Service Level Agreements (SLAs). In this paper, we present LAAR, a novel method for adaptive replication that trades fault tolerance for in- creased capacity during load spikes. We have implemented and validated LAAR as a middleware layer on top of IBM In- foSphere Streamsr. We have performed a wide set of experiments on an industrial-quality 60-core cluster deployment and we show that, under the assumption of only statistical knowledge of streams load distribution, LAAR can reduce resource consumption while guaranteeing an upper-bound on information loss in case of failures. Keywords data streams processing, fault-tolerance, dynamic adapta- tion, service-level agreement, IBM InfoSphere Streamsr 1. INTRODUCTION In recent years, the ability to effectively process Big Data Streams is becoming increasingly important: the vision of smarter cities where data from several physical-world sources are continuously collected, filtered, analyzed, and fed back to administrators and citizens to assist them in their hour-by-hour tasks is just one example of the multitude of novel scenarios where handling large and unbounded flows of information in real-time is a primary requirement. Experience with Cloud services [31] has shown that the possibility to offload the management of computing infras- tructures to third parties represents an attractive opportu- nity for both developers and cloud providers. However, in a cloud environment, the nature of stream processing applica- tions poses hard challenges to platform providers, including the ability to offer, at the same time, extreme performance elasticity in spite of load variations and resiliency to failures, while keeping costs limited. From a provider perspective, one major problem lies in the necessity to handle load fluctuations due to sudden and possibly temporary variations in the rates of data streams feeding the hosted applications. If not handled properly, in fact, load peaks can lead to increased processing latency due to data queuing and to data loss due to queue overflows. To avoid these effects, it is necessary to allocate the proper amount of additional resources for the overloaded applica- tions, either statically or dynamically when load variations are detected [4, 8, 22]. Another typical requirement for stream processing appli- cations is the implementation of fault-tolerance techniques. In fact, since they usually run for (indefinitely) long time in- tervals, failures are unavoidable. Many proposals in the lit- erature have investigated possible fault-tolerance approaches  a including active replication [9, 28], checkpointing [11, 18], replay logs [6, 16], or hybrid solutions [34]  a each providing different trade-offs between runtime cost in absence of fail- ures (best-case) and recovery cost. Whichever the adopted technique, maintaining some form of replication at some level (software/hardware components, state, or messages) is a significant overhead in terms of computing resources. In a large class of applications, however,  ""perfect "" fault tolerance is not always required, while it is of primary im- portance to effectively manage temporary load variations. This is very common, for example, when dealing with Smart City-generated Big Data. In this context, in fact, large data streams are produced by many distributed sources  a e.g., mobile phones, ad-hoc sensing devices, or vehicles  a that continuously capture and transmit sensed environmen- tal features. These data need to be analyzed in real-time, and results must be promptly delivered to let appropriate control actions be performed. In this kind of scenarios, controlled information loss is usually tolerable, given the common partial information redundancy or overlap of input streams1. Consider, for instance, an application used to control traffic light signals based on periodic reports of vehicles ' positions, among other factors. During high traffic conditions (i.e., high system load), it is clearly preferable to compute on incomplete information than delay control decisions, given the high redundancy in reported positions. At the same time, during low traffic conditions, processing events with accuracy is still important. In this work, we investigate the possibility to trade-off reli- ability guarantees and execution cost, and use the conserved resources to handle load variations. We propose a novel method, called Load-Adaptive Active Replication (LAAR), that dynamically deactivates and activates redundant replicas of application Processing Elements (PE) in order to claim/release resources and accommodate temporary load variations. Our technique provides a-priori guarantees about the achievable levels of fault-tolerance, expressed in terms of an internal completeness metric that captures the max- imum amount of information that can be lost in case of failures. We show that LAAR can be suitably implemented as a middleware-level layer on top of existing stream pro- cessing platforms, and we present general architectural and design guidelines about how to do it efficiently. As a working proof-of-concept, we describe an implementation of LAAR on top of IBM InfoSphere Streamsr [13], an enterprise-level stream processing platform, and we discuss experimental results about the performance of LAAR on a 60-core IBM BladeCenterr cluster deployment. The remainder of the paper is organized as follows: af- ter reviewing the related literature in Section 2, we present the considered SLA-aware stream processing service model in Section 3. In Section 4, we model our middleware and explain its goals and runtime architecture. Finally, in Sec- tion 5, we report a wide set of performance results that quantitatively evaluate the effectiveness of our proposal. ",Paolo Bellavista,"Universit? di Bologna, Department of Computer Science and Engineering, Bologna, Italy",paolo.bellavista@unibo.it,Antonio Corradi,"Universit? di Bologna, Department of Computer Science and Engineering, Bologna, Italy",antonio.corradi@unibo.it,Spyros Kotoulas,"Smarter Cities Technology Centre, IBM Research, Dublin, Ireland",spyros.kotoulas@ie.ibm.com,Andrea Reale,"Universit? di Bologna Department of Computer Science and Engineering Bologna, Italy",andrea.reale@unibo.it,,,,,,,,,,,,,,,,,,
20200123,1343,Nadathur Satish,"Throughput Computing Lab, Intel Corporation",nadathur.rajagopalan.satish@intel.com,,Fast Sort on CPUs and GPUs: A Case for Bandwidth Oblivious SIMD Sort,"Fast Sort on CPUs and GPUs: A Case for Bandwidth Oblivious SIMD Sort, Fast Sort on CPUs and GPUs: A Case for Bandwidth Oblivious SIMD Sort, Fast Sort on CPUs and GPUs: A Case for Bandwidth Oblivious SIMD Sort, Fast Sort on CPUs and GPUs: A Case for Bandwidth Oblivious SIMD Sort, Fast Sort on CPUs and GPUs: A Case for Bandwidth Oblivious SIMD Sort, ABSTRACT Sort is a fundamental kernel used in many database operations. In-memory sorts are now feasible; sort performance is limited by compute flops and main memory bandwidth rather than I/O. In this paper, we present a competitive analysis of comparison and noncomparison based sorting algorithms on two modern architectures - the latest CPU and GPU architectures. We propose novel CPU radix sort and GPU merge sort implementations which are 2X faster than previously published results. We perform a fair comparison of the algorithms using these best performing implementations on both architectures. While radix sort is faster on current architectures, the gap narrows from CPU to GPU architectures. Merge sort performs better than radix sort for sorting keys of large sizes - such keys will be required to accommodate the increasing cardinality of future databases. We present analytical models for analyzing the performance of our implementations in terms of architectural features such as core count, SIMD and bandwidth. Our obtained performance results are successfully predicted by our models. Our analysis points to merge sort winning over radix sort on future ar- chitectures due to its efficient utilization of SIMD and low band- width utilization. We simulate a 64-core platform with varying SIMD widths under constant bandwidth per core constraints, and show that large data sizes of 240 (one trillion records), merge sort performance on large key sizes is up to 3X better than radix sort for large SIMD widths on future architectures. Therefore, merge sort should be the sorting method of choice for future databases. Categories and Subject Descriptors H.2 [Database Management]: Systems General Terms Performance, Algorithms 1. INTRODUCTION Sorting is of fundamental importance in databases. Common applications of sorting in database systems include index creation, user-requested sort queries, and operations such as duplicate removal, ranking and merge-join operations. Sorting on large data- bases has traditionally focused on external sorting algorithms. How- ever, the rapid increase in main memory capacity has made in- memory sorting feasible. In-memory sorts are bounded by compute, bandwidth and la- tency characteristics of processor architectures. Recent and future trends in modern computer architectures are therefore of primary importance for high performance sort implementations. Compute capacity has increased through a combination of having more cores (thread-level parallelism) with each core having wide vector (SIMD) units to exploit data-level parallelism. Core counts will increase rapidly as Moore 's law continues to increase the number of onchip transistors. The SIMD width of modern CPU and GPU pro- cessors has been steadily increasing - from 128-bit in SSE architec- tures, 256-bit in AVX [14] to 512-bit in the upcoming Larrabee [23] architecture. GPUs have a logical 1024-bit SIMD with physical SIMD widths of 256-bits on the latest NVIDIA GTX 200 series, increasing to 512-bits on the upcoming Fermi architecture [19]. Memory bandwidth is increasing at a slower pace than compute. Algorithms that are bound by memory bandwidth will not scale well to future architectures. A variety of algorithms have been developed for sorting a list of numbers. Sorting algorithms can be broadly classified as ei- ther comparison based or non-comparison based sorts. Comparison based sorting algorithms rearrange the data items based on the re- sults of comparing pairs of elements at a time. Non-comparison based sorts rely on using the absolute values of the data items, rather than comparisons, to rearrange the data. A common example of a non-comparison based sort is radix sort. Radix sort is a mul- tiple pass sort algorithm that buckets data according to individual digits of the data items. Sorting algorithms differ in their compu- tational complexity, which dictates the inherent amount of com- putation required by the algorithm, and also differ in their archi- tectural friendliness, or how well they can use current and future architectural trends, such as increasing thread-level and data-level parallelism on modern architectures. There is often a trade-off be- tween these factors. For instance, radix sorts are not naturally data-parallel, unlike comparison sorts that can use data parallel merging networks. Further, radix sort needs many passes over each data item - resulting in high bandwidth utilization. Merge sort, on the other hand, can be made bandwidth friendly (and is used in external disk sorts for this reason). Opposing these architectural inefficiencies of radix sort is its lower computational complex- ity of O(N), as against the lower bound  (N logN) of comparison based sorts. The right choice of sorting algorithms becomes a trade- off between computational complexity and architectural efficiency; such trade-offs are architecture-dependent. There has, so far, not 351 been much work in analyzing the efficiency with which sorting techniques utilize modern architectural features. In this work, we evaluate these trade-offs on two sorting algorithms - radix sort with a low O(N) computational complexity, and a SIMD-efficient and bandwidth oblivious merge sort with a complexity of O(N logN). We investigate these trade-offs on the latest CPU and GPU archi- tectures, which are commercially widespread and hence of interest to the database community. The Intel Core i7 CPU has 4 cores each with 128-bit SSE width, while the NVIDIA GTX 280 has 30 SMs each with 256-bit SIMD units. In order to make such an investigation fair, the algorithms must be implemented as efficiently as possible on each architecture. We, therefore, identified bottlenecks found in common implementations of each sorting algorithm (such as irregular memory accesses, lack of SIMD use, conflicts in local storage such as cache or shared memory) and optimized our algorithms to avoid such bottlenecks. Our novel CPU radix sort algorithm uses a buffer stored in cache to localize scatters; this avoids capacity and conflict misses, resulting in the fastest reported CPU sorts. We implemented an optimized merge sort on the GPU which is only 10% off the best known sort- ing algorithm (a radix sort) on the GPU. We adopted highly opti- mized codes where available, including a CPU merge sort and a GPU radix sort. Our resulting implementations are the best per- forming implementations of these sorting algorithms on these ar- chitectures, and include the highest performing sort on each archi- tecture. We provide a performance model for each of our result- ing implementations in terms of the compute, bandwidth and SIMD usage of our algorithms. Our analysis results match well with the actual performance results. The influence of architectural awareness on sorting algorithms is clear from our investigations. The best implementation of the same radix sort algorithm is very different on CPUs and GPUs - a SIMD friendly 1-bit split based code is best on GPUs that heavily rely on data-level parallelism, while a scalar buffer-based scatter approach works best on CPUs with lower SIMD widths. However, we show that both versions of radix sort have heavy bandwidth demands due to their multi-pass nature. The bandwidth demand of radix sort increases for large key sizes - radix becomes bandwidth bound on even the latest CPUs on 6-byte keys. GPUs have much higher bandwidth - however, even then a part of the radix sort algorithm is bandwidth bound. Algorithms that are bandwidth bound cannot use compute resources effectively. On the other hand, merge sort uses bandwidth resources efficiently, and is compute-bound. Merge sort hence becomes faster than radix on GPUs on keys larger than 8- bytes, and faster on CPUs for keys greater than 9-bytes. In addition, merge sort can also utilize SIMD resources efficiently. While the higher computational complexity of merge sort does make it slower than radix on current architectures for large data sets of 4-byte keys, the gap narrows from 1.7X on CPUs with 128-bit SIMD to only about 10% on GPUs with 256-bit SIMD. Having identified the bottlenecks of these algorithms on current hardware, we project the performance of our algorithms on future architectures with wider SIMD and lower bandwidth-to-compute requirements. The bandwidth-oblivious SIMD-friendly merge sort will perform better on such architectures. We confirm our projec- tions by simulating our algorithms on architectures with varying SIMD widths, and show that as SIMD widths increase to 2048- bit and beyond, SIMD merge sort performance for 8-byte keys is 1.5X faster than radix sort on data sizes as large as 240 (one trillion records). For 16-byte keys, the performance ratio further increases to 3X better than radix sort. The bandwidth-oblivious SIMD- friendly merge sort, should, therefore, be the sorting method of choice for future databases.",Nadathur Satish,"Throughput Computing Lab, Intel Corporation",nadathur.rajagopalan.satish@intel.com,Changkyu Kim,"Throughput Computing Lab, Intel Corporation",0,Jatin Chhugani,"Throughput Computing Lab, Intel Corporation",,Anthony D. Nguyen,"Throughput Computing Lab, Intel Corporation",,Victor W. Lee,"Throughput Computing Lab, Intel Corporation",,Daehyun Kim,"Throughput Computing Lab, Intel Corporation",,Pradeep Dubey,"Throughput Computing Lab, Intel Corporation",,,,,,,,,,
20200124,1344,Stacy Patterson,"Department of Electrical Engineering Technion - Israel Institute of Technology Haifa, 32000, Israel",stacyp@ee.technion.ac.il,,"Serializability, not Serial: Concurrency Control and Availability in Multi-Datacenter Datastores","Serializability, not Serial: Concurrency Control and Availability in Multi-Datacenter Datastores, Serializability, not Serial: Concurrency Control and Availability in Multi-Datacenter Datastores, Serializability, not Serial: Concurrency Control and Availability in Multi-Datacenter Datastores, Serializability, not Serial: Concurrency Control and Availability in Multi-Datacenter Datastores, Serializability, not Serial: Concurrency Control and Availability in Multi-Datacenter Datastores, ABSTRACT We present a framework for concurrency control and availability in multi-datacenter datastores. While we consider Google 's Megastore as our motivating example, we define general abstractions for key components, making our solu- tion extensible to any system that satisfies the abstraction properties. We first develop and analyze a transaction management and replication protocol based on a straightforward implementation of the Paxos algorithm. Our investigation reveals that this protocol acts as a concurrency prevention mechanism rather than a concurrency control mechanism. We then propose an enhanced protocol called Paxos with Combination and Promotion (Paxos-CP) that provides true transaction concurrency while requiring the same per instance message complexity as the basic Paxos protocol. Finally, we compare the performance of Paxos and Paxos-CP in a multi-datacenter experimental study, and we demon- strate that Paxos-CP results in significantly fewer aborted transactions than basic Paxos. 1. INTRODUCTION Cloud computing has the potential to become the founda- tion for most information technology architectures. It offers application developers access to seemingly infinite storage, compute, and network resources, all on a pay-per-use basis. While the appeal of the cloud computing model is obvious from a financial perspective, its success also depends on the ability of clouds to provide reliable, scalable services that support the features developers need. In particular, it is important that cloud datastores, such as Google 's BigTable [8] and Amazon 's SimpleDB [1], provide support for various types of data consistency and guarantee the availability of application data in the face of failures. Initially, cloud datastores provided only eventually con- sistent update operations guaranteeing that updates would eventually propagate to all replicas. While these datastores were highly scalable, developers found it difficult to create applications within the eventual consistency model [20]. Many cloud providers then introduced support for atomic access to individual data items, in essence, providing strong consistency guarantees. This consistency level has become a standard feature that is offered in most cloud datastore im- plementations, including BigTable, SimpleDB, and Apache HBase [16]. Strong consistency of single data items is suffi- cient for many applications. However, if several data items must be updated atomically, the burden to implement this atomic action in a scalable, fault tolerant manner lies with the software developer. Several recent works have addressed the problem of implementing ACID transactions in cloud datastores [2, 10, 11], and, while full transaction support re- mains a scalability challenge, these works demonstrate that transactions are feasible so long as the number of tuples that are transactionally related is not  ""too big "". While many solutions have been developed to provide con- sistency and fault tolerance in cloud datastores that are hosted within a single data center, these solutions are of no help if the entire datacenter becomes unavailable. For example, in April 2011, a software error brought down one of Amazon 's EC2 availability zones and caused service dis- ruption in the U.S. East Region [24]. As a result, major web sites like Reddit, Foursquare, and Quora were unavail- able for hours to days [5]. And, in August 2011, lightning caused Microsoft and Amazon clouds in Dublin [15] to go offline for hours. In both instances, there were errors in the recovery process, and it was not possible to restore a consistent snapshot of some application data. These recent outages demonstrate the need for replica- tion of application data at multiple datacenters as well as the importance of using provably correct protocols for performing this replication. In a recent work, Baker et al. de- scribe Megastore, Google 's approach to providing transac- tions in the cloud with full replication at multiple datacen- ters [2]. Megastore is implemented on top of BigTable and provides support for ACID transactions over small sets of data items called entity groups. It uses multi-version concurrency control and a replicated write-ahead log. Replication is performed using the Paxos algorithm [18] to ensure consistency even with unreliable communication and datacenter outages. While the paper presents an overview of the Megastore system, it lacks the formality and detail required to verify Megastore 's correctness. We assert that such analysis is needed for systems like Megastore, especially in light of the outages described above and the widely acknowledged difficulties associated with understanding and implementing the Paxos algorithm [7, 19, 25]. In this work, we address the need for formal analysis of replication and concurrency control in transactional cloud datastores. We define and analyze several Paxos-based pro- tocols for replication and transaction management in the multi-datacenter setting. While we take Megastore as our motivating example, we define general abstractions for each of the key components, and we use these abstractions in our protocol design and analysis. The specific contributions of our work are: ? We provide a formal description of the Paxos protocol for replication and concurrency control, and we prove its correctness. Through our analysis, we also show that the Paxos protocol, as implemented in Megastore, aborts transactions that could be safely committed. In essence, it acts as a concurrency prevention mechanism rather than a concurrency control mechanism. ? We propose an enhanced replication and concurrency control protocol that we call Paxos with Combination and Promotion (Paxos-CP). Paxos-CP enables true transaction concurrency, with the same per-instance message complexity as the original Paxos protocol. ? We compare the performance of Paxos and Paxos-CP in a multi-datacenter experimental study, and we demon- strate the benefits of our enhanced Paxos protocol. The remainder of this paper is organized as follows. In Section 2, we give an overview of the design of the cloud datastore including the data model and reference architecture. Section 3 summarizes the theoretical foundations that we use to analyze the correctness of the transactional cloud datastore. In Section 4, we present the details of the trans- action manager, including the basic Paxos commit protocol, and we prove its correctness. In Section 5, we present our extended Paxos commit protocol that allows for transaction concurrency, and we prove the correctness of this protocol. We present evaluation results comparing the basic and ex- tended Paxos commit protocols in Section 6. In Section 7, we discuss related work, and we conclude in Section 8.",Stacy Patterson,"Department of Electrical Engineering Technion - Israel Institute of Technology Haifa, 32000, Israel",stacyp@ee.technion.ac.il,Aaron J. Elmore,"Department of Computer Science University of California, Santa Barbara Santa Barbara, CA 93106",aelmore@cs.ucsb.edu,Faisal Nawab,"Department of Computer Science University of California, Santa Barbara Santa Barbara, CA 93106",nawab@cs.ucsb.edu,Divyakant Agrawal,"Department of Computer Science University of California, Santa Barbara Santa Barbara, CA 93106",agrawal@cs.ucsb.edu,Amr El Abbadi,"Department of Computer Science University of California, Santa Barbara Santa Barbara, CA 93106",amr@cs.ucsb.edu,,,,,,,,,,,,,,,
20200125,1380,Zhepeng Yan,"University of Pennsylvania Philadelphia, PA, USA",zhepeng@cis.upenn.edu,,Actively Soliciting Feedback for Query Answers in Keyword Search-Based Data Integration,"Actively Soliciting Feedback for Query Answers in Keyword Search-Based Data Integration, Actively Soliciting Feedback for Query Answers in Keyword Search-Based Data Integration, Actively Soliciting Feedback for Query Answers in Keyword Search-Based Data Integration, Actively Soliciting Feedback for Query Answers in Keyword Search-Based Data Integration, Actively Soliciting Feedback for Query Answers in Keyword Search-Based Data Integration, ABSTRACT The problem of scaling up data integration, such that new sources can be quickly utilized as they are discovered, remains elusive: global schemas for integrated data are difficult to develop and expand, and schema and record matching techniques are limited by the fact that data and metadata are often under-specified and must be disambiguated by data experts. One promising approach is to avoid using a global schema, and instead to develop keyword search- based data integration - where the system lazily discovers associ- ations enabling it to join together matches to keywords, and return ranked results. The user is expected to understand the data domain and provide feedback about answers' quality. The system general- izes such feedback to learn how to correctly integrate data. A major open challenge is that under this model, the user only sees and offers feedback on a few ""top-k"" results: this result set must be carefully selected to include answers of high relevance and answers that are highly informative when feedback is given on them. Existing systems merely focus on predicting relevance, by composing the scores of various schema and record matching algorithms. In this paper we show how to predict the uncertainty associated with a query result's score, as well as how informative feedback is on a given result. We build upon these foundations to develop an active learning approach to keyword search-based data integration, and we validate the effectiveness of our solution over real data from several very different domains. 1. INTRODUCTION The vision of rapid information integration remains elusive, de- spite steady progress in system architectures [13] and in alignment techniques for discovering links among records [11] and schema el- ements [28]. In general, the approach is to define one or more inte- grated or mediated schemas capturing the data domain, use schema mapping (alignment) and entity resolution (record linking) tools to map data sources into the mediated schema, and finally allow users to pose structured queries against mediated schemas. A stumbling block is that string, pattern, and structural similari- ties among data and metadata elements (the core techniques whose outputs are combined by alignment tools) do not suffice to unique- ly identify the correspondences between data or metadata items. The resulting ambiguous matches can only be resolved with do- main (commonly, human) expertise. As a result, many of today's tools aim for semi-automated matching, where the system makes predictions and relies on a human domain expert to correct any mistakes or resolve any uncertainties (e.g., see [28, p. 345]). There are several shortcomings to having a database administra- tor inspect the output of a schema matching tool before adding the mapping to an existing system: (1) administrator vetting becomes a bottleneck to the system incorporating sources; (2) the metadata might not clearly describe the data that must be mapped1; (3) subtle variations in semantics may only show up in occasional, incorrect query results. Moreover, the mediated schema itself can be a bot- tleneck to adding new data, as new sources may have concepts that do not yet exist at the global level. For these reasons, recent work [4, 29, 34, 35] has proposed to complement (or even replace) conventional integration with tech- niques that do not rely on a mediated schema and schema mappings created by an administrator. Instead the proposal is to adopt a keyword search over databases model [5, 19, 20, 25] where matches to individual keywords are assembled into query results by discov- ering ""join trees"" that link the matches. This requires discovering paths of associations (alignments across records, terms, or schema elements in sources) that can join matching records together. Under this model, the output of alignment algorithms is used directly to answer queries, with no administrator intervention: the system relies on the end user to have the domain expertise to vet the re- sults, and to provide feedback [34, 35] on the system's ranking of (some) individual query results. Now instead of having a human administrator correct bad associations, the system must learn the correct score (possibly zero or infinite) of each individual associ- ation, given the user's feedback on query answers that are formed from multiple associations [34]. This model is a form of ""pay-as-you-go"" integration [13], as it enables the system and its users to focus their attention on those associations that relate to actual information needs. The associ- ations relevant to frequently posed queries should be the ones that receive the most attention and refinement. In fact the pay-as-you-go approach can be used to complement and inform more traditional integration techniques: the keyword search log can help a human administrator determine which parts of the data to prioritize integrating, and provide clues for what mappings are most relevant. However, to successfully learn to integrate data, the system must balance its need to acquire feedback useful for answering future queries, versus the requirement that each user immediately gets the information he or she needs. Today's keyword search systems have approached this problem by simply assuming the query scoring function is accurate: they return the top-k results according to the scoring function, which in turn bases its scores on the predicted (but possibly incorrect) output of matching tools. Under this model the user will attempt to remove false positives but has no way of seeing - and providing feedback on - false negatives. Such a model works well when the system returns a good mix of correct and invalid results and the user can ""separate"" them. However, as the number and complexity of sources and their at- tributes increases, many potential queries are likely to have similar scores, due to inherent uncertainty in combining low-confidence results from various matching algorithms. The number of potential results can grow rapidly as the number of keyword matches increases, whereas the number of results seen by the user remains constrained by the dimensions of the screen and the limits of user attention. Thus, when a keyword-based data integration system selects queries to produce answers, it should not merely choose alignments based on the relative scores of associations - but also the uncertainty associated with a given query result, and the informativeness of feedback given on that particular result. In this paper, we use active learning to help the system deter- mine which query results to present, given a combination of their predicted score, their inherent uncertainty, and the amount of infor- mation gained about other potential queries. Intuitively, the infor- mativeness of feedback on a query result is related to how much uncertainty there is about the result's relevance to the query, and how many other similar share features with this result - mean- ing that feedback on the first result also reduces their uncertain- ty. We provide a more precise characterization of informativeness later in the paper. Our work goes beyond previous attempts to use uncertainty-directed ranking in the pay-as-you-go-integration space, such as [24] which focused on individual mappings, by look- ing at the total uncertainty associated with queries and their results, and how this uncertainty should be combined with relevance rank- ing. The key questions addressed in this paper are how to estimate the utility of a given query to the system and to the user, and how to estimate the uncertainty of a query's score, in applying active learning to the problem of determining the relevance of associations to a query. Specifically, we make the following contributions: ? Techniques for estimating the uncertainty associated with a query, through the notions of entropy and variance, and by combining the probability distributions of the output for in- dividual schema matching or record linking outputs. ? Pruning and active learning techniques that focus the user's attention on the query results most likely to either be relevant, or help the system produce better results. ? A scoring model using expected model change to relate the user's model of browsing data to how we should combine and rank both useful and uncertain query answers. ? A method of clustering similar join queries, and choosing the most useful representative. ? An experimental evaluation demonstrating the effectiveness of our approach across several real data domains. Section 2 provides the context of our problem, including the ba- sic workflow of our integration task. Section 3 shows how we as- sess the informativeness of each query. Section 4 then describes how we combine informativeness and predicted score to return ranked query results, and to learn from feedback on them. We experimen- tally analyze our results in Section 5, describe related work in Sec- tion 6, and conclude in Section 7. ",Zhepeng Yan,"University of Pennsylvania Philadelphia, PA, USA",zhepeng@cis.upenn.edu,Nan Zheng,"University of Pennsylvania Philadelphia, PA, USA",nanzheng@cis.upenn.edu,Zachary G. Ives,"University of Pennsylvania Philadelphia, PA, USA",zives@cis.upenn.edu,Partha Pratim Talukdar,"Carnegie Mellon University  Pittsburgh, PA USA",ppt@cs.cmu.edu,Cong Yu," Google, Inc. New York, NY USA",congyu@google.com,,,,,,,,,,,,,,,
