{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "<center>\n",
    "    \n",
    "# 2020.07.31 RC Code\n",
    "\n",
    "## An-Algorithm-for-Peer-Reviewer-Recommendation\n",
    "    \n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-3c9cd3775c16>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-3c9cd3775c16>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    tt.iloc[:,[0,:]]\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "t=[[0,0,0],\n",
    "  [0,0,0]]\n",
    "tt=pd.DataFrame(t)\n",
    "tt.iloc[:,[0,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "\n",
    "#import python packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.datasets import *\n",
    "from sklearn.cluster import *\n",
    "\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from operator import itemgetter\n",
    "from operator import attrgetter\n",
    "\n",
    "from pyjarowinkler import distance\n",
    "from collections import Counter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from math import log\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk,math,time,csv,sys,re,io,os\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def remove_string_special_characters(s):\n",
    "    \n",
    "    stripped = re.sub('[^a-zA-z\\s]', '', s)\n",
    "    \n",
    "    stripped = re.sub('_', '', stripped)\n",
    "    \n",
    "    stripped = re.sub('\\s+', ' ', stripped)\n",
    "    \n",
    "    stripped = stripped.strip()\n",
    "    \n",
    "    if stripped != '':\n",
    "        return stripped.lower()\n",
    "    \n",
    "def multisort(xs, specs):\n",
    "    \n",
    "    for key, reverse in reversed(specs):\n",
    "        \n",
    "        xs.sort(key=attrgetter(key), reverse=reverse)\n",
    "        \n",
    "    return xs\n",
    "\n",
    "def uniq_list(input):\n",
    "    output = []\n",
    "    for x in input:\n",
    "        if x not in output:\n",
    "            output.append(x)\n",
    "    return output\n",
    "\n",
    "def extractive_keyword(path,database_update_path,extract_word_num=25):\n",
    "    \n",
    "    reviewee = pd.read_csv(path, encoding='latin1')\n",
    "    count,temp = len(reviewee),[]\n",
    "\n",
    "    for i in range(count):\n",
    "        \n",
    "        temp_intro = reviewee['submitter_intro'][i]\n",
    "\n",
    "        textrank_textsent_mearge = ''\n",
    "        textrank_text,textrank_sent = '',''\n",
    "\n",
    "        for c in (keywords(temp_intro, words=extract_word_num, lemmatize=True).split('\\n')):\n",
    "            \n",
    "            textrank_text += (c+ \" \")\n",
    "\n",
    "        temp.append(textrank_text)\n",
    "\n",
    "    reviewee['submitter_attribute']=temp\n",
    "    \n",
    "    reviewee.iloc[:,1:].to_csv(database_update_path)\n",
    "    \n",
    "    #return type : pandas.dataframe\n",
    "    return reviewee\n",
    "\n",
    "\n",
    "def professionalism(path,extractive_keyword_result,reviewee_index,top_limit,silhouette_range=25):\n",
    "    \n",
    "    reviewee,index,top=extractive_keyword_result,reviewee_index,top_limit\n",
    "    temp_id,temp_doi = 0,''\n",
    "    \n",
    "    temp_title = reviewee.loc[index]['submitter_title']\n",
    "    temp_attribute = reviewee.loc[index]['submitter_attribute']\n",
    "    \n",
    "    reviewer_attr = pd.read_csv(path, encoding='latin1')\n",
    "    \n",
    "    reviewer_attr.loc[-1] = [str(temp_id),temp_doi,temp_title,temp_attribute]\n",
    "    reviewer_attr.index += 1\n",
    "    reviewer_attr.sort_index(inplace=True)\n",
    "    reviewer = reviewer_attr['reviewer_paper_attribure']\n",
    "    \n",
    "    jac_token,jac,cos,avg=[],[],[],[]\n",
    "\n",
    "    # jaccard_distance\n",
    "    for t in range(len(reviewer)):        \n",
    "        jac_token.append(set(nltk.ngrams((nltk.word_tokenize(reviewer[t])), n=1)))    \n",
    "    for j in range(len(reviewer)):\n",
    "        jac.append(1-(nltk.jaccard_distance(jac_token[0], jac_token[j])))\n",
    "\n",
    "    # cosine_similarity\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    sparse_matrix = count_vectorizer.fit_transform(reviewer)\n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, \n",
    "                      columns=count_vectorizer.get_feature_names(), \n",
    "                      index=[i for i in reviewer])\n",
    "    cos=cosine_similarity(df, df)[0].tolist()\n",
    "\n",
    "    for i in range(len(jac)):\n",
    "        avg.append((jac[i] + cos[i])/2)\n",
    "    reviewer_attr['sim']=avg\n",
    "    \n",
    "    reviewer_attr2 = reviewer_attr.sort_values(by=['sim'], axis=0, ascending=False)\n",
    "    reviewer_attr3=reviewer_attr2[~reviewer_attr2.duplicated(['reviewer_orcid'],keep=False) == True]\n",
    "    reviewer_attr4 = reviewer_attr2[reviewer_attr2.duplicated(['reviewer_orcid'],keep='last') == True]\n",
    "    reviewer_attr5=pd.concat([reviewer_attr3,reviewer_attr4])\n",
    "    reviewer_attr5.rename(columns = {'reviewer_paper_attribure' : 'reviewer_paper_feature'}, inplace = True)\n",
    "    display(reviewer_attr5.iloc[:,[0,2,3,4]])\n",
    "    reviewer2 = list(reviewer_attr5['reviewer_paper_feature'])\n",
    "    \n",
    "    reviewer_attribute=[]\n",
    "    for i in range(len(reviewer2)):\n",
    "        a=((reviewer2[i]).split(' '))\n",
    "        b=a[:20]\n",
    "        temp=''\n",
    "        for j in range(20):\n",
    "            temp += (str(b[j]) + ' ')\n",
    "        reviewer_attribute.append(temp[:-1])\n",
    "    \n",
    "    def tf(t, d):\n",
    "        return d.count(t)\n",
    "\n",
    "    def idf(t):\n",
    "        df = 0\n",
    "        for doc in reviewer_attribute:\n",
    "            df += t in doc\n",
    "        return log(N/(df + 1))\n",
    "\n",
    "    def tfidf(t, d):\n",
    "        return tf(t,d)* idf(t)\n",
    "    try:\n",
    "        tfidf_m = pd.read_csv('./tfidf_m.csv', encoding='latin1',index_col=0)\n",
    "    except:\n",
    "        vocab = list(set(w for doc in reviewer_attribute for w in doc.split()))\n",
    "        vocab.sort()\n",
    "\n",
    "        N = len(reviewer_attribute)\n",
    "\n",
    "        #tfidf_Metrix\n",
    "        result = []\n",
    "        for i in range(N):\n",
    "            result.append([])\n",
    "            d = reviewer_attribute[i]\n",
    "            for j in range(len(vocab)):\n",
    "                t = vocab[j]\n",
    "\n",
    "                result[-1].append(tfidf(t,d))\n",
    "        tfidf_m = pd.DataFrame(result, columns = vocab)\n",
    "        tfidf_m.to_csv('./tfidf_m.csv',index=False)\n",
    "    index_df=[]\n",
    "    for j in range(len(tfidf_m)):\n",
    "        index_df.append('Manuscript '+str(j))\n",
    "    tfidf_m.index=index_df\n",
    "    display(tfidf_m.iloc[:,[85,786,787,941,1392,1573,2550,2659,3099,3438,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]])\n",
    "    \n",
    "    try :\n",
    "        dissim_m = pd.read_csv('./dissimilarity.csv', encoding='latin1',index_col=0)\n",
    "    except :\n",
    "        #dissimilarity metrix\n",
    "        dissimilarity=[]\n",
    "        for i in range(0,len(tfidf_m.index)):\n",
    "            temp2=[]\n",
    "            a1=[(tfidf_m.iloc[i,:]).to_list()]\n",
    "            for j in range(0, len(tfidf_m.index)):\n",
    "                a2=[(tfidf_m.iloc[j,:]).to_list()]\n",
    "                a3=(euclidean_distances(a1,a2))[0][0]\n",
    "                temp2.append(a3)\n",
    "            dissimilarity.append(temp2)\n",
    "        dissim_m = pd.DataFrame(dissimilarity)\n",
    "        dissim_m.to_csv('./dissimilarity.csv')\n",
    "\n",
    "    dissim_m.index=index_df\n",
    "    dissim_m.columns=index_df\n",
    "    \n",
    "    display(dissim_m)\n",
    "    dissimilarity=dissim_m.values\n",
    "    \n",
    "    model1 = AgglomerativeClustering(n_clusters=8, affinity='euclidean', linkage='ward')\n",
    "    model1.fit(dissimilarity)\n",
    "    labels1 = model1.labels_\n",
    "    \n",
    "    reviewer_attr5['cluster']=labels1\n",
    "    \n",
    "    cluster_reviewer = reviewer_attr5[reviewer_attr5['cluster'] == reviewer_attr5.loc[0]['cluster']]\n",
    "#     cluster_reviewer2 = cluster_reviewer.sort_values(by=['sim'], axis=0, ascending=False)\n",
    "\n",
    "    cluster_reviewer2 = cluster_reviewer.sort_values(by=['sim'], axis=0, ascending=False)\n",
    "    \n",
    "    professionalism=cluster_reviewer2.iloc[0:top+1] #1\n",
    "\n",
    "    #return type : pandas.dataframe\n",
    "    return professionalism\n",
    "\n",
    "def interest(co_author_path, reviewer_information_path, co_author_network_path, professionalism_result, extractive_keyword_result, reviewee_index,matrix_multifly_count):\n",
    "    \n",
    "    #매개변수 전달\n",
    "    path1,path2=co_author_path,reviewer_information_path\n",
    "    network_path=co_author_network_path\n",
    "    temp,reviewee = professionalism_result,extractive_keyword_result\n",
    "    index,multifly=reviewee_index,matrix_multifly_count\n",
    "\n",
    "    #import Dataset\n",
    "    co_author_csv = pd.read_csv(path1, encoding='latin1')\n",
    "    \n",
    "    #merge coauthor & 전문성 검사 결과\n",
    "    co_author_df = co_author_csv.merge(temp, on=['reviewer_orcid'])  \n",
    "    co_author_df2 = co_author_df.iloc[:]['reviewer_name'].tolist()\n",
    "    \n",
    "    #import network\n",
    "    try :\n",
    "        #read network csv\n",
    "        network_csv = pd.read_csv(network_path, encoding='latin1',index_col=0)\n",
    "    except FileNotFoundError :\n",
    "        df1=pd.read_csv('./network/network0704.csv')\n",
    "        df2=pd.read_csv('./network/network0704_2.csv')\n",
    "\n",
    "        tmp=[1]\n",
    "        tmp.extend(i*2 for i in range(1,11))\n",
    "\n",
    "        for k in range(1,len(df1.columns)):\n",
    "            a=df1.columns[k]\n",
    "            a1=df2.loc[df2['reviewer_coauthor_title']==a]\n",
    "            a_list=[]\n",
    "            for i in range(len(tmp)):\n",
    "                a_list.append(a1.iloc[0][tmp[i]])\n",
    "            for i in range(len(df1)):\n",
    "                if (df1.iloc[i,0] in a_list) is True :df1.iloc[i,k]=1\n",
    "                else :df1.iloc[i,k]=0\n",
    "\n",
    "        mat=(df1.values)[:,1:]\n",
    "        mat2=mat.T\n",
    "        mat3=np.dot(mat,mat2)\n",
    "        for i in range(len(mat3)):\n",
    "            mat3[i,i]=0\n",
    "        fof=np.dot(mat3,mat3)\n",
    "        \n",
    "        df1_index=(df1.iloc[:,0]).tolist()\n",
    "        df1_col=(df1.columns)[1:]\n",
    "        network_csv=pd.DataFrame(data=mat3,index=df1_index,columns=df1_index)\n",
    "        network_csv.to_csv(network_path)\n",
    "    \n",
    "    display(network_csv)\n",
    "    reviewer_list=(network_csv.index).tolist()\n",
    "    \n",
    "    reviewee_list=[]\n",
    "    reviewee.fillna(0, inplace=True)\n",
    "    for i in range(1,11):\n",
    "        col_index = (i*3)+5\n",
    "        if reviewee.loc[index][col_index] != 0:\n",
    "            reviewee_list.append(reviewee.loc[index][col_index])\n",
    "    \n",
    "    co_rel_df = pd.DataFrame(\n",
    "        columns=[i for i in reviewer_list],\n",
    "        index=[j for j in reviewee_list])\n",
    "    \n",
    "    for i in range(len(reviewee_list)):\n",
    "        indet_temp=reviewer_list.index(reviewee_list[i])\n",
    "        co_rel_df.iloc[i,indet_temp]=1\n",
    "    co_rel_df.fillna(0, inplace=True)\n",
    "    \n",
    "    display(co_rel_df.iloc[:,19:])\n",
    "    \n",
    "    network_csv_v=network_csv.values\n",
    "    for i in range(multifly):\n",
    "        network_csv_v = network_csv_v.dot(network_csv_v)\n",
    "\n",
    "    co_rel_df_v=co_rel_df.values\n",
    "    fof = co_rel_df_v.dot(network_csv_v)\n",
    "    \n",
    "    df_fof=pd.DataFrame(data=fof,\n",
    "                 index=(co_rel_df.index).tolist(),\n",
    "                 columns=(network_csv.index).tolist())\n",
    "    \n",
    "    display(df_fof.iloc[:,[20,21,22,23,24,26,27,28,29,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50]])\n",
    "    df_fof_series =df_fof.loc[:, (df_fof != 0).any(axis=0)]\n",
    "    df_fof_series_list=(df_fof_series.columns).tolist()\n",
    "    \n",
    "    reviewer_list1 = list(set(co_author_df2).difference(df_fof_series_list))\n",
    "    \n",
    "    co_inst_csv = pd.read_csv(path2, encoding='latin1')\n",
    "\n",
    "    co_inst_df = co_inst_csv.merge(temp, on=['reviewer_orcid'])\n",
    "\n",
    "    reviewee_list2=[]\n",
    "    for i in range(1,11):\n",
    "        col_index = (i*3)+6\n",
    "        if reviewee.loc[index][col_index] != 0:\n",
    "            reviewee_list2.append(reviewee.loc[index][col_index])\n",
    "    \n",
    "    reviewer_list2,reviewer_inst_list=[],[]\n",
    "    for j in range(len(co_inst_df)):#\n",
    "        inst_list_temp=[]\n",
    "        reviewer_list2.append(co_inst_df['reviewer_name'][j])#\n",
    "        reviewer_inst_list.append(co_inst_df['reviewer_institution'][j])#\n",
    "\n",
    "    inst_rel_df = pd.DataFrame(\n",
    "        columns=[i for i in reviewer_list2],#\n",
    "        index=[j for j in reviewee_list])#\n",
    "\n",
    "    for i in range(len(reviewee_list2)):\n",
    "        for j in range(len(reviewer_inst_list)):\n",
    "            if (reviewee_list2[i] == reviewer_inst_list[j]) : inst_rel_df.iloc[i, j] = 1\n",
    "            else : inst_rel_df.iloc[i, j] = 0\n",
    "                \n",
    "    #-----------------\n",
    "    \n",
    "#     display(inst_rel_df.iloc[:,[750,751,752,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,1,2,3,4,5,6,7,8,9,10]])\n",
    "    \n",
    "    #-----------------\n",
    "    \n",
    "    inst_rel_df_series = inst_rel_df.loc[:, (inst_rel_df != 0).any(axis=0)]\n",
    "    inst_rel_df_series_list=(inst_rel_df_series.columns).tolist()\n",
    "    \n",
    "    reviewer_list2 = list(set(reviewer_list2).difference(inst_rel_df_series_list))\n",
    "    \n",
    "    reviewer_rank_list = list(set(reviewer_list1).intersection(reviewer_list2))\n",
    "\n",
    "    id_index,sim_index,count_index,title_index=[],[],[],[]\n",
    "    reviewer_rank = pd.DataFrame({'reviewer_name': reviewer_rank_list})\n",
    "    \n",
    "    for i in range(len(reviewer_rank)):\n",
    "        for j in range(len(co_author_df)):\n",
    "            if reviewer_rank.loc[i]['reviewer_name'] == co_author_df.loc[j]['reviewer_name'] :\n",
    "                id_index.append(int(co_author_df.iloc[j]['reviewer_orcid']))\n",
    "                sim_index.append(co_author_df.iloc[j]['sim'])\n",
    "                title_index.append(co_author_df.iloc[j]['reviewer_title'])\n",
    "                break\n",
    "            if reviewer_rank.loc[i]['reviewer_name'] == co_inst_df.loc[j]['reviewer_name'] :\n",
    "                count_index.append(co_inst_df.iloc[j]['count'])\n",
    "    \n",
    "    aaa=[]\n",
    "    for i in range(len(reviewer_rank)):\n",
    "        aaa.append(0)\n",
    "    \n",
    "    reviewer_rank['reviewer_orcid']=id_index\n",
    "    reviewer_rank['title']=title_index\n",
    "    reviewer_rank['sim']=sim_index\n",
    "    reviewer_rank['count']=aaa\n",
    "    \n",
    "    reviewer_rank2 = reviewer_rank.sort_values(by=['sim'], axis=0, ascending=False)\n",
    "                \n",
    "    #return type : pandas.dataframe\n",
    "    return reviewer_rank2\n",
    "\n",
    "def save_csv(output_path,extractive_keyword_result,professionalism_result,reviewee_index,top_limit):\n",
    "    \n",
    "    path,ee_num,top=output_path,reviewee_index,top_limit\n",
    "    reviewee,reviewer_rank_name=extractive_keyword_result,professionalism_result\n",
    "    \n",
    "    export_data=[]\n",
    "    for i in range((top*2)):\n",
    "        #reviewee\n",
    "        temp=[]\n",
    "        temp.append(reviewee.iloc[(1//top*2)+ee_num]['submitter_title'])\n",
    "        temp.append(reviewee.iloc[(1//top*2)+ee_num]['date'])\n",
    "        temp.append(reviewee.iloc[(1//top*2)+ee_num]['submitter_name'])\n",
    "        #reviewer_rank_name\n",
    "        temp.append(reviewer_rank_name.iloc[i]['reviewer_name'])\n",
    "        temp.append(reviewer_rank_name.iloc[i]['reviewer_orcid'])\n",
    "        temp.append(reviewer_rank_name.iloc[i]['title'])\n",
    "        temp.append(reviewer_rank_name.iloc[i]['sim'])\n",
    "        temp.append(reviewer_rank_name.iloc[i]['count'])\n",
    "        #export_data\n",
    "        export_data.append(temp)\n",
    "        \n",
    "    try :\n",
    "        export_csv = pd.read_csv(path,index_col=0)\n",
    "    except FileNotFoundError :\n",
    "        export_csv = pd.DataFrame([],columns=['submitter_title','date','submitter_name','reviewer_name','reviewer_orcid','title','sim','count'])\n",
    "    \n",
    "    for i in range(len(export_data)):\n",
    "        export_csv.loc[len(export_csv)] = export_data[i]\n",
    "    \n",
    "    export_csv2 = export_csv.sort_values(by=['sim'], axis=0, ascending=False)\n",
    "    \n",
    "    export_csv2.to_csv(path)\n",
    "    \n",
    "def equl_distribution(input_csv_path, output_csv_path):\n",
    "    \n",
    "    #read csv\n",
    "    export_csv2 = pd.read_csv(input_csv_path,index_col=0)\n",
    "    \n",
    "    class Paper:\n",
    "        \n",
    "        def __init__(self, title, date, submitter, reviwer_name, reviwer_orcid, title2, sim, count):\n",
    "            self.title = title\n",
    "            self.date = date\n",
    "            self.submitter = submitter\n",
    "            self.reviwer_name = reviwer_name\n",
    "            self.reviwer_orcid = reviwer_orcid\n",
    "            self.reviwer_title = title2\n",
    "            self.sim = sim\n",
    "            self.count = count\n",
    "\n",
    "        def __repr__(self):\n",
    "            return repr((self.title, self.date, self.submitter, self.reviwer_name, self.reviwer_orcid, self.reviwer_title, self.sim, self.count))\n",
    "\n",
    "    papers,objs=[export_csv2.iloc[i].tolist() for i in range(len(export_csv2))],[]\n",
    "\n",
    "    for paper in papers:\n",
    "        objs.append(Paper(*paper))\n",
    "    \n",
    "    o = (multisort(list(objs), (('date', False), ('sim', True))))\n",
    "    \n",
    "    final_list=[]\n",
    "    for i in range(0,len(export_csv2),6) :\n",
    "        temp_list=[]\n",
    "        for t in range(6):\n",
    "            if len(temp_list) == 3:break\n",
    "            else :\n",
    "                temp = i + t\n",
    "                if (o[temp].count) < 3 :\n",
    "                    o[temp].count += 1\n",
    "                    for j in range(0+temp, len(export_csv2)) :\n",
    "                        if (o[temp].reviwer_name == o[j].reviwer_name) :\n",
    "                            o[j].count += 1\n",
    "                    o[temp].count -= 1\n",
    "                    class_1=(str(o[temp]))[1:-1]\n",
    "                    class_2=class_1.replace('\\'','')\n",
    "                    class_3=class_2.split(', ')\n",
    "                    temp_list.append(class_3)\n",
    "        final_list.extend(temp_list)\n",
    "        \n",
    "    final=pd.DataFrame(final_list,columns=['submitter_title','date','submitter_name','reviewer_name','reviewer_orcid','title','sim','count'])\n",
    "    final.to_csv(output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[extractive_keyword | 1.23829]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿date</th>\n",
       "      <th>submitter_orcid</th>\n",
       "      <th>submitter_name</th>\n",
       "      <th>submitter_institution</th>\n",
       "      <th>submitter_email</th>\n",
       "      <th>submitter_title_doi</th>\n",
       "      <th>submitter_title</th>\n",
       "      <th>submitter_intro</th>\n",
       "      <th>submitter_author1_name</th>\n",
       "      <th>submitter_author1_institution</th>\n",
       "      <th>...</th>\n",
       "      <th>submitter_author8_name</th>\n",
       "      <th>submitter_author8_institution</th>\n",
       "      <th>submitter_author8_email</th>\n",
       "      <th>submitter_author9_name</th>\n",
       "      <th>submitter_author9_institution</th>\n",
       "      <th>submitter_author9_email</th>\n",
       "      <th>submitter_author10_name</th>\n",
       "      <th>submitter_author10_institution</th>\n",
       "      <th>submitter_author10_email</th>\n",
       "      <th>submitter_attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200101</td>\n",
       "      <td>326</td>\n",
       "      <td>Lu Qin</td>\n",
       "      <td>The Chinese University of Hong Kong, Hong Kong...</td>\n",
       "      <td>lqin@se.cuhk.edu.hk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diversifying Top-K Results</td>\n",
       "      <td>ABSTRACT This paper proposes a general framewo...</td>\n",
       "      <td>Lu Qin</td>\n",
       "      <td>The Chinese University of Hong Kong, Hong Kong...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>distance similarities match sequences subseque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200102</td>\n",
       "      <td>897</td>\n",
       "      <td>Haohan Zhu</td>\n",
       "      <td>Department of Computer Science Boston University</td>\n",
       "      <td>zhu@cs.bu.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Generic Framework for Efficient and Effectiv...</td>\n",
       "      <td>ABSTRACT Top-k query processing finds a list o...</td>\n",
       "      <td>Haohan Zhu</td>\n",
       "      <td>Department of Computer Science Boston University</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>result algorithms searches problems solution b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200103</td>\n",
       "      <td>1387</td>\n",
       "      <td>Stefan Aulbach</td>\n",
       "      <td>Technische UniversitÃ¤t MÃ¼nchen, Germany</td>\n",
       "      <td>stefan.aulbach@in.tum.de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Comparison of Flexible Schemas for Software ...</td>\n",
       "      <td>ABSTRACT A multi-tenant database system for So...</td>\n",
       "      <td>Stefan Aulbach</td>\n",
       "      <td>Technische UniversitÃ¤t MÃ¼nchen, Germany</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>table column mappings tenants performing queri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200104</td>\n",
       "      <td>1126</td>\n",
       "      <td>Orestis Polychroniou</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>orestis@cs.columbia.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Comprehensive Study of Main-Memory Partition...</td>\n",
       "      <td>ABSTRACT Analytical database systems can achie...</td>\n",
       "      <td>Orestis Polychroniou</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partitions cached numa sorted memory tuples al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200105</td>\n",
       "      <td>1388</td>\n",
       "      <td>Yang Cao</td>\n",
       "      <td>RCBD and SKLSDE Lab, Beihang University</td>\n",
       "      <td>yang.cao@ed.ac.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Making Pattern Queries Bounded in Big Graphs</td>\n",
       "      <td>Abstract  It is cost-prohibitive to find match...</td>\n",
       "      <td>Yang Cao</td>\n",
       "      <td>RCBD and SKLSDE Lab, Beihang University</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>querying graphs constraint accessed node bound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20200106</td>\n",
       "      <td>1389</td>\n",
       "      <td>Abdeltawab M. Hendawi</td>\n",
       "      <td>Department of Computer Science and Engineering...</td>\n",
       "      <td>hendawi@cs.umn.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Predictive Tree: An Efficient Index for Predic...</td>\n",
       "      <td>Abstract Predictive queries on moving objects ...</td>\n",
       "      <td>Abdeltawab M. Hendawi</td>\n",
       "      <td>Department of Computer Science and Engineering...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>predictions node querying trees times object l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20200107</td>\n",
       "      <td>1390</td>\n",
       "      <td>Michael Mattig</td>\n",
       "      <td>Department of Mathematics and Computer Science...</td>\n",
       "      <td>mattig@mathematik.uni-marburg.de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kernel-Based Cardinality Estimation on Metric ...</td>\n",
       "      <td>ABSTRACT The efficient management of metric da...</td>\n",
       "      <td>Michael Mattig</td>\n",
       "      <td>Department of Mathematics and Computer Science...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>query metric data distances estimates spaces k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20200108</td>\n",
       "      <td>1391</td>\n",
       "      <td>Michael Vollmer</td>\n",
       "      <td>Karlsruhe Institute of Technology (KIT) Karlsr...</td>\n",
       "      <td>michael.vollmer@kit.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iterative Estimation of Mutual Information wit...</td>\n",
       "      <td>ABSTRACT Mutual Information (MI) is an establi...</td>\n",
       "      <td>Michael Vollmer</td>\n",
       "      <td>Karlsruhe Institute of Technology (KIT) Karlsr...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>estimators time iterate data imie results comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20200109</td>\n",
       "      <td>1393</td>\n",
       "      <td>Chris Mayfield</td>\n",
       "      <td>Purdue University West Lafayette, Indiana, USA</td>\n",
       "      <td>cmayfiel@cs.purdue.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERACER: A Database Approach for Statistical In...</td>\n",
       "      <td>ERACER: A Database Approach for Statistical In...</td>\n",
       "      <td>Chris Mayfield</td>\n",
       "      <td>Purdue University West Lafayette, Indiana, USA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data values databases statistical inferences c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20200110</td>\n",
       "      <td>1394</td>\n",
       "      <td>Alexander Hall</td>\n",
       "      <td>Google, Inc.</td>\n",
       "      <td>alexhall@google.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Processing a Trillion Cells per Mouse Click</td>\n",
       "      <td>Processing a Trillion Cells per Mouse Click, P...</td>\n",
       "      <td>Alexander Hall</td>\n",
       "      <td>Google, Inc.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data stored query columns large interacting da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ï»¿date  submitter_orcid         submitter_name  \\\n",
       "0  20200101              326                 Lu Qin   \n",
       "1  20200102              897             Haohan Zhu   \n",
       "2  20200103             1387         Stefan Aulbach   \n",
       "3  20200104             1126   Orestis Polychroniou   \n",
       "4  20200105             1388               Yang Cao   \n",
       "5  20200106             1389  Abdeltawab M. Hendawi   \n",
       "6  20200107             1390         Michael Mattig   \n",
       "7  20200108             1391        Michael Vollmer   \n",
       "8  20200109             1393         Chris Mayfield   \n",
       "9  20200110             1394         Alexander Hall   \n",
       "\n",
       "                               submitter_institution  \\\n",
       "0  The Chinese University of Hong Kong, Hong Kong...   \n",
       "1   Department of Computer Science Boston University   \n",
       "2          Technische UniversitÃ¤t MÃ¼nchen, Germany   \n",
       "3                                Columbia University   \n",
       "4            RCBD and SKLSDE Lab, Beihang University   \n",
       "5  Department of Computer Science and Engineering...   \n",
       "6  Department of Mathematics and Computer Science...   \n",
       "7  Karlsruhe Institute of Technology (KIT) Karlsr...   \n",
       "8     Purdue University West Lafayette, Indiana, USA   \n",
       "9                                       Google, Inc.   \n",
       "\n",
       "                    submitter_email  submitter_title_doi  \\\n",
       "0               lqin@se.cuhk.edu.hk                  NaN   \n",
       "1                     zhu@cs.bu.edu                  NaN   \n",
       "2          stefan.aulbach@in.tum.de                  NaN   \n",
       "3           orestis@cs.columbia.edu                  NaN   \n",
       "4                 yang.cao@ed.ac.uk                  NaN   \n",
       "5                hendawi@cs.umn.edu                  NaN   \n",
       "6  mattig@mathematik.uni-marburg.de                  NaN   \n",
       "7           michael.vollmer@kit.edu                  NaN   \n",
       "8            cmayfiel@cs.purdue.edu                  NaN   \n",
       "9               alexhall@google.com                  NaN   \n",
       "\n",
       "                                     submitter_title  \\\n",
       "0                         Diversifying Top-K Results   \n",
       "1  A Generic Framework for Efficient and Effectiv...   \n",
       "2  A Comparison of Flexible Schemas for Software ...   \n",
       "3  A Comprehensive Study of Main-Memory Partition...   \n",
       "4       Making Pattern Queries Bounded in Big Graphs   \n",
       "5  Predictive Tree: An Efficient Index for Predic...   \n",
       "6  Kernel-Based Cardinality Estimation on Metric ...   \n",
       "7  Iterative Estimation of Mutual Information wit...   \n",
       "8  ERACER: A Database Approach for Statistical In...   \n",
       "9        Processing a Trillion Cells per Mouse Click   \n",
       "\n",
       "                                     submitter_intro submitter_author1_name  \\\n",
       "0  ABSTRACT This paper proposes a general framewo...                 Lu Qin   \n",
       "1  ABSTRACT Top-k query processing finds a list o...             Haohan Zhu   \n",
       "2  ABSTRACT A multi-tenant database system for So...         Stefan Aulbach   \n",
       "3  ABSTRACT Analytical database systems can achie...   Orestis Polychroniou   \n",
       "4  Abstract  It is cost-prohibitive to find match...               Yang Cao   \n",
       "5  Abstract Predictive queries on moving objects ...  Abdeltawab M. Hendawi   \n",
       "6  ABSTRACT The efficient management of metric da...         Michael Mattig   \n",
       "7  ABSTRACT Mutual Information (MI) is an establi...        Michael Vollmer   \n",
       "8  ERACER: A Database Approach for Statistical In...         Chris Mayfield   \n",
       "9  Processing a Trillion Cells per Mouse Click, P...         Alexander Hall   \n",
       "\n",
       "                       submitter_author1_institution  ...  \\\n",
       "0  The Chinese University of Hong Kong, Hong Kong...  ...   \n",
       "1   Department of Computer Science Boston University  ...   \n",
       "2          Technische UniversitÃ¤t MÃ¼nchen, Germany  ...   \n",
       "3                                Columbia University  ...   \n",
       "4            RCBD and SKLSDE Lab, Beihang University  ...   \n",
       "5  Department of Computer Science and Engineering...  ...   \n",
       "6  Department of Mathematics and Computer Science...  ...   \n",
       "7  Karlsruhe Institute of Technology (KIT) Karlsr...  ...   \n",
       "8     Purdue University West Lafayette, Indiana, USA  ...   \n",
       "9                                       Google, Inc.  ...   \n",
       "\n",
       "  submitter_author8_name submitter_author8_institution  \\\n",
       "0                    NaN                           NaN   \n",
       "1                    NaN                           NaN   \n",
       "2                    NaN                           NaN   \n",
       "3                    NaN                           NaN   \n",
       "4                    NaN                           NaN   \n",
       "5                    NaN                           NaN   \n",
       "6                    NaN                           NaN   \n",
       "7                    NaN                           NaN   \n",
       "8                    NaN                           NaN   \n",
       "9                    NaN                           NaN   \n",
       "\n",
       "  submitter_author8_email submitter_author9_name  \\\n",
       "0                     NaN                    NaN   \n",
       "1                     NaN                    NaN   \n",
       "2                     NaN                    NaN   \n",
       "3                     NaN                    NaN   \n",
       "4                     NaN                    NaN   \n",
       "5                     NaN                    NaN   \n",
       "6                     NaN                    NaN   \n",
       "7                     NaN                    NaN   \n",
       "8                     NaN                    NaN   \n",
       "9                     NaN                    NaN   \n",
       "\n",
       "  submitter_author9_institution submitter_author9_email  \\\n",
       "0                           NaN                     NaN   \n",
       "1                           NaN                     NaN   \n",
       "2                           NaN                     NaN   \n",
       "3                           NaN                     NaN   \n",
       "4                           NaN                     NaN   \n",
       "5                           NaN                     NaN   \n",
       "6                           NaN                     NaN   \n",
       "7                           NaN                     NaN   \n",
       "8                           NaN                     NaN   \n",
       "9                           NaN                     NaN   \n",
       "\n",
       "  submitter_author10_name submitter_author10_institution  \\\n",
       "0                     NaN                            NaN   \n",
       "1                     NaN                            NaN   \n",
       "2                     NaN                            NaN   \n",
       "3                     NaN                            NaN   \n",
       "4                     NaN                            NaN   \n",
       "5                     NaN                            NaN   \n",
       "6                     NaN                            NaN   \n",
       "7                     NaN                            NaN   \n",
       "8                     NaN                            NaN   \n",
       "9                     NaN                            NaN   \n",
       "\n",
       "  submitter_author10_email                                submitter_attribute  \n",
       "0                      NaN  distance similarities match sequences subseque...  \n",
       "1                      NaN  result algorithms searches problems solution b...  \n",
       "2                      NaN  table column mappings tenants performing queri...  \n",
       "3                      NaN  partitions cached numa sorted memory tuples al...  \n",
       "4                      NaN  querying graphs constraint accessed node bound...  \n",
       "5                      NaN  predictions node querying trees times object l...  \n",
       "6                      NaN  query metric data distances estimates spaces k...  \n",
       "7                      NaN  estimators time iterate data imie results comp...  \n",
       "8                      NaN  data values databases statistical inferences c...  \n",
       "9                      NaN  data stored query columns large interacting da...  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------1---------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "reviewee=extractive_keyword(path='../reviewee/submitter_10_k.csv',\n",
    "                            database_update_path='../reviewee/update/sybmitter_update_100.csv',\n",
    "                            extract_word_num=30)\n",
    "#return type : pandas.dataframe\n",
    "print('[extractive_keyword | {time:2.5f}]'.format(time=time.time() - start_time))\n",
    "display(reviewee)\n",
    "print('---------------1---------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_orcid</th>\n",
       "      <th>reviewer_title</th>\n",
       "      <th>reviewer_paper_feature</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Diversifying Top-K Results</td>\n",
       "      <td>distance similarities match sequences subseque...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2579</td>\n",
       "      <td>Efficient Subgraph Matching on Billion Node Gr...</td>\n",
       "      <td>graph data indexed queried joining result subg...</td>\n",
       "      <td>0.155556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>1106</td>\n",
       "      <td>Skip-and-Prune: Cosine-based Top-K Query Proce...</td>\n",
       "      <td>based queries keywords vectors contexts data s...</td>\n",
       "      <td>0.155556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>381</td>\n",
       "      <td>Parallel Duplicate Detection in Adverse Drug R...</td>\n",
       "      <td>reported duplicated data fields recorded metho...</td>\n",
       "      <td>0.155556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>35</td>\n",
       "      <td>Effective Data Co-Reduction for Multimedia Sim...</td>\n",
       "      <td>data dimensionalities multimedia dcr distance ...</td>\n",
       "      <td>0.131054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>888</td>\n",
       "      <td>Challenging the Long Tail Recommendation</td>\n",
       "      <td>recommenders users tail items product niche po...</td>\n",
       "      <td>0.025141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1898</td>\n",
       "      <td>Finding Contrast Patterns for Mixed Streaming ...</td>\n",
       "      <td>data algorithms itemsets differ pattern contra...</td>\n",
       "      <td>0.025141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>288</td>\n",
       "      <td>Sensitivity Analysis and Explanations for Robu...</td>\n",
       "      <td>probabilities querying sensitive input tuples ...</td>\n",
       "      <td>0.025141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2498</td>\n",
       "      <td>Parallel Subgraph Listing in a Large-Scale Graph</td>\n",
       "      <td>graphs subgraphs parallel result perform listi...</td>\n",
       "      <td>0.025141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2044</td>\n",
       "      <td>Group Recommendation with Temporal Affinities</td>\n",
       "      <td>groups affin users times preferred recommend d...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>845 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    reviewer_orcid                                     reviewer_title  \\\n",
       "0                0                         Diversifying Top-K Results   \n",
       "334           2579  Efficient Subgraph Matching on Billion Node Gr...   \n",
       "790           1106  Skip-and-Prune: Cosine-based Top-K Query Proce...   \n",
       "842            381  Parallel Duplicate Detection in Adverse Drug R...   \n",
       "569             35  Effective Data Co-Reduction for Multimedia Sim...   \n",
       "..             ...                                                ...   \n",
       "512            888           Challenging the Long Tail Recommendation   \n",
       "83            1898  Finding Contrast Patterns for Mixed Streaming ...   \n",
       "371            288  Sensitivity Analysis and Explanations for Robu...   \n",
       "514           2498   Parallel Subgraph Listing in a Large-Scale Graph   \n",
       "142           2044      Group Recommendation with Temporal Affinities   \n",
       "\n",
       "                                reviewer_paper_feature       sim  \n",
       "0    distance similarities match sequences subseque...  1.000000  \n",
       "334  graph data indexed queried joining result subg...  0.155556  \n",
       "790  based queries keywords vectors contexts data s...  0.155556  \n",
       "842  reported duplicated data fields recorded metho...  0.155556  \n",
       "569  data dimensionalities multimedia dcr distance ...  0.131054  \n",
       "..                                                 ...       ...  \n",
       "512  recommenders users tail items product niche po...  0.025141  \n",
       "83   data algorithms itemsets differ pattern contra...  0.025141  \n",
       "371  probabilities querying sensitive input tuples ...  0.025141  \n",
       "514  graphs subgraphs parallel result perform listi...  0.025141  \n",
       "142  groups affin users times preferred recommend d...  0.000000  \n",
       "\n",
       "[845 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>data</th>\n",
       "      <th>database</th>\n",
       "      <th>distance</th>\n",
       "      <th>graph</th>\n",
       "      <th>index</th>\n",
       "      <th>process</th>\n",
       "      <th>queries</th>\n",
       "      <th>similar</th>\n",
       "      <th>time</th>\n",
       "      <th>...</th>\n",
       "      <th>abstraction</th>\n",
       "      <th>abstractions</th>\n",
       "      <th>abstracts</th>\n",
       "      <th>accelerating</th>\n",
       "      <th>accepted</th>\n",
       "      <th>access</th>\n",
       "      <th>accessed</th>\n",
       "      <th>accesses</th>\n",
       "      <th>accessible</th>\n",
       "      <th>accessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Manuscript 0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527808</td>\n",
       "      <td>1.38275</td>\n",
       "      <td>2.788093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.011949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.45107</td>\n",
       "      <td>2.273429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263904</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.653363</td>\n",
       "      <td>2.011949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263904</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.487063</td>\n",
       "      <td>1.45107</td>\n",
       "      <td>2.273429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527808</td>\n",
       "      <td>1.38275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527808</td>\n",
       "      <td>1.38275</td>\n",
       "      <td>2.788093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.273429</td>\n",
       "      <td>1.292599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 840</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 841</th>\n",
       "      <td>1.090362</td>\n",
       "      <td>0.263904</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.292599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 842</th>\n",
       "      <td>1.090362</td>\n",
       "      <td>0.263904</td>\n",
       "      <td>1.38275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 843</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.653363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.487063</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 844</th>\n",
       "      <td>1.090362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.292599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>845 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                algorithm      data  database  distance     graph     index  \\\n",
       "Manuscript 0     0.000000  0.527808   1.38275  2.788093  0.000000  2.011949   \n",
       "Manuscript 1     0.000000  0.263904   0.00000  0.000000  3.653363  2.011949   \n",
       "Manuscript 2     0.000000  0.263904   0.00000  0.000000  0.000000  0.000000   \n",
       "Manuscript 3     0.000000  0.527808   1.38275  0.000000  0.000000  0.000000   \n",
       "Manuscript 4     0.000000  0.527808   1.38275  2.788093  0.000000  0.000000   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "Manuscript 840   0.000000  0.000000   0.00000  0.000000  0.000000  0.000000   \n",
       "Manuscript 841   1.090362  0.263904   0.00000  0.000000  0.000000  0.000000   \n",
       "Manuscript 842   1.090362  0.263904   1.38275  0.000000  0.000000  0.000000   \n",
       "Manuscript 843   0.000000  0.000000   0.00000  0.000000  3.653363  0.000000   \n",
       "Manuscript 844   1.090362  0.000000   0.00000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                 process  queries   similar      time  ...  abstraction  \\\n",
       "Manuscript 0    0.000000  1.45107  2.273429  0.000000  ...          0.0   \n",
       "Manuscript 1    0.000000  0.00000  0.000000  0.000000  ...          0.0   \n",
       "Manuscript 2    1.487063  1.45107  2.273429  0.000000  ...          0.0   \n",
       "Manuscript 3    0.000000  0.00000  0.000000  0.000000  ...          0.0   \n",
       "Manuscript 4    0.000000  0.00000  2.273429  1.292599  ...          0.0   \n",
       "...                  ...      ...       ...       ...  ...          ...   \n",
       "Manuscript 840  0.000000  0.00000  0.000000  0.000000  ...          0.0   \n",
       "Manuscript 841  0.000000  0.00000  0.000000  1.292599  ...          0.0   \n",
       "Manuscript 842  0.000000  0.00000  0.000000  0.000000  ...          0.0   \n",
       "Manuscript 843  1.487063  0.00000  0.000000  0.000000  ...          0.0   \n",
       "Manuscript 844  0.000000  0.00000  0.000000  1.292599  ...          0.0   \n",
       "\n",
       "                abstractions  abstracts  accelerating  accepted  access  \\\n",
       "Manuscript 0             0.0        0.0           0.0       0.0     0.0   \n",
       "Manuscript 1             0.0        0.0           0.0       0.0     0.0   \n",
       "Manuscript 2             0.0        0.0           0.0       0.0     0.0   \n",
       "Manuscript 3             0.0        0.0           0.0       0.0     0.0   \n",
       "Manuscript 4             0.0        0.0           0.0       0.0     0.0   \n",
       "...                      ...        ...           ...       ...     ...   \n",
       "Manuscript 840           0.0        0.0           0.0       0.0     0.0   \n",
       "Manuscript 841           0.0        0.0           0.0       0.0     0.0   \n",
       "Manuscript 842           0.0        0.0           0.0       0.0     0.0   \n",
       "Manuscript 843           0.0        0.0           0.0       0.0     0.0   \n",
       "Manuscript 844           0.0        0.0           0.0       0.0     0.0   \n",
       "\n",
       "                accessed  accesses  accessible  accessing  \n",
       "Manuscript 0         0.0       0.0         0.0        0.0  \n",
       "Manuscript 1         0.0       0.0         0.0        0.0  \n",
       "Manuscript 2         0.0       0.0         0.0        0.0  \n",
       "Manuscript 3         0.0       0.0         0.0        0.0  \n",
       "Manuscript 4         0.0       0.0         0.0        0.0  \n",
       "...                  ...       ...         ...        ...  \n",
       "Manuscript 840       0.0       0.0         0.0        0.0  \n",
       "Manuscript 841       0.0       0.0         0.0        0.0  \n",
       "Manuscript 842       0.0       0.0         0.0        0.0  \n",
       "Manuscript 843       0.0       0.0         0.0        0.0  \n",
       "Manuscript 844       0.0       0.0         0.0        0.0  \n",
       "\n",
       "[845 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manuscript 0</th>\n",
       "      <th>Manuscript 1</th>\n",
       "      <th>Manuscript 2</th>\n",
       "      <th>Manuscript 3</th>\n",
       "      <th>Manuscript 4</th>\n",
       "      <th>Manuscript 5</th>\n",
       "      <th>Manuscript 6</th>\n",
       "      <th>Manuscript 7</th>\n",
       "      <th>Manuscript 8</th>\n",
       "      <th>Manuscript 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Manuscript 835</th>\n",
       "      <th>Manuscript 836</th>\n",
       "      <th>Manuscript 837</th>\n",
       "      <th>Manuscript 838</th>\n",
       "      <th>Manuscript 839</th>\n",
       "      <th>Manuscript 840</th>\n",
       "      <th>Manuscript 841</th>\n",
       "      <th>Manuscript 842</th>\n",
       "      <th>Manuscript 843</th>\n",
       "      <th>Manuscript 844</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Manuscript 0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.739043e+01</td>\n",
       "      <td>28.371600</td>\n",
       "      <td>31.131022</td>\n",
       "      <td>30.649123</td>\n",
       "      <td>31.084986</td>\n",
       "      <td>29.875811</td>\n",
       "      <td>29.606264</td>\n",
       "      <td>30.018720</td>\n",
       "      <td>26.195887</td>\n",
       "      <td>...</td>\n",
       "      <td>29.088150</td>\n",
       "      <td>30.060332</td>\n",
       "      <td>34.723257</td>\n",
       "      <td>32.613515</td>\n",
       "      <td>32.260986</td>\n",
       "      <td>34.022679</td>\n",
       "      <td>30.895223</td>\n",
       "      <td>3.026952e+01</td>\n",
       "      <td>31.430739</td>\n",
       "      <td>32.773349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 1</th>\n",
       "      <td>27.390426</td>\n",
       "      <td>4.768372e-07</td>\n",
       "      <td>28.546876</td>\n",
       "      <td>29.508148</td>\n",
       "      <td>29.608212</td>\n",
       "      <td>28.507454</td>\n",
       "      <td>25.821632</td>\n",
       "      <td>27.796307</td>\n",
       "      <td>28.686423</td>\n",
       "      <td>27.589892</td>\n",
       "      <td>...</td>\n",
       "      <td>26.647278</td>\n",
       "      <td>26.638247</td>\n",
       "      <td>32.334228</td>\n",
       "      <td>29.816074</td>\n",
       "      <td>30.261769</td>\n",
       "      <td>32.075576</td>\n",
       "      <td>29.194411</td>\n",
       "      <td>2.799859e+01</td>\n",
       "      <td>26.906891</td>\n",
       "      <td>31.265480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 2</th>\n",
       "      <td>28.371600</td>\n",
       "      <td>2.854688e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.301920</td>\n",
       "      <td>30.493540</td>\n",
       "      <td>31.244990</td>\n",
       "      <td>29.579406</td>\n",
       "      <td>29.139824</td>\n",
       "      <td>29.667732</td>\n",
       "      <td>29.424980</td>\n",
       "      <td>...</td>\n",
       "      <td>28.460049</td>\n",
       "      <td>29.631602</td>\n",
       "      <td>32.571154</td>\n",
       "      <td>32.042691</td>\n",
       "      <td>31.347954</td>\n",
       "      <td>32.494837</td>\n",
       "      <td>29.646717</td>\n",
       "      <td>2.928851e+01</td>\n",
       "      <td>30.700726</td>\n",
       "      <td>31.702934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 3</th>\n",
       "      <td>31.131022</td>\n",
       "      <td>2.950815e+01</td>\n",
       "      <td>30.301920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.677802</td>\n",
       "      <td>32.315906</td>\n",
       "      <td>31.078506</td>\n",
       "      <td>29.410607</td>\n",
       "      <td>30.198413</td>\n",
       "      <td>29.992146</td>\n",
       "      <td>...</td>\n",
       "      <td>29.663838</td>\n",
       "      <td>30.517212</td>\n",
       "      <td>34.337017</td>\n",
       "      <td>32.586972</td>\n",
       "      <td>31.610693</td>\n",
       "      <td>34.040853</td>\n",
       "      <td>30.951059</td>\n",
       "      <td>2.989724e+01</td>\n",
       "      <td>31.541690</td>\n",
       "      <td>32.751674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 4</th>\n",
       "      <td>30.649123</td>\n",
       "      <td>2.960821e+01</td>\n",
       "      <td>30.493540</td>\n",
       "      <td>31.677802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.085562</td>\n",
       "      <td>30.876660</td>\n",
       "      <td>30.154951</td>\n",
       "      <td>31.547206</td>\n",
       "      <td>30.589232</td>\n",
       "      <td>...</td>\n",
       "      <td>29.814700</td>\n",
       "      <td>31.131315</td>\n",
       "      <td>35.268271</td>\n",
       "      <td>33.312835</td>\n",
       "      <td>32.584539</td>\n",
       "      <td>34.793242</td>\n",
       "      <td>30.890161</td>\n",
       "      <td>3.072936e+01</td>\n",
       "      <td>32.280813</td>\n",
       "      <td>33.591129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 840</th>\n",
       "      <td>34.022679</td>\n",
       "      <td>3.207558e+01</td>\n",
       "      <td>32.494837</td>\n",
       "      <td>34.040853</td>\n",
       "      <td>34.793242</td>\n",
       "      <td>34.574697</td>\n",
       "      <td>33.359701</td>\n",
       "      <td>32.850231</td>\n",
       "      <td>33.042686</td>\n",
       "      <td>32.426947</td>\n",
       "      <td>...</td>\n",
       "      <td>32.250904</td>\n",
       "      <td>32.780532</td>\n",
       "      <td>35.799737</td>\n",
       "      <td>34.980251</td>\n",
       "      <td>34.656481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.083551</td>\n",
       "      <td>3.232488e+01</td>\n",
       "      <td>34.186818</td>\n",
       "      <td>34.253887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 841</th>\n",
       "      <td>30.895223</td>\n",
       "      <td>2.919441e+01</td>\n",
       "      <td>29.646717</td>\n",
       "      <td>30.951059</td>\n",
       "      <td>30.890161</td>\n",
       "      <td>31.736707</td>\n",
       "      <td>30.017994</td>\n",
       "      <td>29.694253</td>\n",
       "      <td>30.768105</td>\n",
       "      <td>29.304145</td>\n",
       "      <td>...</td>\n",
       "      <td>29.049218</td>\n",
       "      <td>30.186881</td>\n",
       "      <td>33.427382</td>\n",
       "      <td>32.675935</td>\n",
       "      <td>31.038689</td>\n",
       "      <td>33.083551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.920891e+01</td>\n",
       "      <td>31.065636</td>\n",
       "      <td>31.551464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 842</th>\n",
       "      <td>30.269521</td>\n",
       "      <td>2.799859e+01</td>\n",
       "      <td>29.288506</td>\n",
       "      <td>29.897240</td>\n",
       "      <td>30.729360</td>\n",
       "      <td>30.951406</td>\n",
       "      <td>27.479690</td>\n",
       "      <td>28.325220</td>\n",
       "      <td>28.825191</td>\n",
       "      <td>28.556635</td>\n",
       "      <td>...</td>\n",
       "      <td>25.936595</td>\n",
       "      <td>28.824329</td>\n",
       "      <td>33.384567</td>\n",
       "      <td>31.113439</td>\n",
       "      <td>30.528439</td>\n",
       "      <td>32.324876</td>\n",
       "      <td>29.208908</td>\n",
       "      <td>3.371748e-07</td>\n",
       "      <td>29.898645</td>\n",
       "      <td>30.871188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 843</th>\n",
       "      <td>31.430739</td>\n",
       "      <td>2.690689e+01</td>\n",
       "      <td>30.700726</td>\n",
       "      <td>31.541690</td>\n",
       "      <td>32.280813</td>\n",
       "      <td>31.534648</td>\n",
       "      <td>27.806742</td>\n",
       "      <td>29.445469</td>\n",
       "      <td>30.983365</td>\n",
       "      <td>29.974579</td>\n",
       "      <td>...</td>\n",
       "      <td>29.132235</td>\n",
       "      <td>29.317654</td>\n",
       "      <td>34.752774</td>\n",
       "      <td>32.163180</td>\n",
       "      <td>32.183481</td>\n",
       "      <td>34.186818</td>\n",
       "      <td>31.065636</td>\n",
       "      <td>2.989865e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.658564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript 844</th>\n",
       "      <td>32.773349</td>\n",
       "      <td>3.126548e+01</td>\n",
       "      <td>31.702934</td>\n",
       "      <td>32.751674</td>\n",
       "      <td>33.591129</td>\n",
       "      <td>33.724291</td>\n",
       "      <td>32.247128</td>\n",
       "      <td>31.488450</td>\n",
       "      <td>32.404189</td>\n",
       "      <td>31.451081</td>\n",
       "      <td>...</td>\n",
       "      <td>30.548915</td>\n",
       "      <td>31.564587</td>\n",
       "      <td>34.453067</td>\n",
       "      <td>34.309866</td>\n",
       "      <td>33.325940</td>\n",
       "      <td>34.253887</td>\n",
       "      <td>31.551464</td>\n",
       "      <td>3.087119e+01</td>\n",
       "      <td>32.658564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>845 rows × 845 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Manuscript 0  Manuscript 1  Manuscript 2  Manuscript 3  \\\n",
       "Manuscript 0        0.000000  2.739043e+01     28.371600     31.131022   \n",
       "Manuscript 1       27.390426  4.768372e-07     28.546876     29.508148   \n",
       "Manuscript 2       28.371600  2.854688e+01      0.000000     30.301920   \n",
       "Manuscript 3       31.131022  2.950815e+01     30.301920      0.000000   \n",
       "Manuscript 4       30.649123  2.960821e+01     30.493540     31.677802   \n",
       "...                      ...           ...           ...           ...   \n",
       "Manuscript 840     34.022679  3.207558e+01     32.494837     34.040853   \n",
       "Manuscript 841     30.895223  2.919441e+01     29.646717     30.951059   \n",
       "Manuscript 842     30.269521  2.799859e+01     29.288506     29.897240   \n",
       "Manuscript 843     31.430739  2.690689e+01     30.700726     31.541690   \n",
       "Manuscript 844     32.773349  3.126548e+01     31.702934     32.751674   \n",
       "\n",
       "                Manuscript 4  Manuscript 5  Manuscript 6  Manuscript 7  \\\n",
       "Manuscript 0       30.649123     31.084986     29.875811     29.606264   \n",
       "Manuscript 1       29.608212     28.507454     25.821632     27.796307   \n",
       "Manuscript 2       30.493540     31.244990     29.579406     29.139824   \n",
       "Manuscript 3       31.677802     32.315906     31.078506     29.410607   \n",
       "Manuscript 4        0.000000     32.085562     30.876660     30.154951   \n",
       "...                      ...           ...           ...           ...   \n",
       "Manuscript 840     34.793242     34.574697     33.359701     32.850231   \n",
       "Manuscript 841     30.890161     31.736707     30.017994     29.694253   \n",
       "Manuscript 842     30.729360     30.951406     27.479690     28.325220   \n",
       "Manuscript 843     32.280813     31.534648     27.806742     29.445469   \n",
       "Manuscript 844     33.591129     33.724291     32.247128     31.488450   \n",
       "\n",
       "                Manuscript 8  Manuscript 9  ...  Manuscript 835  \\\n",
       "Manuscript 0       30.018720     26.195887  ...       29.088150   \n",
       "Manuscript 1       28.686423     27.589892  ...       26.647278   \n",
       "Manuscript 2       29.667732     29.424980  ...       28.460049   \n",
       "Manuscript 3       30.198413     29.992146  ...       29.663838   \n",
       "Manuscript 4       31.547206     30.589232  ...       29.814700   \n",
       "...                      ...           ...  ...             ...   \n",
       "Manuscript 840     33.042686     32.426947  ...       32.250904   \n",
       "Manuscript 841     30.768105     29.304145  ...       29.049218   \n",
       "Manuscript 842     28.825191     28.556635  ...       25.936595   \n",
       "Manuscript 843     30.983365     29.974579  ...       29.132235   \n",
       "Manuscript 844     32.404189     31.451081  ...       30.548915   \n",
       "\n",
       "                Manuscript 836  Manuscript 837  Manuscript 838  \\\n",
       "Manuscript 0         30.060332       34.723257       32.613515   \n",
       "Manuscript 1         26.638247       32.334228       29.816074   \n",
       "Manuscript 2         29.631602       32.571154       32.042691   \n",
       "Manuscript 3         30.517212       34.337017       32.586972   \n",
       "Manuscript 4         31.131315       35.268271       33.312835   \n",
       "...                        ...             ...             ...   \n",
       "Manuscript 840       32.780532       35.799737       34.980251   \n",
       "Manuscript 841       30.186881       33.427382       32.675935   \n",
       "Manuscript 842       28.824329       33.384567       31.113439   \n",
       "Manuscript 843       29.317654       34.752774       32.163180   \n",
       "Manuscript 844       31.564587       34.453067       34.309866   \n",
       "\n",
       "                Manuscript 839  Manuscript 840  Manuscript 841  \\\n",
       "Manuscript 0         32.260986       34.022679       30.895223   \n",
       "Manuscript 1         30.261769       32.075576       29.194411   \n",
       "Manuscript 2         31.347954       32.494837       29.646717   \n",
       "Manuscript 3         31.610693       34.040853       30.951059   \n",
       "Manuscript 4         32.584539       34.793242       30.890161   \n",
       "...                        ...             ...             ...   \n",
       "Manuscript 840       34.656481        0.000000       33.083551   \n",
       "Manuscript 841       31.038689       33.083551        0.000000   \n",
       "Manuscript 842       30.528439       32.324876       29.208908   \n",
       "Manuscript 843       32.183481       34.186818       31.065636   \n",
       "Manuscript 844       33.325940       34.253887       31.551464   \n",
       "\n",
       "                Manuscript 842  Manuscript 843  Manuscript 844  \n",
       "Manuscript 0      3.026952e+01       31.430739       32.773349  \n",
       "Manuscript 1      2.799859e+01       26.906891       31.265480  \n",
       "Manuscript 2      2.928851e+01       30.700726       31.702934  \n",
       "Manuscript 3      2.989724e+01       31.541690       32.751674  \n",
       "Manuscript 4      3.072936e+01       32.280813       33.591129  \n",
       "...                        ...             ...             ...  \n",
       "Manuscript 840    3.232488e+01       34.186818       34.253887  \n",
       "Manuscript 841    2.920891e+01       31.065636       31.551464  \n",
       "Manuscript 842    3.371748e-07       29.898645       30.871188  \n",
       "Manuscript 843    2.989865e+01        0.000000       32.658564  \n",
       "Manuscript 844    3.087119e+01       32.658564        0.000000  \n",
       "\n",
       "[845 rows x 845 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_orcid</th>\n",
       "      <th>reviewer_title</th>\n",
       "      <th>reviewer_paper_feature</th>\n",
       "      <th>sim</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Diversifying Top-K Results</td>\n",
       "      <td>distance similarities match sequences subseque...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>549</td>\n",
       "      <td>Efficient Record Linkage Using a Compact Hammi...</td>\n",
       "      <td>blocks data records distance spaces large vect...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>381</td>\n",
       "      <td>Parallel Duplicate Detection in Adverse Drug R...</td>\n",
       "      <td>reported duplicated data fields recorded metho...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>891</td>\n",
       "      <td>Efficient Reachability Query Evaluation in Lar...</td>\n",
       "      <td>timely queries reachable process contacting gr...</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2476</td>\n",
       "      <td>Efficient Subgraph Similarity Search on Large ...</td>\n",
       "      <td>graphs probabilistic subgraphs probabilities d...</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1200</td>\n",
       "      <td>Reconstruction Privacy: Enabling Statistical L...</td>\n",
       "      <td>privacy data records values sensitivity attrib...</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>365</td>\n",
       "      <td>GBLENDER: Towards Blending Visual Query Formul...</td>\n",
       "      <td>graphs efficiently querying user indexes visua...</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>585</td>\n",
       "      <td>InsightNotes: Summary-Based Annotation Managem...</td>\n",
       "      <td>annotating summaries queries database insightn...</td>\n",
       "      <td>0.106044</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>919</td>\n",
       "      <td>Sedna: Native XML Database Management System (...</td>\n",
       "      <td>storages data xml sedna section manager design...</td>\n",
       "      <td>0.104170</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>1478</td>\n",
       "      <td>Efficient Query Processing Using the Earth Mov...</td>\n",
       "      <td>videos data signatures database similar effici...</td>\n",
       "      <td>0.104170</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>874</td>\n",
       "      <td>Identifying User Interests within the Data Spa...</td>\n",
       "      <td>querie area database data accesses users diffe...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>288</td>\n",
       "      <td>Lineage Processing over Correlated Probabilist...</td>\n",
       "      <td>data correlation database querying tuples line...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>778</td>\n",
       "      <td>Verifying Computations with Streaming Interact...</td>\n",
       "      <td>protocol compute verifies query stream keys da...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2548</td>\n",
       "      <td>Quality and Efficiency in High Dimensional Nea...</td>\n",
       "      <td>queries lsh sections point figure value specif...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>481</td>\n",
       "      <td>Hermes: Dynamic Partitioning for Distributed S...</td>\n",
       "      <td>partitionings performs section networks social...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>324</td>\n",
       "      <td>Indexing the Earth MoverÂ¢Â® ?s Distance Using...</td>\n",
       "      <td>emds indexed distributed normals errors bounde...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>2441</td>\n",
       "      <td>A Data-adaptive and Dynamic Segmentation Index...</td>\n",
       "      <td>segmenting time method series nodes indexed sp...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>692</td>\n",
       "      <td>Compacting Transactional Data in Hybrid OLTP&amp;O...</td>\n",
       "      <td>data compress query memory transactions proces...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1399</td>\n",
       "      <td>Schema Extraction for Tabular Data on the Web</td>\n",
       "      <td>table data row relations methods contained dat...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>1099</td>\n",
       "      <td>Efficient Window Aggregation with General Stre...</td>\n",
       "      <td>aggregate windows streaming slices generalizes...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>991</td>\n",
       "      <td>Incremental Elasticity For Array Databases</td>\n",
       "      <td>data database arrays incrementally elastic ske...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reviewer_orcid                                     reviewer_title  \\\n",
       "0                0                         Diversifying Top-K Results   \n",
       "32             549  Efficient Record Linkage Using a Compact Hammi...   \n",
       "842            381  Parallel Duplicate Detection in Adverse Drug R...   \n",
       "19             891  Efficient Reachability Query Evaluation in Lar...   \n",
       "388           2476  Efficient Subgraph Similarity Search on Large ...   \n",
       "111           1200  Reconstruction Privacy: Enabling Statistical L...   \n",
       "765            365  GBLENDER: Towards Blending Visual Query Formul...   \n",
       "597            585  InsightNotes: Summary-Based Annotation Managem...   \n",
       "654            919  Sedna: Native XML Database Management System (...   \n",
       "605           1478  Efficient Query Processing Using the Earth Mov...   \n",
       "251            874  Identifying User Interests within the Data Spa...   \n",
       "808            288  Lineage Processing over Correlated Probabilist...   \n",
       "935            778  Verifying Computations with Streaming Interact...   \n",
       "184           2548  Quality and Efficiency in High Dimensional Nea...   \n",
       "817            481  Hermes: Dynamic Partitioning for Distributed S...   \n",
       "241            324  Indexing the Earth MoverÂ¢Â® ?s Distance Using...   \n",
       "880           2441  A Data-adaptive and Dynamic Segmentation Index...   \n",
       "292            692  Compacting Transactional Data in Hybrid OLTP&O...   \n",
       "160           1399      Schema Extraction for Tabular Data on the Web   \n",
       "667           1099  Efficient Window Aggregation with General Stre...   \n",
       "652            991         Incremental Elasticity For Array Databases   \n",
       "\n",
       "                                reviewer_paper_feature       sim  cluster  \n",
       "0    distance similarities match sequences subseque...  1.000000        2  \n",
       "32   blocks data records distance spaces large vect...  0.155556        2  \n",
       "842  reported duplicated data fields recorded metho...  0.155556        2  \n",
       "19   timely queries reachable process contacting gr...  0.128788        2  \n",
       "388  graphs probabilistic subgraphs probabilities d...  0.128788        2  \n",
       "111  privacy data records values sensitivity attrib...  0.128788        2  \n",
       "765  graphs efficiently querying user indexes visua...  0.128788        2  \n",
       "597  annotating summaries queries database insightn...  0.106044        2  \n",
       "654  storages data xml sedna section manager design...  0.104170        2  \n",
       "605  videos data signatures database similar effici...  0.104170        2  \n",
       "251  querie area database data accesses users diffe...  0.102381        2  \n",
       "808  data correlation database querying tuples line...  0.102381        2  \n",
       "935  protocol compute verifies query stream keys da...  0.102381        2  \n",
       "184  queries lsh sections point figure value specif...  0.102381        2  \n",
       "817  partitionings performs section networks social...  0.102381        2  \n",
       "241  emds indexed distributed normals errors bounde...  0.102381        2  \n",
       "880  segmenting time method series nodes indexed sp...  0.102381        2  \n",
       "292  data compress query memory transactions proces...  0.102381        2  \n",
       "160  table data row relations methods contained dat...  0.102381        2  \n",
       "667  aggregate windows streaming slices generalizes...  0.102381        2  \n",
       "652  data database arrays incrementally elastic ske...  0.102381        2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------2----------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reviewer=professionalism(path='../reviewer_pool/reviewer_attribute_937.csv',\n",
    "                         extractive_keyword_result=reviewee,\n",
    "                         reviewee_index=0,\n",
    "                         top_limit=20,\n",
    "                         silhouette_range=25)\n",
    "#return type : pandas.dataframe\n",
    "display(reviewer.iloc[:,[0,2,3,4,5]])\n",
    "print('--------------2----------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aman Sinha</th>\n",
       "      <th>Anastasia Ailamaki</th>\n",
       "      <th>AnHai Doan</th>\n",
       "      <th>Beng Chin Ooi</th>\n",
       "      <th>Brit Youngmann</th>\n",
       "      <th>Chin-Wan Chung</th>\n",
       "      <th>Chong Sun</th>\n",
       "      <th>Christian S. Jensen</th>\n",
       "      <th>Christoph Koch</th>\n",
       "      <th>Gao Cong</th>\n",
       "      <th>...</th>\n",
       "      <th>Ziqiang Feng</th>\n",
       "      <th>Ziqiang Yu</th>\n",
       "      <th>Zitong Chen</th>\n",
       "      <th>Ziyang Liu</th>\n",
       "      <th>Ziyu Guan</th>\n",
       "      <th>Zografoula Vagena</th>\n",
       "      <th>Zoheb Vacheri</th>\n",
       "      <th>Zoi Kaoudi</th>\n",
       "      <th>Zsolt IstvÃ¡n</th>\n",
       "      <th>Zuhair Khayyat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aman Sinha</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anastasia Ailamaki</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnHai Doan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beng Chin Ooi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brit Youngmann</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zografoula Vagena</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoheb Vacheri</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoi Kaoudi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zsolt IstvÃ¡n</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zuhair Khayyat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2622 rows × 2622 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Aman Sinha  Anastasia Ailamaki   AnHai Doan  \\\n",
       "Aman Sinha                  0.0                  0.0         0.0   \n",
       "Anastasia Ailamaki          0.0                  0.0         0.0   \n",
       "AnHai Doan                  0.0                  0.0         0.0   \n",
       "Beng Chin Ooi               0.0                  0.0         0.0   \n",
       "Brit Youngmann              0.0                  0.0         0.0   \n",
       "...                         ...                  ...         ...   \n",
       "Zografoula Vagena           0.0                  0.0         0.0   \n",
       "Zoheb Vacheri               0.0                  0.0         1.0   \n",
       "Zoi Kaoudi                  0.0                  0.0         0.0   \n",
       "Zsolt IstvÃ¡n               0.0                  0.0         0.0   \n",
       "Zuhair Khayyat              0.0                  0.0         0.0   \n",
       "\n",
       "                     Beng Chin Ooi  Brit Youngmann  Chin-Wan Chung  Chong Sun  \\\n",
       "Aman Sinha                     0.0             0.0             0.0        0.0   \n",
       "Anastasia Ailamaki             0.0             0.0             0.0        0.0   \n",
       "AnHai Doan                     0.0             0.0             0.0        1.0   \n",
       "Beng Chin Ooi                  0.0             0.0             0.0        0.0   \n",
       "Brit Youngmann                 0.0             0.0             0.0        0.0   \n",
       "...                            ...             ...             ...        ...   \n",
       "Zografoula Vagena              0.0             0.0             0.0        0.0   \n",
       "Zoheb Vacheri                  0.0             0.0             0.0        0.0   \n",
       "Zoi Kaoudi                     0.0             0.0             0.0        0.0   \n",
       "Zsolt IstvÃ¡n                  0.0             0.0             0.0        0.0   \n",
       "Zuhair Khayyat                 0.0             0.0             0.0        0.0   \n",
       "\n",
       "                     Christian S. Jensen  Christoph Koch  Gao Cong  ...  \\\n",
       "Aman Sinha                           0.0             0.0       0.0  ...   \n",
       "Anastasia Ailamaki                   0.0             0.0       0.0  ...   \n",
       "AnHai Doan                           0.0             0.0       0.0  ...   \n",
       "Beng Chin Ooi                        1.0             0.0       1.0  ...   \n",
       "Brit Youngmann                       0.0             0.0       0.0  ...   \n",
       "...                                  ...             ...       ...  ...   \n",
       "Zografoula Vagena                    0.0             0.0       0.0  ...   \n",
       "Zoheb Vacheri                        0.0             0.0       0.0  ...   \n",
       "Zoi Kaoudi                           0.0             0.0       0.0  ...   \n",
       "Zsolt IstvÃ¡n                        0.0             0.0       0.0  ...   \n",
       "Zuhair Khayyat                       0.0             0.0       0.0  ...   \n",
       "\n",
       "                     Ziqiang Feng  Ziqiang Yu  Zitong Chen  Ziyang Liu  \\\n",
       "Aman Sinha                    0.0         0.0          0.0         0.0   \n",
       "Anastasia Ailamaki            0.0         0.0          0.0         0.0   \n",
       "AnHai Doan                    0.0         0.0          0.0         0.0   \n",
       "Beng Chin Ooi                 0.0         0.0          0.0         0.0   \n",
       "Brit Youngmann                0.0         0.0          0.0         0.0   \n",
       "...                           ...         ...          ...         ...   \n",
       "Zografoula Vagena             0.0         0.0          0.0         0.0   \n",
       "Zoheb Vacheri                 0.0         0.0          0.0         0.0   \n",
       "Zoi Kaoudi                    0.0         0.0          0.0         0.0   \n",
       "Zsolt IstvÃ¡n                 0.0         0.0          0.0         0.0   \n",
       "Zuhair Khayyat                0.0         0.0          0.0         0.0   \n",
       "\n",
       "                     Ziyu Guan  Zografoula Vagena  Zoheb Vacheri  Zoi Kaoudi  \\\n",
       "Aman Sinha                 0.0                0.0            0.0         0.0   \n",
       "Anastasia Ailamaki         0.0                0.0            0.0         0.0   \n",
       "AnHai Doan                 0.0                0.0            1.0         0.0   \n",
       "Beng Chin Ooi              0.0                0.0            0.0         0.0   \n",
       "Brit Youngmann             0.0                0.0            0.0         0.0   \n",
       "...                        ...                ...            ...         ...   \n",
       "Zografoula Vagena          0.0                0.0            0.0         0.0   \n",
       "Zoheb Vacheri              0.0                0.0            0.0         0.0   \n",
       "Zoi Kaoudi                 0.0                0.0            0.0         0.0   \n",
       "Zsolt IstvÃ¡n              0.0                0.0            0.0         0.0   \n",
       "Zuhair Khayyat             0.0                0.0            0.0         0.0   \n",
       "\n",
       "                     Zsolt IstvÃ¡n  Zuhair Khayyat  \n",
       "Aman Sinha                     0.0             0.0  \n",
       "Anastasia Ailamaki             0.0             0.0  \n",
       "AnHai Doan                     0.0             0.0  \n",
       "Beng Chin Ooi                  0.0             0.0  \n",
       "Brit Youngmann                 0.0             0.0  \n",
       "...                            ...             ...  \n",
       "Zografoula Vagena              0.0             0.0  \n",
       "Zoheb Vacheri                  0.0             0.0  \n",
       "Zoi Kaoudi                     0.0             0.0  \n",
       "Zsolt IstvÃ¡n                  0.0             0.0  \n",
       "Zuhair Khayyat                 0.0             0.0  \n",
       "\n",
       "[2622 rows x 2622 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lu Qin</th>\n",
       "      <th>M. Amber Hassaan</th>\n",
       "      <th>Md. Mostofa Ali Patwary</th>\n",
       "      <th>Nguyen Quoc Viet Hung</th>\n",
       "      <th>Pradeep Dubey</th>\n",
       "      <th>Rimma Nehme</th>\n",
       "      <th>Ruoming Jin</th>\n",
       "      <th>Sanjeev Khanna</th>\n",
       "      <th>Shuigeng Zhou</th>\n",
       "      <th>Stratos Idreos</th>\n",
       "      <th>...</th>\n",
       "      <th>Ziqiang Feng</th>\n",
       "      <th>Ziqiang Yu</th>\n",
       "      <th>Zitong Chen</th>\n",
       "      <th>Ziyang Liu</th>\n",
       "      <th>Ziyu Guan</th>\n",
       "      <th>Zografoula Vagena</th>\n",
       "      <th>Zoheb Vacheri</th>\n",
       "      <th>Zoi Kaoudi</th>\n",
       "      <th>Zsolt IstvÃ¡n</th>\n",
       "      <th>Zuhair Khayyat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lu Qin</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeffrey Xu Yu</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lijun Chang</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2603 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Lu Qin  M. Amber Hassaan  Md. Mostofa Ali Patwary  \\\n",
       "Lu Qin              1                 0                        0   \n",
       "Jeffrey Xu Yu       0                 0                        0   \n",
       "Lijun Chang         0                 0                        0   \n",
       "\n",
       "               Nguyen Quoc Viet Hung  Pradeep Dubey  Rimma Nehme  Ruoming Jin  \\\n",
       "Lu Qin                             0              0            0            0   \n",
       "Jeffrey Xu Yu                      0              0            0            0   \n",
       "Lijun Chang                        0              0            0            0   \n",
       "\n",
       "               Sanjeev Khanna  Shuigeng Zhou  Stratos Idreos  ...  \\\n",
       "Lu Qin                      0              0               0  ...   \n",
       "Jeffrey Xu Yu               0              0               0  ...   \n",
       "Lijun Chang                 0              0               0  ...   \n",
       "\n",
       "               Ziqiang Feng  Ziqiang Yu  Zitong Chen  Ziyang Liu  Ziyu Guan  \\\n",
       "Lu Qin                    0           0            0           0          0   \n",
       "Jeffrey Xu Yu             0           0            0           0          0   \n",
       "Lijun Chang               0           0            0           0          0   \n",
       "\n",
       "               Zografoula Vagena  Zoheb Vacheri  Zoi Kaoudi  Zsolt IstvÃ¡n  \\\n",
       "Lu Qin                         0              0           0              0   \n",
       "Jeffrey Xu Yu                  0              0           0              0   \n",
       "Lijun Chang                    0              0           0              0   \n",
       "\n",
       "               Zuhair Khayyat  \n",
       "Lu Qin                      0  \n",
       "Jeffrey Xu Yu               0  \n",
       "Lijun Chang                 0  \n",
       "\n",
       "[3 rows x 2603 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M. Amber Hassaan</th>\n",
       "      <th>Md. Mostofa Ali Patwary</th>\n",
       "      <th>Nguyen Quoc Viet Hung</th>\n",
       "      <th>Pradeep Dubey</th>\n",
       "      <th>Rimma Nehme</th>\n",
       "      <th>Sanjeev Khanna</th>\n",
       "      <th>Shuigeng Zhou</th>\n",
       "      <th>Stratos Idreos</th>\n",
       "      <th>Susan L. Price</th>\n",
       "      <th>Yiqing Ren</th>\n",
       "      <th>...</th>\n",
       "      <th>Abdulhadi Alzaidy</th>\n",
       "      <th>Abdullah Mueen</th>\n",
       "      <th>Aber Whitcomb</th>\n",
       "      <th>Abhay Jha</th>\n",
       "      <th>Abhay Mehta</th>\n",
       "      <th>Abhishek Mukherji</th>\n",
       "      <th>About Data Exchange</th>\n",
       "      <th>Ada Wai-Chee Fu</th>\n",
       "      <th>Ada Waichee Fu</th>\n",
       "      <th>Adam Marcus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lu Qin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeffrey Xu Yu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lijun Chang</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               M. Amber Hassaan  Md. Mostofa Ali Patwary  \\\n",
       "Lu Qin                      0.0                      0.0   \n",
       "Jeffrey Xu Yu               0.0                      0.0   \n",
       "Lijun Chang                 0.0                      0.0   \n",
       "\n",
       "               Nguyen Quoc Viet Hung  Pradeep Dubey  Rimma Nehme  \\\n",
       "Lu Qin                           0.0            0.0          0.0   \n",
       "Jeffrey Xu Yu                    0.0            0.0          0.0   \n",
       "Lijun Chang                      0.0            0.0          0.0   \n",
       "\n",
       "               Sanjeev Khanna  Shuigeng Zhou  Stratos Idreos  Susan L. Price  \\\n",
       "Lu Qin                    0.0            0.0             0.0             0.0   \n",
       "Jeffrey Xu Yu             0.0            0.0             0.0             0.0   \n",
       "Lijun Chang               0.0            0.0             0.0             0.0   \n",
       "\n",
       "               Yiqing Ren  ...  Abdulhadi Alzaidy  Abdullah Mueen  \\\n",
       "Lu Qin                0.0  ...                0.0             0.0   \n",
       "Jeffrey Xu Yu         0.0  ...                0.0             0.0   \n",
       "Lijun Chang           0.0  ...                0.0             0.0   \n",
       "\n",
       "               Aber Whitcomb  Abhay Jha  Abhay Mehta  Abhishek Mukherji  \\\n",
       "Lu Qin                   0.0        0.0          0.0                0.0   \n",
       "Jeffrey Xu Yu            0.0        0.0          0.0                0.0   \n",
       "Lijun Chang              0.0        0.0          0.0                0.0   \n",
       "\n",
       "               About Data Exchange  Ada Wai-Chee Fu  Ada Waichee Fu  \\\n",
       "Lu Qin                         0.0              7.0             0.0   \n",
       "Jeffrey Xu Yu                  0.0              8.0             0.0   \n",
       "Lijun Chang                    0.0              3.0             0.0   \n",
       "\n",
       "               Adam Marcus  \n",
       "Lu Qin                 0.0  \n",
       "Jeffrey Xu Yu          0.0  \n",
       "Lijun Chang            0.0  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University Leipzig Germany</th>\n",
       "      <th>University of Maryland College Park, MD, USA</th>\n",
       "      <th>University of Washington</th>\n",
       "      <th>University of Texas at Arlington</th>\n",
       "      <th>CWI, Amsterdam</th>\n",
       "      <th>Department of Computer Science Iowa State University Ames, IA, USA</th>\n",
       "      <th>University of Southern California</th>\n",
       "      <th>Department of Computer Science and Engineering Chinese University of Hong Kong New Territories, Hong Kong</th>\n",
       "      <th>AT&amp;T Labs Research 180 Park Avenue Florham Park, NJ 07932</th>\n",
       "      <th>Teradata Corporation, 100 N. Sepulveda Blvd., El Segundo, CA, 90245</th>\n",
       "      <th>...</th>\n",
       "      <th>School of Computing Science Newcastle University</th>\n",
       "      <th>INRIA &amp; U. Paris-Sud, France</th>\n",
       "      <th>UC Riverside</th>\n",
       "      <th>Lane Center of Computational Biology, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA</th>\n",
       "      <th>Department of Computer Science and Engineering HKUST Hong Kong</th>\n",
       "      <th>Huawei Noah's Ark Lab, Hong Kong</th>\n",
       "      <th>EPFL &amp; Cornell University</th>\n",
       "      <th>Yahoo! Research Santa Clara, CA, USA</th>\n",
       "      <th>CWI Amsterdam The Netherlands</th>\n",
       "      <th>University of Washington, Seattle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The Chinese University of Hong Kong, Hong Kong, China</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Chinese University of Hong Kong, Hong Kong, China</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Chinese University of Hong Kong, Hong Kong, China</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   University Leipzig Germany  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                          0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                          0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                          0   \n",
       "\n",
       "                                                   University of Maryland College Park, MD, USA  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                            0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                            0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                            0   \n",
       "\n",
       "                                                   University of Washington  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                        0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                        0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                        0   \n",
       "\n",
       "                                                   University of Texas at Arlington  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                0   \n",
       "\n",
       "                                                   CWI, Amsterdam  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...              0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...              0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...              0   \n",
       "\n",
       "                                                   Department of Computer Science Iowa State University Ames, IA, USA  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                   \n",
       "\n",
       "                                                   University of Southern California  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                 0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                 0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                 0   \n",
       "\n",
       "                                                   Department of Computer Science and Engineering Chinese University of Hong Kong New Territories, Hong Kong   \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                                                           \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                                                           \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                                                           \n",
       "\n",
       "                                                   AT&T Labs Research 180 Park Avenue Florham Park, NJ 07932  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0          \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0          \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0          \n",
       "\n",
       "                                                   Teradata Corporation, 100 N. Sepulveda Blvd., El Segundo, CA, 90245  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                    \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                    \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                    \n",
       "\n",
       "                                                    ...  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...  ...   \n",
       "The Chinese University of Hong Kong, Hong Kong,...  ...   \n",
       "The Chinese University of Hong Kong, Hong Kong,...  ...   \n",
       "\n",
       "                                                   School of Computing Science Newcastle University  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                0   \n",
       "\n",
       "                                                   INRIA & U. Paris-Sud, France  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                            0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                            0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                            0   \n",
       "\n",
       "                                                   UC Riverside  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...            0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...            0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...            0   \n",
       "\n",
       "                                                   Lane Center of Computational Biology, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                                                                  \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                                                                  \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0                                                                  \n",
       "\n",
       "                                                   Department of Computer Science and Engineering HKUST Hong Kong  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0               \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0               \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                                  0               \n",
       "\n",
       "                                                   Huawei Noah's Ark Lab, Hong Kong  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                0   \n",
       "\n",
       "                                                   EPFL & Cornell University  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                         0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                         0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                         0   \n",
       "\n",
       "                                                   Yahoo! Research Santa Clara, CA, USA  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                                    0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                    0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                    0   \n",
       "\n",
       "                                                   CWI Amsterdam The Netherlands  \\\n",
       "The Chinese University of Hong Kong, Hong Kong,...                             0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                             0   \n",
       "The Chinese University of Hong Kong, Hong Kong,...                             0   \n",
       "\n",
       "                                                   University of Washington, Seattle  \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                 0  \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                 0  \n",
       "The Chinese University of Hong Kong, Hong Kong,...                                 0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>reviewer_orcid</th>\n",
       "      <th>title</th>\n",
       "      <th>sim</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chen Wang</td>\n",
       "      <td>381</td>\n",
       "      <td>Parallel Duplicate Detection in Adverse Drug R...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dimitrios Karapiperis</td>\n",
       "      <td>549</td>\n",
       "      <td>Efficient Record Linkage Using a Compact Hammi...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Houtan Shirani-Mehr</td>\n",
       "      <td>891</td>\n",
       "      <td>Efficient Reachability Query Evaluation in Lar...</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ke Wang</td>\n",
       "      <td>1200</td>\n",
       "      <td>Reconstruction Privacy: Enabling Statistical L...</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dongqing Xiao</td>\n",
       "      <td>585</td>\n",
       "      <td>InsightNotes: Summary-Based Annotation Managem...</td>\n",
       "      <td>0.106044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ilya Taranov</td>\n",
       "      <td>919</td>\n",
       "      <td>Sedna: Native XML Database Management System (...</td>\n",
       "      <td>0.104170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merih Seran Uysal</td>\n",
       "      <td>1478</td>\n",
       "      <td>Efficient Query Processing Using the Earth Mov...</td>\n",
       "      <td>0.104170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jonas Traub</td>\n",
       "      <td>1099</td>\n",
       "      <td>Efficient Window Aggregation with General Stre...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian E. Ruttenberg</td>\n",
       "      <td>324</td>\n",
       "      <td>Indexing the Earth MoverÂ¢Â® ?s Distance Using...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bhargav Kanagal</td>\n",
       "      <td>288</td>\n",
       "      <td>Lineage Processing over Correlated Probabilist...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Daniel Nicoara</td>\n",
       "      <td>481</td>\n",
       "      <td>Hermes: Dynamic Partitioning for Distributed S...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Florian Funke</td>\n",
       "      <td>692</td>\n",
       "      <td>Compacting Transactional Data in Hybrid OLTP&amp;O...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Graham Cormode</td>\n",
       "      <td>778</td>\n",
       "      <td>Verifying Computations with Streaming Interact...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hoang Vu Nguyen</td>\n",
       "      <td>874</td>\n",
       "      <td>Identifying User Interests within the Data Spa...</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Marco D. Adelfio</td>\n",
       "      <td>1399</td>\n",
       "      <td>Schema Extraction for Tabular Data on the Web</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jennie Duggan</td>\n",
       "      <td>991</td>\n",
       "      <td>Incremental Elasticity For Array Databases</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewer_name  reviewer_orcid  \\\n",
       "3               Chen Wang             381   \n",
       "14  Dimitrios Karapiperis             549   \n",
       "12    Houtan Shirani-Mehr             891   \n",
       "15                Ke Wang            1200   \n",
       "13          Dongqing Xiao             585   \n",
       "2            Ilya Taranov             919   \n",
       "6       Merih Seran Uysal            1478   \n",
       "0             Jonas Traub            1099   \n",
       "1     Brian E. Ruttenberg             324   \n",
       "4         Bhargav Kanagal             288   \n",
       "5          Daniel Nicoara             481   \n",
       "7           Florian Funke             692   \n",
       "8          Graham Cormode             778   \n",
       "9         Hoang Vu Nguyen             874   \n",
       "10       Marco D. Adelfio            1399   \n",
       "11          Jennie Duggan             991   \n",
       "\n",
       "                                                title       sim  count  \n",
       "3   Parallel Duplicate Detection in Adverse Drug R...  0.155556      0  \n",
       "14  Efficient Record Linkage Using a Compact Hammi...  0.155556      0  \n",
       "12  Efficient Reachability Query Evaluation in Lar...  0.128788      0  \n",
       "15  Reconstruction Privacy: Enabling Statistical L...  0.128788      0  \n",
       "13  InsightNotes: Summary-Based Annotation Managem...  0.106044      0  \n",
       "2   Sedna: Native XML Database Management System (...  0.104170      0  \n",
       "6   Efficient Query Processing Using the Earth Mov...  0.104170      0  \n",
       "0   Efficient Window Aggregation with General Stre...  0.102381      0  \n",
       "1   Indexing the Earth MoverÂ¢Â® ?s Distance Using...  0.102381      0  \n",
       "4   Lineage Processing over Correlated Probabilist...  0.102381      0  \n",
       "5   Hermes: Dynamic Partitioning for Distributed S...  0.102381      0  \n",
       "7   Compacting Transactional Data in Hybrid OLTP&O...  0.102381      0  \n",
       "8   Verifying Computations with Streaming Interact...  0.102381      0  \n",
       "9   Identifying User Interests within the Data Spa...  0.102381      0  \n",
       "10      Schema Extraction for Tabular Data on the Web  0.102381      0  \n",
       "11         Incremental Elasticity For Array Databases  0.102381      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------3----------------\n"
     ]
    }
   ],
   "source": [
    "reviewer_rank = interest(\n",
    "    co_author_path='../reviewer_pool/reviewer_coauthor_937.csv',\n",
    "    reviewer_information_path='../reviewer_pool/reviewer_information_937.csv',\n",
    "    co_author_network_path='../co_author_network/network.csv',\n",
    "    professionalism_result=reviewer,\n",
    "    extractive_keyword_result=reviewee,\n",
    "    reviewee_index=0,\n",
    "    matrix_multifly_count=1)\n",
    "#return type : pandas.dataframe\n",
    "display(reviewer_rank)\n",
    "# reviewer_rank.to_csv('./a.csv')\n",
    "print('--------------3----------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.save_csv(output_path, extractive_keyword_result, professionalism_result, reviewee_index, top_limit)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------11------------------\n"
     ]
    }
   ],
   "source": [
    "save_csv(output_path='../algorithm_output/export_csv_937.csv',\n",
    "         extractive_keyword_result=reviewee,\n",
    "         professionalism_result=reviewer_rank,\n",
    "         reviewee_index=0,\n",
    "         top_limit=3)\n",
    "display(save_csv)\n",
    "\n",
    "\n",
    "print('-------------------11------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[equl_distribution | 53.81100]\n"
     ]
    }
   ],
   "source": [
    "equl_distribution(input_csv_path='../algorithm_output/export_csv_937.csv',\n",
    "             output_csv_path='../algorithm_output/final_csv_937.csv')\n",
    "\n",
    "print('[equl_distribution | {time:2.5f}]'.format(time=time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>submitter_title</th>\n",
       "      <th>date</th>\n",
       "      <th>submitter_name</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>reviewer_orcid</th>\n",
       "      <th>title</th>\n",
       "      <th>sim</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Diversifying Top-K Results</td>\n",
       "      <td>20200101</td>\n",
       "      <td>Lu Qin</td>\n",
       "      <td>Jong Wook Kim</td>\n",
       "      <td>1106</td>\n",
       "      <td>Skip-and-Prune: Cosine-based Top-K Query Proce...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Diversifying Top-K Results</td>\n",
       "      <td>20200101</td>\n",
       "      <td>Lu Qin</td>\n",
       "      <td>Jong Wook Kim</td>\n",
       "      <td>1106</td>\n",
       "      <td>Skip-and-Prune: Cosine-based Top-K Query Proce...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Diversifying Top-K Results</td>\n",
       "      <td>20200101</td>\n",
       "      <td>Lu Qin</td>\n",
       "      <td>El Kindi Rezig</td>\n",
       "      <td>606</td>\n",
       "      <td>Query-Time Record Linkage and Fusion over Web ...</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Diversifying Top-K Results</td>\n",
       "      <td>20200101</td>\n",
       "      <td>Lu Qin</td>\n",
       "      <td>Henning K?hler</td>\n",
       "      <td>859</td>\n",
       "      <td>Efficient Parallel Skyline Processing using Hy...</td>\n",
       "      <td>0.110073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Diversifying Top-K Results</td>\n",
       "      <td>20200101</td>\n",
       "      <td>Lu Qin</td>\n",
       "      <td>Henning K?hler</td>\n",
       "      <td>859</td>\n",
       "      <td>Efficient Parallel Skyline Processing using Hy...</td>\n",
       "      <td>0.110073</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Diversifying Top-K Results</td>\n",
       "      <td>20200101</td>\n",
       "      <td>Lu Qin</td>\n",
       "      <td>Gheorghi Guzun</td>\n",
       "      <td>764</td>\n",
       "      <td>Distributed query-aware quantization for high-...</td>\n",
       "      <td>0.104170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             submitter_title      date submitter_name  \\\n",
       "0           0  Diversifying Top-K Results  20200101         Lu Qin   \n",
       "1           1  Diversifying Top-K Results  20200101         Lu Qin   \n",
       "2           2  Diversifying Top-K Results  20200101         Lu Qin   \n",
       "3           3  Diversifying Top-K Results  20200101         Lu Qin   \n",
       "4           4  Diversifying Top-K Results  20200101         Lu Qin   \n",
       "5           5  Diversifying Top-K Results  20200101         Lu Qin   \n",
       "\n",
       "    reviewer_name  reviewer_orcid  \\\n",
       "0  Jong Wook Kim             1106   \n",
       "1  Jong Wook Kim             1106   \n",
       "2  El Kindi Rezig             606   \n",
       "3  Henning K?hler             859   \n",
       "4  Henning K?hler             859   \n",
       "5  Gheorghi Guzun             764   \n",
       "\n",
       "                                               title       sim  count  \n",
       "0  Skip-and-Prune: Cosine-based Top-K Query Proce...  0.155556      1  \n",
       "1  Skip-and-Prune: Cosine-based Top-K Query Proce...  0.155556      2  \n",
       "2  Query-Time Record Linkage and Fusion over Web ...  0.128788      1  \n",
       "3  Efficient Parallel Skyline Processing using Hy...  0.110073      1  \n",
       "4  Efficient Parallel Skyline Processing using Hy...  0.110073      2  \n",
       "5  Distributed query-aware quantization for high-...  0.104170      1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = pd.read_csv('../algorithm_output/final_csv_937.csv', encoding='latin1')\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
