{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>submitter_orcid</th>\n",
       "      <th>submitter_name</th>\n",
       "      <th>submitter_institution</th>\n",
       "      <th>submitter_email</th>\n",
       "      <th>submitter_title_doi</th>\n",
       "      <th>submitter_title</th>\n",
       "      <th>submitter_intro</th>\n",
       "      <th>submitter_author1_name</th>\n",
       "      <th>submitter_author1_institution</th>\n",
       "      <th>...</th>\n",
       "      <th>submitter_author8_name</th>\n",
       "      <th>submitter_author8_institution</th>\n",
       "      <th>submitter_author8_email</th>\n",
       "      <th>submitter_author9_name</th>\n",
       "      <th>submitter_author9_institution</th>\n",
       "      <th>submitter_author9_email</th>\n",
       "      <th>submitter_author10_name</th>\n",
       "      <th>submitter_author10_institution</th>\n",
       "      <th>submitter_author10_email</th>\n",
       "      <th>submitter_attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200101</td>\n",
       "      <td>326</td>\n",
       "      <td>Lu Qin</td>\n",
       "      <td>The Chinese University of Hong Kong, Hong Kong...</td>\n",
       "      <td>lqin@se.cuhk.edu.hk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diversifying Top-K Results</td>\n",
       "      <td>ABSTRACT This paper proposes a general framewo...</td>\n",
       "      <td>Lu Qin</td>\n",
       "      <td>The Chinese University of Hong Kong, Hong Kong...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>distance similarities match sequences subseque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200102</td>\n",
       "      <td>897</td>\n",
       "      <td>Haohan Zhu</td>\n",
       "      <td>Department of Computer Science Boston University</td>\n",
       "      <td>zhu@cs.bu.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Generic Framework for Efficient and Effectiv...</td>\n",
       "      <td>ABSTRACT Top-k query processing finds a list o...</td>\n",
       "      <td>Haohan Zhu</td>\n",
       "      <td>Department of Computer Science Boston University</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>result algorithms searches problems solution b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200103</td>\n",
       "      <td>1387</td>\n",
       "      <td>Stefan Aulbach</td>\n",
       "      <td>Technische Universit?t M?nchen, Germany</td>\n",
       "      <td>stefan.aulbach@in.tum.de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Comparison of Flexible Schemas for Software ...</td>\n",
       "      <td>ABSTRACT A multi-tenant database system for So...</td>\n",
       "      <td>Stefan Aulbach</td>\n",
       "      <td>Technische Universit?t M?nchen, Germany</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>table column mappings tenants performing queri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  submitter_orcid  submitter_name  \\\n",
       "0  20200101              326          Lu Qin   \n",
       "1  20200102              897      Haohan Zhu   \n",
       "2  20200103             1387  Stefan Aulbach   \n",
       "\n",
       "                               submitter_institution  \\\n",
       "0  The Chinese University of Hong Kong, Hong Kong...   \n",
       "1   Department of Computer Science Boston University   \n",
       "2            Technische Universit?t M?nchen, Germany   \n",
       "\n",
       "            submitter_email  submitter_title_doi  \\\n",
       "0       lqin@se.cuhk.edu.hk                  NaN   \n",
       "1             zhu@cs.bu.edu                  NaN   \n",
       "2  stefan.aulbach@in.tum.de                  NaN   \n",
       "\n",
       "                                     submitter_title  \\\n",
       "0                         Diversifying Top-K Results   \n",
       "1  A Generic Framework for Efficient and Effectiv...   \n",
       "2  A Comparison of Flexible Schemas for Software ...   \n",
       "\n",
       "                                     submitter_intro submitter_author1_name  \\\n",
       "0  ABSTRACT This paper proposes a general framewo...                 Lu Qin   \n",
       "1  ABSTRACT Top-k query processing finds a list o...             Haohan Zhu   \n",
       "2  ABSTRACT A multi-tenant database system for So...         Stefan Aulbach   \n",
       "\n",
       "                       submitter_author1_institution  ...  \\\n",
       "0  The Chinese University of Hong Kong, Hong Kong...  ...   \n",
       "1   Department of Computer Science Boston University  ...   \n",
       "2            Technische Universit?t M?nchen, Germany  ...   \n",
       "\n",
       "  submitter_author8_name submitter_author8_institution  \\\n",
       "0                    NaN                           NaN   \n",
       "1                    NaN                           NaN   \n",
       "2                    NaN                           NaN   \n",
       "\n",
       "  submitter_author8_email submitter_author9_name  \\\n",
       "0                     NaN                    NaN   \n",
       "1                     NaN                    NaN   \n",
       "2                     NaN                    NaN   \n",
       "\n",
       "  submitter_author9_institution submitter_author9_email  \\\n",
       "0                           NaN                     NaN   \n",
       "1                           NaN                     NaN   \n",
       "2                           NaN                     NaN   \n",
       "\n",
       "  submitter_author10_name submitter_author10_institution  \\\n",
       "0                     NaN                            NaN   \n",
       "1                     NaN                            NaN   \n",
       "2                     NaN                            NaN   \n",
       "\n",
       "  submitter_author10_email                                submitter_attribute  \n",
       "0                      NaN  distance similarities match sequences subseque...  \n",
       "1                      NaN  result algorithms searches problems solution b...  \n",
       "2                      NaN  table column mappings tenants performing queri...  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "\n",
    "#import python packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.datasets import *\n",
    "from sklearn.cluster import *\n",
    "\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from operator import itemgetter\n",
    "from operator import attrgetter\n",
    "\n",
    "from pyjarowinkler import distance\n",
    "from collections import Counter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#전처리 함수 정의부\n",
    "def remove_string_special_characters(s):\n",
    "    \n",
    "    stripped = re.sub('[^a-zA-z\\s]', '', s)\n",
    "    \n",
    "    stripped = re.sub('_', '', stripped)\n",
    "    \n",
    "    stripped = re.sub('\\s+', ' ', stripped)\n",
    "    \n",
    "    stripped = stripped.strip()\n",
    "    \n",
    "    if stripped != '':\n",
    "        return stripped.lower()\n",
    "    \n",
    "#클래스 정렬 함수 정의부\n",
    "def multisort(xs, specs):\n",
    "    \n",
    "    for key, reverse in reversed(specs):\n",
    "        \n",
    "        xs.sort(key=attrgetter(key), reverse=reverse)\n",
    "        \n",
    "    return xs\n",
    "\n",
    "#속성집합 추출 함수 정의부\n",
    "#키워드 매개변수(입력csv path, 속선집합 포함 출력csv path, 추출할 단어 수)\n",
    "def extractive_keyword(path,database_update_path,extract_word_num=20):\n",
    "    \n",
    "    reviewee = pd.read_csv(path, encoding='latin1')\n",
    "    count,temp = len(reviewee),[]\n",
    "\n",
    "    for i in range(count):\n",
    "        \n",
    "        temp_intro = reviewee['submitter_intro'][i]\n",
    "\n",
    "        textrank_text = ''\n",
    "\n",
    "        for c in (keywords(temp_intro, words=extract_word_num, lemmatize=True).split('\\n')):\n",
    "            \n",
    "            textrank_text += (c+ \" \")\n",
    "\n",
    "        temp.append(textrank_text)\n",
    "\n",
    "    reviewee['submitter_attribute']=temp\n",
    "    \n",
    "    #return type : pandas.dataframe\n",
    "    return reviewee\n",
    "\n",
    "reviewee=extractive_keyword(path='../reviewee/submitter_10.csv',\n",
    "                                database_update_path='../../reviewee/sybmitter_update_100.csv',\n",
    "                                extract_word_num=20)\n",
    "reviewee[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "#전문성 검사 함수 정의부\n",
    "#키워드 매개변수(입력csv path, 투고원고 DataFrame, i번째 투고 원고, 추천할 심사자 수, 실루엣값 계산 범위 지정)\n",
    "def professionalism(path,extractive_keyword_result,reviewee_index,top_limit,silhouette_range=25):\n",
    "    \n",
    "    #인자 전달\n",
    "    reviewee,index,top=extractive_keyword_result,reviewee_index,top_limit\n",
    "    temp_id,temp_doi = 0,''\n",
    "    \n",
    "    #투고 원고 열 정보 추출\n",
    "    temp_title = reviewee.loc[index]['submitter_title']\n",
    "    temp_attribure = reviewee.loc[index]['submitter_attribute']\n",
    "    \n",
    "    # 심사자풀 Read\n",
    "    reviewer_attr = pd.read_csv(path, encoding='latin1')\n",
    "    \n",
    "    # 투고원고 dataframe 맨 윗줄 추가\n",
    "    reviewer_attr.loc[-1] = [str(temp_id),temp_doi,temp_title,temp_attribure]\n",
    "    reviewer_attr.index += 1\n",
    "    reviewer_attr.sort_index(inplace=True)\n",
    "    reviewer = reviewer_attr['reviewer_paper_attribure']\n",
    "    \n",
    "    jac_token,jac,cos,avg=[],[],[],[]\n",
    "\n",
    "    # jaccard_distance\n",
    "    for t in range(len(reviewer)):        \n",
    "        jac_token.append(set(nltk.ngrams((nltk.word_tokenize(reviewer[t])), n=1)))    \n",
    "    for j in range(len(reviewer)):\n",
    "        jac.append(1-(nltk.jaccard_distance(jac_token[0], jac_token[j])))\n",
    "\n",
    "    # cosine_similarity\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    sparse_matrix = count_vectorizer.fit_transform(reviewer)\n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, \n",
    "                      columns=count_vectorizer.get_feature_names(), \n",
    "                      index=[i for i in reviewer])\n",
    "    cos=cosine_similarity(df, df)[0].tolist()\n",
    "\n",
    "    for i in range(len(jac)):\n",
    "        avg.append((jac[i] + cos[i])/2)\n",
    "    reviewer_attr['sim']=avg\n",
    "    \n",
    "    reviewer_attr2 = reviewer_attr.sort_values(by=['sim'], axis=0, ascending=False)\n",
    "    reviewer_attr3=reviewer_attr2[~reviewer_attr2.duplicated(['reviewer_orcid'],keep=False) == True]\n",
    "    reviewer_attr4 = reviewer_attr2[reviewer_attr2.duplicated(['reviewer_orcid'],keep='last') == True]\n",
    "    reviewer_attr5=pd.concat([reviewer_attr3,reviewer_attr4])\n",
    "    reviewer_attr5.rename(columns = {'reviewer_paper_attribure' : 'reviewer_paper_feature'}, inplace = True)\n",
    "    reviewer2 = list(reviewer_attr5['reviewer_paper_feature'])\n",
    "    \n",
    "    # 속성집합 20개 제한\n",
    "    reviewer_attribute=[]\n",
    "    for i in range(len(reviewer)):\n",
    "        a=((reviewer[i]).split(' '))\n",
    "        b=a[:20]\n",
    "        temp=[]\n",
    "        for j in range(20):\n",
    "            temp.append(b[j])\n",
    "            temp += (str(b[j]) + ',')\n",
    "        reviewer_attribute.append(temp[:-1])\n",
    "    \n",
    "    common_texts_and_tags = [\n",
    "        (text, [f\"str_{i}\",]) for i, text in enumerate(reviewer_attribute)\n",
    "    ]\n",
    "    \n",
    "    TRAIN_documents = [TaggedDocument(words=text, tags=tags) for text, tags in common_texts_and_tags]\n",
    "    \n",
    "    model = Doc2Vec(TRAIN_documents)\n",
    "    \n",
    "    for text, tags in common_texts_and_tags:\n",
    "        trained_doc_vec = model.docvecs[tags[0]]\n",
    "        inferred_doc_vec = model.infer_vector(text)\n",
    "\n",
    "    dtm_df=[]\n",
    "    for text, tags in common_texts_and_tags:\n",
    "\n",
    "        inferred_doc_vec = model.infer_vector(text)\n",
    "\n",
    "        dtm_df_temp=[]\n",
    "        for text2, tag2s in common_texts_and_tags:\n",
    "\n",
    "            inferred_doc_vec = model.infer_vector(text2)\n",
    "\n",
    "            sim = word_vectors.wmdistance(text, text2)\n",
    "\n",
    "            dtm_df_temp.append(sim)\n",
    "        dtm_df.append(dtm_df_temp)\n",
    "\n",
    "    dissim_df = pd.DataFrame(data=dtm_df)\n",
    "    dissimilarity=dissim_df.values\n",
    "\n",
    "    model1 = AgglomerativeClustering(n_clusters=8, affinity='euclidean', linkage='ward')\n",
    "    model1.fit(dissimilarity)\n",
    "    labels1 = model1.labels_\n",
    "    dissim_df['cluster']=labels1\n",
    "    \n",
    "    cluster_reviewer = reviewer_attr5[reviewer_attr5['cluster'] == reviewer_attr5.loc[0]['cluster']]\n",
    "\n",
    "    cluster_reviewer2 = cluster_reviewer.sort_values(by=['sim'], axis=0, ascending=False)\n",
    "    \n",
    "    professionalism=cluster_reviewer2.iloc[0:top+1] #1\n",
    "    \n",
    "    #return type : pandas.dataframe\n",
    "    return dissim_df\n",
    "    \n",
    "#전문성검사\n",
    "#키워드 매개변수(입력csv path, 투고원고 DataFrame, i번째 투고 원고, 추천할 심사자 수, 실루엣값 계산 범위 지정)\n",
    "i=0\n",
    "print(str(i)+'번째')\n",
    "aaa = professionalism(path='./reviewer_attribute_937.csv',\n",
    "                     extractive_keyword_result=reviewee,\n",
    "                     reviewee_index=i,\n",
    "                     top_limit=10,\n",
    "                     silhouette_range=25)\n",
    "#return type : pandas.dataframe\n",
    "\n",
    "# reviewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interest(co_author_path, reviewer_information_path, co_author_network_path, professionalism_result, extractive_keyword_result, reviewee_index,matrix_multifly_count):\n",
    "    \n",
    "    #매개변수 전달\n",
    "    path1,path2=co_author_path,reviewer_information_path\n",
    "    network_path=co_author_network_path\n",
    "    temp,reviewee = professionalism_result,extractive_keyword_result\n",
    "    index,multifly=reviewee_index,matrix_multifly_count\n",
    "\n",
    "    #import Dataset\n",
    "    co_author_csv = pd.read_csv(path1, encoding='latin1')\n",
    "    \n",
    "    #merge coauthor & 전문성 검사 결과\n",
    "    co_author_df = co_author_csv.merge(temp, on=['reviewer_orcid'])  \n",
    "    co_author_df2 = co_author_df.iloc[:]['reviewer_name'].tolist()\n",
    "    \n",
    "    #import network\n",
    "    try :\n",
    "        #read network csv\n",
    "        network_csv = pd.read_csv(network_path, encoding='latin1',index_col=0)\n",
    "    except FileNotFoundError :\n",
    "        df1=pd.read_csv('./network/network0704.csv')\n",
    "        df2=pd.read_csv('./network/network0704_2.csv')\n",
    "\n",
    "        tmp=[1]\n",
    "        tmp.extend(i*2 for i in range(1,11))\n",
    "\n",
    "        for k in range(1,len(df1.columns)):\n",
    "            a=df1.columns[k]\n",
    "            a1=df2.loc[df2['reviewer_coauthor_title']==a]\n",
    "            a_list=[]\n",
    "            for i in range(len(tmp)):\n",
    "                a_list.append(a1.iloc[0][tmp[i]])\n",
    "            for i in range(len(df1)):\n",
    "                if (df1.iloc[i,0] in a_list) is True :df1.iloc[i,k]=1\n",
    "                else :df1.iloc[i,k]=0\n",
    "\n",
    "        mat=(df1.values)[:,1:]\n",
    "        mat2=mat.T\n",
    "        mat3=np.dot(mat,mat2)\n",
    "        for i in range(len(mat3)):\n",
    "            mat3[i,i]=0\n",
    "        fof=np.dot(mat3,mat3)\n",
    "        \n",
    "        df1_index=(df1.iloc[:,0]).tolist()\n",
    "        df1_col=(df1.columns)[1:]\n",
    "        network_csv=pd.DataFrame(data=mat3,index=df1_index,columns=df1_index)\n",
    "        network_csv.to_csv(network_path)\n",
    "    \n",
    "    display(network_csv)\n",
    "    reviewer_list=(network_csv.index).tolist()\n",
    "    \n",
    "    reviewee_list=[]\n",
    "    reviewee.fillna(0, inplace=True)\n",
    "    for i in range(1,11):\n",
    "        col_index = (i*3)+5\n",
    "        if reviewee.loc[index][col_index] != 0:\n",
    "            reviewee_list.append(reviewee.loc[index][col_index])\n",
    "    \n",
    "    co_rel_df = pd.DataFrame(\n",
    "        columns=[i for i in reviewer_list],\n",
    "        index=[j for j in reviewee_list])\n",
    "    \n",
    "    for i in range(len(reviewee_list)):\n",
    "        indet_temp=reviewer_list.index(reviewee_list[i])\n",
    "        co_rel_df.iloc[i,indet_temp]=1\n",
    "    co_rel_df.fillna(0, inplace=True)\n",
    "    \n",
    "    display(co_rel_df.iloc[:,19:])\n",
    "    \n",
    "    network_csv_v=network_csv.values\n",
    "    for i in range(multifly):\n",
    "        network_csv_v = network_csv_v.dot(network_csv_v)\n",
    "\n",
    "    co_rel_df_v=co_rel_df.values\n",
    "    fof = co_rel_df_v.dot(network_csv_v)\n",
    "    \n",
    "    df_fof=pd.DataFrame(data=fof,\n",
    "                 index=(co_rel_df.index).tolist(),\n",
    "                 columns=(network_csv.index).tolist())\n",
    "    \n",
    "    display(df_fof.iloc[:,[20,21,22,23,24,26,27,28,29,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50]])\n",
    "    df_fof_series =df_fof.loc[:, (df_fof != 0).any(axis=0)]\n",
    "    df_fof_series_list=(df_fof_series.columns).tolist()\n",
    "    \n",
    "    reviewer_list1 = list(set(co_author_df2).difference(df_fof_series_list))\n",
    "    \n",
    "    co_inst_csv = pd.read_csv(path2, encoding='latin1')\n",
    "\n",
    "    co_inst_df = co_inst_csv.merge(temp, on=['reviewer_orcid'])\n",
    "\n",
    "    reviewee_list2=[]\n",
    "    for i in range(1,11):\n",
    "        col_index = (i*3)+6\n",
    "        if reviewee.loc[index][col_index] != 0:\n",
    "            reviewee_list2.append(reviewee.loc[index][col_index])\n",
    "    \n",
    "    reviewer_list2,reviewer_inst_list=[],[]\n",
    "    for j in range(len(co_inst_df)):#\n",
    "        inst_list_temp=[]\n",
    "        reviewer_list2.append(co_inst_df['reviewer_name'][j])#\n",
    "        reviewer_inst_list.append(co_inst_df['reviewer_institution'][j])#\n",
    "\n",
    "    inst_rel_df = pd.DataFrame(\n",
    "        columns=[i for i in reviewer_list2],#\n",
    "        index=[j for j in reviewee_list])#\n",
    "\n",
    "    for i in range(len(reviewee_list2)):\n",
    "        for j in range(len(reviewer_inst_list)):\n",
    "            if (reviewee_list2[i] == reviewer_inst_list[j]) : inst_rel_df.iloc[i, j] = 1\n",
    "            else : inst_rel_df.iloc[i, j] = 0\n",
    "                \n",
    "    #-----------------\n",
    "    \n",
    "#     display(inst_rel_df.iloc[:,[750,751,752,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,1,2,3,4,5,6,7,8,9,10]])\n",
    "    \n",
    "    #-----------------\n",
    "    \n",
    "    inst_rel_df_series = inst_rel_df.loc[:, (inst_rel_df != 0).any(axis=0)]\n",
    "    inst_rel_df_series_list=(inst_rel_df_series.columns).tolist()\n",
    "    \n",
    "    reviewer_list2 = list(set(reviewer_list2).difference(inst_rel_df_series_list))\n",
    "    \n",
    "    reviewer_rank_list = list(set(reviewer_list1).intersection(reviewer_list2))\n",
    "\n",
    "    id_index,sim_index,count_index,title_index=[],[],[],[]\n",
    "    reviewer_rank = pd.DataFrame({'reviewer_name': reviewer_rank_list})\n",
    "    \n",
    "    for i in range(len(reviewer_rank)):\n",
    "        for j in range(len(co_author_df)):\n",
    "            if reviewer_rank.loc[i]['reviewer_name'] == co_author_df.loc[j]['reviewer_name'] :\n",
    "                id_index.append(int(co_author_df.iloc[j]['reviewer_orcid']))\n",
    "                sim_index.append(co_author_df.iloc[j]['sim'])\n",
    "                title_index.append(co_author_df.iloc[j]['reviewer_title'])\n",
    "                break\n",
    "            if reviewer_rank.loc[i]['reviewer_name'] == co_inst_df.loc[j]['reviewer_name'] :\n",
    "                count_index.append(co_inst_df.iloc[j]['count'])\n",
    "    \n",
    "    aaa=[]\n",
    "    for i in range(len(reviewer_rank)):\n",
    "        aaa.append(0)\n",
    "    \n",
    "    reviewer_rank['reviewer_orcid']=id_index\n",
    "    reviewer_rank['title']=title_index\n",
    "    reviewer_rank['sim']=sim_index\n",
    "    reviewer_rank['count']=aaa\n",
    "    \n",
    "    reviewer_rank2 = reviewer_rank.sort_values(by=['sim'], axis=0, ascending=False)\n",
    "                \n",
    "    #return type : pandas.dataframe\n",
    "    return reviewer_rank2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(output_path,extractive_keyword_result,professionalism_result,reviewee_index,top_limit):\n",
    "    \n",
    "    path,ee_num,top=output_path,reviewee_index,top_limit\n",
    "    reviewee,reviewer_rank_name=extractive_keyword_result,professionalism_result\n",
    "    \n",
    "    export_data=[]\n",
    "    for i in range((top*2)):\n",
    "        #reviewee\n",
    "        temp=[]\n",
    "        temp.append(reviewee.iloc[(1//top*2)+ee_num]['submitter_title'])\n",
    "        temp.append(reviewee.iloc[(1//top*2)+ee_num]['date'])\n",
    "        temp.append(reviewee.iloc[(1//top*2)+ee_num]['submitter_name'])\n",
    "        #reviewer_rank_name\n",
    "        temp.append(reviewer_rank_name.iloc[i]['reviewer_name'])\n",
    "        temp.append(reviewer_rank_name.iloc[i]['reviewer_orcid'])\n",
    "        temp.append(reviewer_rank_name.iloc[i]['title'])\n",
    "        temp.append(reviewer_rank_name.iloc[i]['sim'])\n",
    "        temp.append(reviewer_rank_name.iloc[i]['count'])\n",
    "        #export_data\n",
    "        export_data.append(temp)\n",
    "        \n",
    "    try :\n",
    "        export_csv = pd.read_csv(path,index_col=0)\n",
    "    except FileNotFoundError :\n",
    "        export_csv = pd.DataFrame([],columns=['submitter_title','date','submitter_name','reviewer_name','reviewer_orcid','title','sim','count'])\n",
    "    \n",
    "    for i in range(len(export_data)):\n",
    "        export_csv.loc[len(export_csv)] = export_data[i]\n",
    "    \n",
    "    export_csv2 = export_csv.sort_values(by=['sim'], axis=0, ascending=False)\n",
    "    \n",
    "    export_csv2.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equl_distribution(input_csv_path, output_csv_path):\n",
    "    \n",
    "    #read csv\n",
    "    export_csv2 = pd.read_csv(input_csv_path,index_col=0)\n",
    "    \n",
    "    class Paper:\n",
    "        \n",
    "        def __init__(self, title, date, submitter, reviwer_name, reviwer_orcid, title2, sim, count):\n",
    "            self.title = title\n",
    "            self.date = date\n",
    "            self.submitter = submitter\n",
    "            self.reviwer_name = reviwer_name\n",
    "            self.reviwer_orcid = reviwer_orcid\n",
    "            self.reviwer_title = title2\n",
    "            self.sim = sim\n",
    "            self.count = count\n",
    "\n",
    "        def __repr__(self):\n",
    "            return repr((self.title, self.date, self.submitter, self.reviwer_name, self.reviwer_orcid, self.reviwer_title, self.sim, self.count))\n",
    "\n",
    "    papers,objs=[export_csv2.iloc[i].tolist() for i in range(len(export_csv2))],[]\n",
    "\n",
    "    for paper in papers:\n",
    "        objs.append(Paper(*paper))\n",
    "    \n",
    "    o = (multisort(list(objs), (('date', False), ('sim', True))))\n",
    "    \n",
    "    final_list=[]\n",
    "    for i in range(0,len(export_csv2),6) :\n",
    "        temp_list=[]\n",
    "        for t in range(6):\n",
    "            if len(temp_list) == 3:break\n",
    "            else :\n",
    "                temp = i + t\n",
    "                if (o[temp].count) < 3 :\n",
    "                    o[temp].count += 1\n",
    "                    for j in range(0+temp, len(export_csv2)) :\n",
    "                        if (o[temp].reviwer_name == o[j].reviwer_name) :\n",
    "                            o[j].count += 1\n",
    "                    o[temp].count -= 1\n",
    "                    class_1=(str(o[temp]))[1:-1]\n",
    "                    class_2=class_1.replace('\\'','')\n",
    "                    class_3=class_2.split(', ')\n",
    "                    temp_list.append(class_3)\n",
    "        final_list.extend(temp_list)\n",
    "        \n",
    "    final=pd.DataFrame(final_list,columns=['submitter_title','date','submitter_name','reviewer_name','reviewer_orcid','title','sim','count'])\n",
    "    final.to_csv(output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewee=extractive_keyword(path='../reviewee/submitter_10_k.csv',\n",
    "                            database_update_path='../reviewee/update/sybmitter_update_100.csv',\n",
    "                            extract_word_num=30)\n",
    "#return type : pandas.dataframe\n",
    "print('[extractive_keyword | {time:2.5f}]'.format(time=time.time() - start_time))\n",
    "display(reviewee)\n",
    "print('---------------1---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer=professionalism(path='../reviewer_pool/reviewer_attribute_937.csv',\n",
    "                         extractive_keyword_result=reviewee,\n",
    "                         reviewee_index=0,\n",
    "                         top_limit=20,\n",
    "                         silhouette_range=25)\n",
    "#return type : pandas.dataframe\n",
    "display(reviewer.iloc[:,[0,2,3,4,5]])\n",
    "print('--------------2----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_rank = interest(\n",
    "    co_author_path='../reviewer_pool/reviewer_coauthor_937.csv',\n",
    "    reviewer_information_path='../reviewer_pool/reviewer_information_937.csv',\n",
    "    co_author_network_path='../co_author_network/network.csv',\n",
    "    professionalism_result=reviewer,\n",
    "    extractive_keyword_result=reviewee,\n",
    "    reviewee_index=0,\n",
    "    matrix_multifly_count=1)\n",
    "#return type : pandas.dataframe\n",
    "display(reviewer_rank)\n",
    "# reviewer_rank.to_csv('./a.csv')\n",
    "print('--------------3----------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(output_path='../algorithm_output/export_csv_937.csv',\n",
    "         extractive_keyword_result=reviewee,\n",
    "         professionalism_result=reviewer_rank,\n",
    "         reviewee_index=0,\n",
    "         top_limit=3)\n",
    "display(save_csv)\n",
    "\n",
    "\n",
    "print('-------------------11------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equl_distribution(input_csv_path='../algorithm_output/export_csv_937.csv',\n",
    "             output_csv_path='../algorithm_output/final_csv_937.csv')\n",
    "\n",
    "print('[equl_distribution | {time:2.5f}]'.format(time=time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
